{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BC2406 Project\n",
    "\n",
    "3 types:\n",
    "* lin reg\n",
    "* logistic reg\n",
    "* CART (dec tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAWN\n",
      "WELL-00001\n",
      "WELL-00002\n",
      "WELL-00006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36000</th>\n",
       "      <td>WELL-00001</td>\n",
       "      <td>20140124213136</td>\n",
       "      <td>2014-01-24 21:31:36.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18433410.0</td>\n",
       "      <td>116.9109</td>\n",
       "      <td>9366608.0</td>\n",
       "      <td>75.34820</td>\n",
       "      <td>-300917.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36001</th>\n",
       "      <td>WELL-00001</td>\n",
       "      <td>20140124213136</td>\n",
       "      <td>2014-01-24 21:31:37.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18433410.0</td>\n",
       "      <td>116.9109</td>\n",
       "      <td>9366602.0</td>\n",
       "      <td>75.34825</td>\n",
       "      <td>-300917.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36002</th>\n",
       "      <td>WELL-00001</td>\n",
       "      <td>20140124213136</td>\n",
       "      <td>2014-01-24 21:31:38.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18433410.0</td>\n",
       "      <td>116.9109</td>\n",
       "      <td>9366598.0</td>\n",
       "      <td>75.34831</td>\n",
       "      <td>-300917.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36003</th>\n",
       "      <td>WELL-00001</td>\n",
       "      <td>20140124213136</td>\n",
       "      <td>2014-01-24 21:31:39.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18433410.0</td>\n",
       "      <td>116.9109</td>\n",
       "      <td>9366592.0</td>\n",
       "      <td>75.34837</td>\n",
       "      <td>-300917.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36004</th>\n",
       "      <td>WELL-00001</td>\n",
       "      <td>20140124213136</td>\n",
       "      <td>2014-01-24 21:31:40.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18433410.0</td>\n",
       "      <td>116.9109</td>\n",
       "      <td>9366588.0</td>\n",
       "      <td>75.34843</td>\n",
       "      <td>-300917.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521489</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20170801063614</td>\n",
       "      <td>2017-08-01 20:19:23.000000</td>\n",
       "      <td>44858050.0</td>\n",
       "      <td>17964400.0</td>\n",
       "      <td>119.2546</td>\n",
       "      <td>2236839.0</td>\n",
       "      <td>81.15103</td>\n",
       "      <td>1306983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521490</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20170801063614</td>\n",
       "      <td>2017-08-01 20:19:24.000000</td>\n",
       "      <td>44858050.0</td>\n",
       "      <td>17964330.0</td>\n",
       "      <td>119.2546</td>\n",
       "      <td>2236629.0</td>\n",
       "      <td>81.15062</td>\n",
       "      <td>1306984.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521491</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20170801063614</td>\n",
       "      <td>2017-08-01 20:19:25.000000</td>\n",
       "      <td>44858050.0</td>\n",
       "      <td>17964270.0</td>\n",
       "      <td>119.2546</td>\n",
       "      <td>2236111.0</td>\n",
       "      <td>81.15021</td>\n",
       "      <td>1306985.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521492</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20170801063614</td>\n",
       "      <td>2017-08-01 20:19:26.000000</td>\n",
       "      <td>44858050.0</td>\n",
       "      <td>17964210.0</td>\n",
       "      <td>119.2546</td>\n",
       "      <td>2235592.0</td>\n",
       "      <td>81.14980</td>\n",
       "      <td>1306986.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521493</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20170801063614</td>\n",
       "      <td>2017-08-01 20:19:27.000000</td>\n",
       "      <td>44858050.0</td>\n",
       "      <td>17964140.0</td>\n",
       "      <td>119.2546</td>\n",
       "      <td>2235074.0</td>\n",
       "      <td>81.14938</td>\n",
       "      <td>1306987.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118294 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name              id                   timestamp       P-PDG  \\\n",
       "36000   WELL-00001  20140124213136  2014-01-24 21:31:36.000000         0.0   \n",
       "36001   WELL-00001  20140124213136  2014-01-24 21:31:37.000000         0.0   \n",
       "36002   WELL-00001  20140124213136  2014-01-24 21:31:38.000000         0.0   \n",
       "36003   WELL-00001  20140124213136  2014-01-24 21:31:39.000000         0.0   \n",
       "36004   WELL-00001  20140124213136  2014-01-24 21:31:40.000000         0.0   \n",
       "...            ...             ...                         ...         ...   \n",
       "521489  WELL-00006  20170801063614  2017-08-01 20:19:23.000000  44858050.0   \n",
       "521490  WELL-00006  20170801063614  2017-08-01 20:19:24.000000  44858050.0   \n",
       "521491  WELL-00006  20170801063614  2017-08-01 20:19:25.000000  44858050.0   \n",
       "521492  WELL-00006  20170801063614  2017-08-01 20:19:26.000000  44858050.0   \n",
       "521493  WELL-00006  20170801063614  2017-08-01 20:19:27.000000  44858050.0   \n",
       "\n",
       "             P-TPT     T-TPT  P-MON-CKP  T-JUS-CKP  P-JUS-CKGL  T-JUS-CKGL  \\\n",
       "36000   18433410.0  116.9109  9366608.0   75.34820   -300917.8         NaN   \n",
       "36001   18433410.0  116.9109  9366602.0   75.34825   -300917.8         NaN   \n",
       "36002   18433410.0  116.9109  9366598.0   75.34831   -300917.8         NaN   \n",
       "36003   18433410.0  116.9109  9366592.0   75.34837   -300917.8         NaN   \n",
       "36004   18433410.0  116.9109  9366588.0   75.34843   -300917.8         NaN   \n",
       "...            ...       ...        ...        ...         ...         ...   \n",
       "521489  17964400.0  119.2546  2236839.0   81.15103   1306983.0         NaN   \n",
       "521490  17964330.0  119.2546  2236629.0   81.15062   1306984.0         NaN   \n",
       "521491  17964270.0  119.2546  2236111.0   81.15021   1306985.0         NaN   \n",
       "521492  17964210.0  119.2546  2235592.0   81.14980   1306986.0         NaN   \n",
       "521493  17964140.0  119.2546  2235074.0   81.14938   1306987.0         NaN   \n",
       "\n",
       "        QGL  class  \n",
       "36000   0.0    0.0  \n",
       "36001   0.0    0.0  \n",
       "36002   0.0    0.0  \n",
       "36003   0.0    0.0  \n",
       "36004   0.0    0.0  \n",
       "...     ...    ...  \n",
       "521489  0.0    1.0  \n",
       "521490  0.0    1.0  \n",
       "521491  0.0    1.0  \n",
       "521492  0.0    1.0  \n",
       "521493  0.0    1.0  \n",
       "\n",
       "[118294 rows x 12 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# csv_directory='/Users/cherylong/Desktop/1_aib_well_dataset'\n",
    "# csv_files=[file for file in os.listdir(csv_directory) if file.endswith('.csv')]\n",
    "# print(csv_files)\n",
    "#import csv files\n",
    "# print(csv_files)\n",
    "path=os.path.join(os.getcwd(),'data','1')\n",
    "csv_files=glob.glob(path + \"/*.csv\")\n",
    "\n",
    "#remove BC2406.ipynb from csv_files\n",
    "# csv_files.remove('BC2406.ipynb')\n",
    "\n",
    "# remove all files whose file name (not path) starts with SIMULATED\n",
    "csv_files=[csv_file for csv_file in csv_files if not os.path.basename(csv_file).startswith('SIMULATED')]\n",
    "csv_files=[csv_file for csv_file in csv_files if not os.path.basename(csv_file).startswith('DRAWN')]\n",
    "\n",
    "dataframes={}\n",
    "for csv_file in csv_files:\n",
    "  well_name=os.path.splitext(csv_file)[0]\n",
    "  df=pd.read_csv(csv_file)\n",
    "  dataframes[well_name]=df\n",
    "\n",
    "for well_name,df in dataframes.items():\n",
    "  df.insert(0,'name',well_name.split('_')[0].split('/')[-1])\n",
    "  df.insert(1,'id',well_name.split('_')[1])\n",
    "\n",
    "df=pd.concat(dataframes.values(),ignore_index=True)\n",
    "\n",
    "distinct_wells=df['name'].unique()\n",
    "for name in distinct_wells:\n",
    "  print(name)\n",
    "\n",
    "# drop all rows with name = \"DRAWN\"\n",
    "\n",
    "df = df[df['name'] != 'DRAWN']\n",
    "\n",
    "# \n",
    "\n",
    "# float64_cols = list(df.select_dtypes(include=\"float64\"))\n",
    "# df[list(df.select_dtypes(include=\"float64\"))] = df[list(df.select_dtypes(include=\"float64\"))].astype(\"float32\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0. 101.   1.  nan]\n",
      "count of 0 in class label 119319\n",
      "count of 1 in class label 33261\n",
      "count of 101 in class label 511895\n"
     ]
    }
   ],
   "source": [
    "# show all values in column class\n",
    "print(df['class'].unique())\n",
    "\n",
    "# count number of 0, 101, 1\n",
    "\n",
    "print(\"count of 0 in class label\",len(df[df['class']==0]))\n",
    "print(\"count of 1 in class label\",len(df[df['class']==1]))\n",
    "print(\"count of 101 in class label\",len(df[df['class']==101]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna()\n",
    "#clean dataset to remove name, id, timestamp\n",
    "df=df.drop(['name','id','timestamp'],axis=1)\n",
    "\n",
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop(['class'],axis=1)\n",
    "y=df['class']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-PDG         float64\n",
      "P-TPT         float64\n",
      "T-TPT         float64\n",
      "P-MON-CKP     float64\n",
      "T-JUS-CKP     float64\n",
      "P-JUS-CKGL    float64\n",
      "T-JUS-CKGL    float64\n",
      "QGL           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (Not good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# import numpy as np\n",
    "\n",
    "# train_set,test_set=train_test_split(df,test_size=0.2,random_state=42)\n",
    "# #random state shuffles the data\n",
    "\n",
    "# #train linear regression model on training set against class label\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# #train model on training set\n",
    "# lin_reg=LinearRegression()\n",
    "# lin_reg.fit(train_set.drop('class',axis=1),train_set['class'])\n",
    "\n",
    "\n",
    "# #predict class label on training set\n",
    "# train_set_predictions=lin_reg.predict(train_set.drop('class',axis=1))\n",
    "# lin_mse=mean_squared_error(train_set['class'],train_set_predictions)\n",
    "# lin_rmse=np.sqrt(lin_mse)\n",
    "# lin_mae=mean_absolute_error(train_set['class'],train_set_predictions)\n",
    "# lin_r2=r2_score(train_set['class'],train_set_predictions)\n",
    "# print(\"Training set RMSE: \",lin_rmse)\n",
    "# print(\"Training set MAE: \",lin_mae)\n",
    "# print(\"Training set R2: \",lin_r2)\n",
    "\n",
    "# #predict class label on test set\n",
    "# test_set_predictions=lin_reg.predict(test_set.drop('class',axis=1))\n",
    "# lin_mse=mean_squared_error(test_set['class'],test_set_predictions)\n",
    "# lin_rmse=np.sqrt(lin_mse)\n",
    "# lin_mae=mean_absolute_error(test_set['class'],test_set_predictions)\n",
    "# lin_r2=r2_score(test_set['class'],test_set_predictions)\n",
    "# print(\"Test set RMSE: \",lin_rmse)\n",
    "# print(\"Test set MAE: \",lin_mae)\n",
    "# print(\"Test set R2: \",lin_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logisitic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_accuracy\n",
      " 0.18048219746203953\n",
      "[[ 24022      0      0]\n",
      " [  6633      0      0]\n",
      " [102444      0      0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.18      1.00      0.31     24022\n",
      "         1.0       0.00      0.00      0.00      6633\n",
      "       101.0       0.00      0.00      0.00    102444\n",
      "\n",
      "    accuracy                           0.18    133099\n",
      "   macro avg       0.06      0.33      0.10    133099\n",
      "weighted avg       0.03      0.18      0.06    133099\n",
      "\n",
      "log_accuracy = 18.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#train logistic regression model on training set against class label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#train model on training set\n",
    "log_reg=LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "logreg_train_set_predictions=log_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "logreg_test_set_predictions=log_reg.predict(X_test)\n",
    "log_accuracy=accuracy_score(y_test,logreg_test_set_predictions)\n",
    "log_confusion_matrix=confusion_matrix(y_test,logreg_test_set_predictions)\n",
    "log_classification_report=classification_report(y_test,logreg_test_set_predictions)\n",
    "\n",
    "print(\"log_accuracy\\n\",log_accuracy)\n",
    "print(log_confusion_matrix)\n",
    "print(log_classification_report)\n",
    "print(\"log_accuracy = %.1f\"%(log_accuracy*100),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (Not really sure what's going on here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train decision tree regression model on training set against class label\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# check X_train for float32 \n",
    "print(X_train.dtypes)\n",
    "#print(X_train.dtype)\n",
    "#X_train = X_train.astype(np.float32)\n",
    "\n",
    "\n",
    "#train model on training set\n",
    "dt_reg=DecisionTreeRegressor()\n",
    "dt_reg.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "dectree_train_set_predictions=dt_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "dectree_test_set_predictions=dt_reg.predict(X_test)\n",
    "dt_mse=mean_squared_error(y_test,dectree_test_set_predictions)\n",
    "dt_rmse=np.sqrt(dt_mse)\n",
    "#dt_accuracy=accuracy_score(y_test,dectree_test_set_predictions)\n",
    "dt_confusion_matrix=confusion_matrix(y_test,dectree_test_set_predictions)\n",
    "\n",
    "print(\"dt_mse\\n\",dt_mse)\n",
    "print(\"dt_rmse\\n\",dt_rmse)\n",
    "print(\"dt_accuracy\\n\",dt_accuracy)\n",
    "print(dt_confusion_matrix)\n",
    "print(\"dt_accuracy = %.1f\"%(dt_accuracy*100),\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_class=xgb.XGBClassifier()\n",
    "xgb_class.fit(X_train,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "xgb_train_set_predictions=xgb_class.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "y_pred=xgb_class.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train logistic regression model on training set against class label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#convert y_pred to 0,1,101\n",
    "y_pred=np.round(y_pred)\n",
    "y_pred=le.inverse_transform(y_pred.astype(int))\n",
    "\n",
    "xgb_accuracy=accuracy_score(y_test,y_pred)\n",
    "xgb_confusion_matrix=confusion_matrix(y_test,y_pred)\n",
    "xgb_classification_report=classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"xgb_accuracy\\n\",xgb_accuracy)\n",
    "print(xgb_confusion_matrix)\n",
    "print(xgb_classification_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_reg=CatBoostClassifier()\n",
    "cat_reg.fit(X_train,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "cat_train_set_predictions=cat_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "cat_test_set_predictions=cat_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert y_pred to 0,1,101\n",
    "cat_test_set_predictions=np.round(cat_test_set_predictions)\n",
    "cat_test_set_predictions=le.inverse_transform(cat_test_set_predictions.astype(int))\n",
    "\n",
    "cat_accuracy=accuracy_score(y_test,cat_test_set_predictions)\n",
    "cat_confusion_matrix=confusion_matrix(y_test,cat_test_set_predictions)\n",
    "\n",
    "print(\"cat_accuracy\\n\",cat_accuracy)\n",
    "print(cat_confusion_matrix)\n",
    "print(xgb_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM  (Can't really download LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train lightgbm regression model on training set against class label\n",
    "\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "lgb_reg=lgb.LGBMRegressor()\n",
    "lgb_reg.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "lgb_train_set_predictions=lgb_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "lgb_test_set_predictions=lgb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "lgb_test_set_predictions=np.round(lgb_test_set_predictions)\n",
    "lgb_test_set_predictions=le.inverse_transform(lgb_test_set_predictions.astype(int))\n",
    "\n",
    "lgb_accuracy=accuracy_score(y_test,lgb_test_set_predictions)\n",
    "lgb_confusion_matrix=confusion_matrix(y_test,lgb_test_set_predictions)\n",
    "lgb_classification_report=classification_report(y_test,lgb_test_set_predictions)\n",
    "\n",
    "print(\"lgb_accuracy\\n\",lgb_accuracy)\n",
    "print(lgb_confusion_matrix)\n",
    "print(xgb_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare both models with f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# calculate F1 scores for both models\n",
    "logreg_f1 = f1_score(y_test, logreg_test_set_predictions, average='weighted')\n",
    "dectree_f1 = f1_score(y_test, dectree_test_set_predictions, average='weighted')\n",
    "\n",
    "# print\n",
    "print(\"F1 scores:\")\n",
    "print(\"Logistic Regression: \", logreg_f1)\n",
    "print(\"Decision Tree Regressor: \", dectree_f1)\n",
    "\n",
    "# compare F1 scores\n",
    "if logreg_f1 > dectree_f1:\n",
    "    print(\"Logistic Regression has a higher F1 score.\")\n",
    "elif logreg_f1 < dectree_f1:\n",
    "    print(\"Decision Tree has a higher F1 score.\")\n",
    "else:\n",
    "    print(\"Both models have the same F1 score.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "csv_directory='/Users/cherylong/Desktop/8_hpl_well_dataset'\n",
    "csv_files=[file for file in os.listdir(csv_directory) if file.endswith('.csv')]\n",
    "print(csv_files)\n",
    "dataframes={}\n",
    "#import csv files\n",
    "# print(csv_files)\n",
    "# path=os.path.join(os.getcwd(),'data','3')\n",
    "# csv_files=glob.glob(path + \"/*.csv\")\n",
    "\n",
    "#remove BC2406.ipynb from csv_files\n",
    "# csv_files.remove('BC2406.ipynb')\n",
    "\n",
    "# remove all files whose file name (not path) starts with SIMULATED\n",
    "#csv_files=[csv_file for csv_file in csv_files if not os.path.basename(csv_file).startswith('SIMULATED')]\n",
    "\n",
    "\n",
    "for csv_file in csv_files:\n",
    "  well_name=os.path.splitext(csv_file)[0]\n",
    "  df=pd.read_csv(os.path.join(csv_directory,csv_file))\n",
    "  dataframes[well_name]=df\n",
    "\n",
    "for well_name,df in dataframes.items():\n",
    "  df.insert(0,'name',well_name.split('_')[0])\n",
    "  df.insert(1,'id',well_name.split('_')[1])\n",
    "\n",
    "df=pd.concat(dataframes.values(),ignore_index=True)\n",
    "\n",
    "distinct_wells=df['name'].unique()\n",
    "for name in distinct_wells:\n",
    "  print(name)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#clean dataset to remove name, id, timestamp\n",
    "df=df.drop(['name','id','timestamp', 'T-JUS-CKGL','P-JUS-CKGL','QGL'],axis=1)\n",
    "\n",
    "#replace all NaN with 0\n",
    "# df=df.fillna(0)\n",
    "\n",
    "# drop all rows with class NaN\n",
    "df=df.dropna(subset=['class'])\n",
    "\n",
    "# # print NaN in any column\n",
    "\n",
    "# drop all rows where P-PDG is NaN\n",
    "df=df.dropna(subset=['P-PDG'])\n",
    "\n",
    "print(df[df.isna().any(axis=1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all values in column class\n",
    "print(df['class'].unique())\n",
    "\n",
    "# print 5 rows where class = NaN\n",
    "print(df[df['class'].isna()].head())\n",
    "\n",
    "#count number of 0, 3 in class label\n",
    "print(\"count of 0 in class label: \",len(df[df['class']==0])) # normal state\n",
    "print(\"count of NaN in class label: \",len(df[df['class'].isna()])) # NaN state\n",
    "print(\"count of 8 in class label: \",len(df[df['class']==8]))  # warning state\n",
    "print(\"count of 108 in class label: \",len(df[df['class']==108]))  # error state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop(['class'],axis=1)\n",
    "y=df['class']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "train_set,test_set=train_test_split(df,test_size=0.2,random_state=42)\n",
    "#random state shuffles the data\n",
    "\n",
    "#train linear regression model on training set against class label\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#train model on training set\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(train_set.drop('class',axis=1),train_set['class'])\n",
    "\n",
    "\n",
    "#predict class label on training set\n",
    "train_set_predictions=lin_reg.predict(train_set.drop('class',axis=1))\n",
    "lin_mse=mean_squared_error(train_set['class'],train_set_predictions)\n",
    "lin_rmse=np.sqrt(lin_mse)\n",
    "lin_mae=mean_absolute_error(train_set['class'],train_set_predictions)\n",
    "lin_r2=r2_score(train_set['class'],train_set_predictions)\n",
    "print(\"Training set RMSE: \",lin_rmse)\n",
    "print(\"Training set MAE: \",lin_mae)\n",
    "print(\"Training set R2: \",lin_r2)\n",
    "\n",
    "#predict class label on test set\n",
    "test_set_predictions=lin_reg.predict(test_set.drop('class',axis=1))\n",
    "lin_mse=mean_squared_error(test_set['class'],test_set_predictions)\n",
    "lin_rmse=np.sqrt(lin_mse)\n",
    "lin_mae=mean_absolute_error(test_set['class'],test_set_predictions)\n",
    "lin_r2=r2_score(test_set['class'],test_set_predictions)\n",
    "print(\"Test set RMSE: \",lin_rmse)\n",
    "print(\"Test set MAE: \",lin_mae)\n",
    "print(\"Test set R2: \",lin_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train logistic regression model on training set against class label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#train model on training set\n",
    "log_reg=LogisticRegression(max_iter=100000)\n",
    "log_reg.fit(X_train_scaled,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "logreg_train_set_predictions=log_reg.predict(X_train_scaled)\n",
    "\n",
    "#test model on test set\n",
    "logreg_test_set_predictions=log_reg.predict(X_test_scaled)\n",
    "log_accuracy=accuracy_score(y_test,logreg_test_set_predictions)\n",
    "log_confusion_matrix=confusion_matrix(y_test,logreg_test_set_predictions)\n",
    "log_classification_report=classification_report(y_test,logreg_test_set_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"log_accuracy\\n\",log_accuracy)\n",
    "print(log_confusion_matrix)\n",
    "print(log_classification_report)\n",
    "print(\"log_accuracy = %.1f\"%(log_accuracy*100),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree (not sure if this works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train decision tree regression model on training set against class label\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train = np.nan_to_num(X_train.astype(np.float64))\n",
    "X_test = np.nan_to_num(X_test.astype(np.float64))\n",
    "\n",
    "# check for infinite or NaN values in X_train and X_test\n",
    "if not np.isfinite(X_train).all() or not np.isfinite(X_test).all():\n",
    "    print(\"Input data contains infinite or NaN values.\")\n",
    "\n",
    "#train model on training set\n",
    "dt_reg=DecisionTreeRegressor()\n",
    "dt_reg.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "dectree_train_set_predictions=dt_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "dectree_test_set_predictions=dt_reg.predict(X_test)\n",
    "dt_mse=mean_squared_error(y_test,dectree_test_set_predictions)\n",
    "dt_rmse=np.sqrt(dt_mse)\n",
    "dt_accuracy=accuracy_score(y_test,dectree_test_set_predictions)\n",
    "dt_confusion_matrix=confusion_matrix(y_test,dectree_test_set_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dt_mse\\n\",dt_mse)\n",
    "print(\"dt_rmse\\n\",dt_rmse)\n",
    "print(\"dt_accuracy\\n\",dt_accuracy)\n",
    "print(dt_confusion_matrix)\n",
    "print(\"dt_accuracy = %.1f\"%(dt_accuracy*100),\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train xgboost regression model on training set against class label\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "xgb_class=xgb.XGBClassifier()\n",
    "xgb_class.fit(X_train_scaled,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "xgb_train_set_predictions=xgb_class.predict(X_train_scaled)\n",
    "\n",
    "#test model on test set\n",
    "y_pred=xgb_class.predict(X_test_scaled)\n",
    "\n",
    "#convert y_pred\n",
    "y_pred=np.round(y_pred)\n",
    "y_pred=le.inverse_transform(y_pred.astype(int))\n",
    "\n",
    "xgb_accuracy=accuracy_score(y_test,y_pred)\n",
    "xgb_confusion_matrix=confusion_matrix(y_test,y_pred)\n",
    "xgb_classification_report=classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"xgb_accuracy\\n\",xgb_accuracy)\n",
    "print(xgb_confusion_matrix)\n",
    "print(xgb_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train catboost regression model on training set against class label\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "cat_reg=CatBoostClassifier()\n",
    "cat_reg.fit(X_train_scaled,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "cat_train_set_predictions=cat_reg.predict(X_train_scaled)\n",
    "\n",
    "\n",
    "#test model on test set\n",
    "cat_test_set_predictions=cat_reg.predict(X_test_scaled)\n",
    "\n",
    "#convert y_pred\n",
    "cat_test_set_predictions=np.round(cat_test_set_predictions)\n",
    "cat_test_set_predictions=le.inverse_transform(cat_test_set_predictions.astype(int))\n",
    "\n",
    "cat_accuracy=accuracy_score(y_test,cat_test_set_predictions)\n",
    "cat_confusion_matrix=confusion_matrix(y_test,cat_test_set_predictions)\n",
    "cat_classification_report=classification_report(y_test,cat_test_set_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cat_accuracy\\n\",cat_accuracy)\n",
    "print(cat_confusion_matrix)\n",
    "print(cat_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune hyperparameters for catboost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "cat_reg=CatBoostClassifier()\n",
    "\n",
    "# define the grid of hyperparameters to search\n",
    "search_space = {'iterations': [100, 200, 500],\n",
    "                'learning_rate': [0.01, 0.05, 0.1],\n",
    "                'depth': [3, 5, 7]}\n",
    "# define search\n",
    "grid_search = GridSearchCV(cat_reg, search_space, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "# execute search\n",
    "grid_result = grid_search.fit(X_train_scaled, y_trainLE)\n",
    "# summarize result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM (can't install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#train lightgbm regression model on training set against class label\n",
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "lgb_reg=lgb.LGBMClassifier()\n",
    "lgb_reg.fit(X_train_scaled,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "lgb_train_set_predictions=lgb_reg.predict(X_train_scaled)\n",
    "\n",
    "#test model on test set\n",
    "lgb_test_set_predictions=lgb_reg.predict(X_test_scaled)\n",
    "\n",
    "#convert y_pred\n",
    "lgb_test_set_predictions=np.round(lgb_test_set_predictions)\n",
    "lgb_test_set_predictions=le.inverse_transform(lgb_test_set_predictions.astype(int))\n",
    "\n",
    "lgb_accuracy=accuracy_score(y_test,lgb_test_set_predictions)\n",
    "lgb_confusion_matrix=confusion_matrix(y_test,lgb_test_set_predictions)\n",
    "lgb_classification_report=classification_report(y_test,lgb_test_set_predictions)\n",
    "\n",
    "print(\"lgb_accuracy\\n\",lgb_accuracy)\n",
    "print(lgb_confusion_matrix)\n",
    "print(lgb_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune hyperparameters for lightgbm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "lgb_reg=lgb.LGBMClassifier()\n",
    "\n",
    "# define the grid of hyperparameters to search\n",
    "search_space = {'n_estimators': [100, 200, 500],\n",
    "                'learning_rate': [0.01, 0.05, 0.1],\n",
    "                'max_depth': [3, 5, 7]}\n",
    "# define search\n",
    "grid_search = GridSearchCV(lgb_reg, search_space, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "# execute search\n",
    "grid_result = grid_search.fit(X_train_scaled, y_trainLE)\n",
    "# summarize result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
