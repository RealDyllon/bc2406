{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BC2406 Project\n",
    "\n",
    "3 types:\n",
    "* lin reg\n",
    "* logistic reg\n",
    "* CART (dec tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMULATED\n",
      "WELL-00001\n",
      "WELL-00002\n",
      "WELL-00006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SIMULATED</td>\n",
       "      <td>00035</td>\n",
       "      <td>2018-10-06 11:30:10.000000</td>\n",
       "      <td>19895150.0</td>\n",
       "      <td>12202720.0</td>\n",
       "      <td>94.10425</td>\n",
       "      <td>1153320.0</td>\n",
       "      <td>71.93039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SIMULATED</td>\n",
       "      <td>00035</td>\n",
       "      <td>2018-10-06 11:30:11.000000</td>\n",
       "      <td>19895150.0</td>\n",
       "      <td>12202720.0</td>\n",
       "      <td>94.10425</td>\n",
       "      <td>1153320.0</td>\n",
       "      <td>71.93040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SIMULATED</td>\n",
       "      <td>00035</td>\n",
       "      <td>2018-10-06 11:30:12.000000</td>\n",
       "      <td>19895150.0</td>\n",
       "      <td>12202720.0</td>\n",
       "      <td>94.10426</td>\n",
       "      <td>1153320.0</td>\n",
       "      <td>71.93042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SIMULATED</td>\n",
       "      <td>00035</td>\n",
       "      <td>2018-10-06 11:30:13.000000</td>\n",
       "      <td>19895150.0</td>\n",
       "      <td>12202720.0</td>\n",
       "      <td>94.10426</td>\n",
       "      <td>1153320.0</td>\n",
       "      <td>71.93044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SIMULATED</td>\n",
       "      <td>00035</td>\n",
       "      <td>2018-10-06 11:30:14.000000</td>\n",
       "      <td>19895150.0</td>\n",
       "      <td>12202720.0</td>\n",
       "      <td>94.10427</td>\n",
       "      <td>1153320.0</td>\n",
       "      <td>71.93045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441402</th>\n",
       "      <td>SIMULATED</td>\n",
       "      <td>00038</td>\n",
       "      <td>2018-10-07 12:28:36.000000</td>\n",
       "      <td>23708740.0</td>\n",
       "      <td>13660770.0</td>\n",
       "      <td>97.60462</td>\n",
       "      <td>1129454.0</td>\n",
       "      <td>83.24790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441403</th>\n",
       "      <td>SIMULATED</td>\n",
       "      <td>00038</td>\n",
       "      <td>2018-10-07 12:28:37.000000</td>\n",
       "      <td>23708740.0</td>\n",
       "      <td>13660770.0</td>\n",
       "      <td>97.60462</td>\n",
       "      <td>1115079.0</td>\n",
       "      <td>83.22288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441404</th>\n",
       "      <td>SIMULATED</td>\n",
       "      <td>00038</td>\n",
       "      <td>2018-10-07 12:28:38.000000</td>\n",
       "      <td>23708740.0</td>\n",
       "      <td>13660770.0</td>\n",
       "      <td>97.60462</td>\n",
       "      <td>1109266.0</td>\n",
       "      <td>83.21536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441405</th>\n",
       "      <td>SIMULATED</td>\n",
       "      <td>00038</td>\n",
       "      <td>2018-10-07 12:28:39.000000</td>\n",
       "      <td>23708740.0</td>\n",
       "      <td>13660770.0</td>\n",
       "      <td>97.60462</td>\n",
       "      <td>1129454.0</td>\n",
       "      <td>83.24790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441406</th>\n",
       "      <td>SIMULATED</td>\n",
       "      <td>00038</td>\n",
       "      <td>2018-10-07 12:28:40.000000</td>\n",
       "      <td>23708740.0</td>\n",
       "      <td>13660770.0</td>\n",
       "      <td>97.60462</td>\n",
       "      <td>1115079.0</td>\n",
       "      <td>83.22288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8441407 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name     id                   timestamp       P-PDG       P-TPT  \\\n",
       "0        SIMULATED  00035  2018-10-06 11:30:10.000000  19895150.0  12202720.0   \n",
       "1        SIMULATED  00035  2018-10-06 11:30:11.000000  19895150.0  12202720.0   \n",
       "2        SIMULATED  00035  2018-10-06 11:30:12.000000  19895150.0  12202720.0   \n",
       "3        SIMULATED  00035  2018-10-06 11:30:13.000000  19895150.0  12202720.0   \n",
       "4        SIMULATED  00035  2018-10-06 11:30:14.000000  19895150.0  12202720.0   \n",
       "...            ...    ...                         ...         ...         ...   \n",
       "8441402  SIMULATED  00038  2018-10-07 12:28:36.000000  23708740.0  13660770.0   \n",
       "8441403  SIMULATED  00038  2018-10-07 12:28:37.000000  23708740.0  13660770.0   \n",
       "8441404  SIMULATED  00038  2018-10-07 12:28:38.000000  23708740.0  13660770.0   \n",
       "8441405  SIMULATED  00038  2018-10-07 12:28:39.000000  23708740.0  13660770.0   \n",
       "8441406  SIMULATED  00038  2018-10-07 12:28:40.000000  23708740.0  13660770.0   \n",
       "\n",
       "            T-TPT  P-MON-CKP  T-JUS-CKP  P-JUS-CKGL  T-JUS-CKGL  QGL  class  \n",
       "0        94.10425  1153320.0   71.93039         NaN         NaN  NaN    0.0  \n",
       "1        94.10425  1153320.0   71.93040         NaN         NaN  NaN    0.0  \n",
       "2        94.10426  1153320.0   71.93042         NaN         NaN  NaN    0.0  \n",
       "3        94.10426  1153320.0   71.93044         NaN         NaN  NaN    0.0  \n",
       "4        94.10427  1153320.0   71.93045         NaN         NaN  NaN    0.0  \n",
       "...           ...        ...        ...         ...         ...  ...    ...  \n",
       "8441402  97.60462  1129454.0   83.24790         NaN         NaN  NaN    1.0  \n",
       "8441403  97.60462  1115079.0   83.22288         NaN         NaN  NaN    1.0  \n",
       "8441404  97.60462  1109266.0   83.21536         NaN         NaN  NaN    1.0  \n",
       "8441405  97.60462  1129454.0   83.24790         NaN         NaN  NaN    1.0  \n",
       "8441406  97.60462  1115079.0   83.22288         NaN         NaN  NaN    1.0  \n",
       "\n",
       "[8441407 rows x 12 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# csv_directory='/Users/cherylong/Desktop/1_aib_well_dataset'\n",
    "# csv_files=[file for file in os.listdir(csv_directory) if file.endswith('.csv')]\n",
    "# print(csv_files)\n",
    "#import csv files\n",
    "# print(csv_files)\n",
    "path=os.path.join(os.getcwd(),'data','1')\n",
    "csv_files=glob.glob(path + \"/*.csv\")\n",
    "\n",
    "#remove BC2406.ipynb from csv_files\n",
    "# csv_files.remove('BC2406.ipynb')\n",
    "\n",
    "# remove all files whose file name (not path) starts with SIMULATED\n",
    "# csv_files=[csv_file for csv_file in csv_files if not os.path.basename(csv_file).startswith('SIMULATED')]\n",
    "csv_files=[csv_file for csv_file in csv_files if not os.path.basename(csv_file).startswith('DRAWN')]\n",
    "\n",
    "dataframes={}\n",
    "for csv_file in csv_files:\n",
    "  well_name=os.path.splitext(csv_file)[0]\n",
    "  df=pd.read_csv(csv_file)\n",
    "  dataframes[well_name]=df\n",
    "\n",
    "for well_name,df in dataframes.items():\n",
    "  df.insert(0,'name',well_name.split('_')[0].split('/')[-1])\n",
    "  df.insert(1,'id',well_name.split('_')[1])\n",
    "\n",
    "df=pd.concat(dataframes.values(),ignore_index=True)\n",
    "\n",
    "distinct_wells=df['name'].unique()\n",
    "for name in distinct_wells:\n",
    "  print(name)\n",
    "\n",
    "# \n",
    "\n",
    "# float64_cols = list(df.select_dtypes(include=\"float64\"))\n",
    "# df[list(df.select_dtypes(include=\"float64\"))] = df[list(df.select_dtypes(include=\"float64\"))].astype(\"float32\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0. 101.   1.  nan]\n",
      "count of 0 in class label 717591\n",
      "count of 1 in class label 2878583\n",
      "count of 101 in class label 4844214\n"
     ]
    }
   ],
   "source": [
    "# show all values in column class\n",
    "print(df['class'].unique())\n",
    "\n",
    "# count number of 0, 101, 1\n",
    "\n",
    "print(\"count of 0 in class label\",len(df[df['class']==0]))\n",
    "print(\"count of 1 in class label\",len(df[df['class']==1]))\n",
    "print(\"count of 101 in class label\",len(df[df['class']==101]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna()\n",
    "#clean dataset to remove name, id, timestamp\n",
    "df=df.drop(['name','id','timestamp'],axis=1)\n",
    "\n",
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop(['class'],axis=1)\n",
    "y=df['class']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-PDG         float64\n",
      "P-TPT         float64\n",
      "T-TPT         float64\n",
      "P-MON-CKP     float64\n",
      "T-JUS-CKP     float64\n",
      "P-JUS-CKGL    float64\n",
      "T-JUS-CKGL    float64\n",
      "QGL           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (Not good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# import numpy as np\n",
    "\n",
    "# train_set,test_set=train_test_split(df,test_size=0.2,random_state=42)\n",
    "# #random state shuffles the data\n",
    "\n",
    "# #train linear regression model on training set against class label\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# #train model on training set\n",
    "# lin_reg=LinearRegression()\n",
    "# lin_reg.fit(train_set.drop('class',axis=1),train_set['class'])\n",
    "\n",
    "\n",
    "# #predict class label on training set\n",
    "# train_set_predictions=lin_reg.predict(train_set.drop('class',axis=1))\n",
    "# lin_mse=mean_squared_error(train_set['class'],train_set_predictions)\n",
    "# lin_rmse=np.sqrt(lin_mse)\n",
    "# lin_mae=mean_absolute_error(train_set['class'],train_set_predictions)\n",
    "# lin_r2=r2_score(train_set['class'],train_set_predictions)\n",
    "# print(\"Training set RMSE: \",lin_rmse)\n",
    "# print(\"Training set MAE: \",lin_mae)\n",
    "# print(\"Training set R2: \",lin_r2)\n",
    "\n",
    "# #predict class label on test set\n",
    "# test_set_predictions=lin_reg.predict(test_set.drop('class',axis=1))\n",
    "# lin_mse=mean_squared_error(test_set['class'],test_set_predictions)\n",
    "# lin_rmse=np.sqrt(lin_mse)\n",
    "# lin_mae=mean_absolute_error(test_set['class'],test_set_predictions)\n",
    "# lin_r2=r2_score(test_set['class'],test_set_predictions)\n",
    "# print(\"Test set RMSE: \",lin_rmse)\n",
    "# print(\"Test set MAE: \",lin_mae)\n",
    "# print(\"Test set R2: \",lin_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logisitic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_accuracy\n",
      " 0.08561306701131682\n",
      "[[144539      0      0]\n",
      " [575479      0      0]\n",
      " [968264      0      0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.09      1.00      0.16    144539\n",
      "         1.0       0.00      0.00      0.00    575479\n",
      "       101.0       0.00      0.00      0.00    968264\n",
      "\n",
      "    accuracy                           0.09   1688282\n",
      "   macro avg       0.03      0.33      0.05   1688282\n",
      "weighted avg       0.01      0.09      0.01   1688282\n",
      "\n",
      "log_accuracy = 8.6 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#train logistic regression model on training set against class label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#train model on training set\n",
    "log_reg=LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "logreg_train_set_predictions=log_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "logreg_test_set_predictions=log_reg.predict(X_test)\n",
    "log_accuracy=accuracy_score(y_test,logreg_test_set_predictions)\n",
    "log_confusion_matrix=confusion_matrix(y_test,logreg_test_set_predictions)\n",
    "log_classification_report=classification_report(y_test,logreg_test_set_predictions)\n",
    "\n",
    "print(\"log_accuracy\\n\",log_accuracy)\n",
    "print(log_confusion_matrix)\n",
    "print(log_classification_report)\n",
    "print(\"log_accuracy = %.1f\"%(log_accuracy*100),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (Not really sure what's going on here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:134: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:134: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_mse\n",
      " 6.628874\n",
      "dt_rmse\n",
      " 2.5746598\n",
      "dt_accuracy\n",
      " 0.999336603719047\n",
      "[[144538      0      1]\n",
      " [     1 574924    554]\n",
      " [     6    558 967700]]\n",
      "dt_accuracy = 99.9 %\n"
     ]
    }
   ],
   "source": [
    "#train decision tree regression model on training set against class label\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# convert everything to float32\n",
    "\n",
    "X_train_32=X_train.astype('float32')\n",
    "y_train_32=y_train.astype('float32')\n",
    "X_test_32=X_test.astype('float32')\n",
    "y_test_32=y_test.astype('float32')\n",
    "\n",
    "# remove inf and nan\n",
    "X_train_32=X_train_32.replace([np.inf, -np.inf], np.nan)\n",
    "X_train_32=X_train_32.fillna(0)\n",
    "y_train_32=y_train_32.replace([np.inf, -np.inf], np.nan)\n",
    "y_train_32=y_train_32.fillna(0)\n",
    "X_test_32=X_test_32.replace([np.inf, -np.inf], np.nan)\n",
    "X_test_32=X_test_32.fillna(0)\n",
    "y_test_32=y_test_32.replace([np.inf, -np.inf], np.nan)\n",
    "y_test_32=y_test_32.fillna(0)\n",
    "\n",
    "#train model on training set\n",
    "dt_reg=DecisionTreeClassifier()\n",
    "dt_reg.fit(X_train_32,y_train_32)\n",
    "\n",
    "#predict class label on training set\n",
    "dectree_train_set_predictions=dt_reg.predict(X_train_32)\n",
    "\n",
    "#test model on test set\n",
    "dectree_test_set_predictions=dt_reg.predict(X_test_32)\n",
    "dt_mse=mean_squared_error(y_test_32,dectree_test_set_predictions)\n",
    "dt_rmse=np.sqrt(dt_mse)\n",
    "dt_accuracy=accuracy_score(y_test,dectree_test_set_predictions)\n",
    "dt_confusion_matrix=confusion_matrix(y_test_32,dectree_test_set_predictions)\n",
    "\n",
    "print(\"dt_mse\\n\",dt_mse)\n",
    "print(\"dt_rmse\\n\",dt_rmse)\n",
    "print(\"dt_accuracy\\n\",dt_accuracy)\n",
    "print(dt_confusion_matrix)\n",
    "print(\"dt_accuracy = %.1f\"%(dt_accuracy*100),\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_class=xgb.XGBClassifier()\n",
    "xgb_class.fit(X_train,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "xgb_train_set_predictions=xgb_class.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "y_pred=xgb_class.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train logistic regression model on training set against class label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#convert y_pred to 0,1,101\n",
    "y_pred=np.round(y_pred)\n",
    "y_pred=le.inverse_transform(y_pred.astype(int))\n",
    "\n",
    "xgb_accuracy=accuracy_score(y_test,y_pred)\n",
    "xgb_confusion_matrix=confusion_matrix(y_test,y_pred)\n",
    "xgb_classification_report=classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"xgb_accuracy\\n\",xgb_accuracy)\n",
    "print(xgb_confusion_matrix)\n",
    "print(xgb_classification_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_reg=CatBoostClassifier()\n",
    "cat_reg.fit(X_train,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "cat_train_set_predictions=cat_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "cat_test_set_predictions=cat_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert y_pred to 0,1,101\n",
    "cat_test_set_predictions=np.round(cat_test_set_predictions)\n",
    "cat_test_set_predictions=le.inverse_transform(cat_test_set_predictions.astype(int))\n",
    "\n",
    "cat_accuracy=accuracy_score(y_test,cat_test_set_predictions)\n",
    "cat_confusion_matrix=confusion_matrix(y_test,cat_test_set_predictions)\n",
    "\n",
    "print(\"cat_accuracy\\n\",cat_accuracy)\n",
    "print(cat_confusion_matrix)\n",
    "print(xgb_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM  (Can't really download LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train lightgbm regression model on training set against class label\n",
    "\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "lgb_reg=lgb.LGBMRegressor()\n",
    "lgb_reg.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "lgb_train_set_predictions=lgb_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "lgb_test_set_predictions=lgb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "lgb_test_set_predictions=np.round(lgb_test_set_predictions)\n",
    "lgb_test_set_predictions=le.inverse_transform(lgb_test_set_predictions.astype(int))\n",
    "\n",
    "lgb_accuracy=accuracy_score(y_test,lgb_test_set_predictions)\n",
    "lgb_confusion_matrix=confusion_matrix(y_test,lgb_test_set_predictions)\n",
    "lgb_classification_report=classification_report(y_test,lgb_test_set_predictions)\n",
    "\n",
    "print(\"lgb_accuracy\\n\",lgb_accuracy)\n",
    "print(lgb_confusion_matrix)\n",
    "print(xgb_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare both models with f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# calculate F1 scores for both models\n",
    "logreg_f1 = f1_score(y_test, logreg_test_set_predictions, average='weighted')\n",
    "dectree_f1 = f1_score(y_test, dectree_test_set_predictions, average='weighted')\n",
    "\n",
    "# print\n",
    "print(\"F1 scores:\")\n",
    "print(\"Logistic Regression: \", logreg_f1)\n",
    "print(\"Decision Tree Regressor: \", dectree_f1)\n",
    "\n",
    "# compare F1 scores\n",
    "if logreg_f1 > dectree_f1:\n",
    "    print(\"Logistic Regression has a higher F1 score.\")\n",
    "elif logreg_f1 < dectree_f1:\n",
    "    print(\"Decision Tree has a higher F1 score.\")\n",
    "else:\n",
    "    print(\"Both models have the same F1 score.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "csv_directory='/Users/cherylong/Desktop/8_hpl_well_dataset'\n",
    "csv_files=[file for file in os.listdir(csv_directory) if file.endswith('.csv')]\n",
    "print(csv_files)\n",
    "dataframes={}\n",
    "#import csv files\n",
    "# print(csv_files)\n",
    "# path=os.path.join(os.getcwd(),'data','3')\n",
    "# csv_files=glob.glob(path + \"/*.csv\")\n",
    "\n",
    "#remove BC2406.ipynb from csv_files\n",
    "# csv_files.remove('BC2406.ipynb')\n",
    "\n",
    "# remove all files whose file name (not path) starts with SIMULATED\n",
    "#csv_files=[csv_file for csv_file in csv_files if not os.path.basename(csv_file).startswith('SIMULATED')]\n",
    "\n",
    "\n",
    "for csv_file in csv_files:\n",
    "  well_name=os.path.splitext(csv_file)[0]\n",
    "  df=pd.read_csv(os.path.join(csv_directory,csv_file))\n",
    "  dataframes[well_name]=df\n",
    "\n",
    "for well_name,df in dataframes.items():\n",
    "  df.insert(0,'name',well_name.split('_')[0])\n",
    "  df.insert(1,'id',well_name.split('_')[1])\n",
    "\n",
    "df=pd.concat(dataframes.values(),ignore_index=True)\n",
    "\n",
    "distinct_wells=df['name'].unique()\n",
    "for name in distinct_wells:\n",
    "  print(name)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#clean dataset to remove name, id, timestamp\n",
    "df=df.drop(['name','id','timestamp', 'T-JUS-CKGL','P-JUS-CKGL','QGL'],axis=1)\n",
    "\n",
    "#replace all NaN with 0\n",
    "# df=df.fillna(0)\n",
    "\n",
    "# drop all rows with class NaN\n",
    "df=df.dropna(subset=['class'])\n",
    "\n",
    "# # print NaN in any column\n",
    "\n",
    "# drop all rows where P-PDG is NaN\n",
    "df=df.dropna(subset=['P-PDG'])\n",
    "\n",
    "print(df[df.isna().any(axis=1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all values in column class\n",
    "print(df['class'].unique())\n",
    "\n",
    "# print 5 rows where class = NaN\n",
    "print(df[df['class'].isna()].head())\n",
    "\n",
    "#count number of 0, 3 in class label\n",
    "print(\"count of 0 in class label: \",len(df[df['class']==0])) # normal state\n",
    "print(\"count of NaN in class label: \",len(df[df['class'].isna()])) # NaN state\n",
    "print(\"count of 8 in class label: \",len(df[df['class']==8]))  # warning state\n",
    "print(\"count of 108 in class label: \",len(df[df['class']==108]))  # error state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop(['class'],axis=1)\n",
    "y=df['class']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "train_set,test_set=train_test_split(df,test_size=0.2,random_state=42)\n",
    "#random state shuffles the data\n",
    "\n",
    "#train linear regression model on training set against class label\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#train model on training set\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(train_set.drop('class',axis=1),train_set['class'])\n",
    "\n",
    "\n",
    "#predict class label on training set\n",
    "train_set_predictions=lin_reg.predict(train_set.drop('class',axis=1))\n",
    "lin_mse=mean_squared_error(train_set['class'],train_set_predictions)\n",
    "lin_rmse=np.sqrt(lin_mse)\n",
    "lin_mae=mean_absolute_error(train_set['class'],train_set_predictions)\n",
    "lin_r2=r2_score(train_set['class'],train_set_predictions)\n",
    "print(\"Training set RMSE: \",lin_rmse)\n",
    "print(\"Training set MAE: \",lin_mae)\n",
    "print(\"Training set R2: \",lin_r2)\n",
    "\n",
    "#predict class label on test set\n",
    "test_set_predictions=lin_reg.predict(test_set.drop('class',axis=1))\n",
    "lin_mse=mean_squared_error(test_set['class'],test_set_predictions)\n",
    "lin_rmse=np.sqrt(lin_mse)\n",
    "lin_mae=mean_absolute_error(test_set['class'],test_set_predictions)\n",
    "lin_r2=r2_score(test_set['class'],test_set_predictions)\n",
    "print(\"Test set RMSE: \",lin_rmse)\n",
    "print(\"Test set MAE: \",lin_mae)\n",
    "print(\"Test set R2: \",lin_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train logistic regression model on training set against class label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#train model on training set\n",
    "log_reg=LogisticRegression(max_iter=100000)\n",
    "log_reg.fit(X_train_scaled,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "logreg_train_set_predictions=log_reg.predict(X_train_scaled)\n",
    "\n",
    "#test model on test set\n",
    "logreg_test_set_predictions=log_reg.predict(X_test_scaled)\n",
    "log_accuracy=accuracy_score(y_test,logreg_test_set_predictions)\n",
    "log_confusion_matrix=confusion_matrix(y_test,logreg_test_set_predictions)\n",
    "log_classification_report=classification_report(y_test,logreg_test_set_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"log_accuracy\\n\",log_accuracy)\n",
    "print(log_confusion_matrix)\n",
    "print(log_classification_report)\n",
    "print(\"log_accuracy = %.1f\"%(log_accuracy*100),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree (not sure if this works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train decision tree regression model on training set against class label\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train = np.nan_to_num(X_train.astype(np.float64))\n",
    "X_test = np.nan_to_num(X_test.astype(np.float64))\n",
    "\n",
    "# check for infinite or NaN values in X_train and X_test\n",
    "if not np.isfinite(X_train).all() or not np.isfinite(X_test).all():\n",
    "    print(\"Input data contains infinite or NaN values.\")\n",
    "\n",
    "#train model on training set\n",
    "dt_reg=DecisionTreeRegressor()\n",
    "dt_reg.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "dectree_train_set_predictions=dt_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "dectree_test_set_predictions=dt_reg.predict(X_test)\n",
    "dt_mse=mean_squared_error(y_test,dectree_test_set_predictions)\n",
    "dt_rmse=np.sqrt(dt_mse)\n",
    "dt_accuracy=accuracy_score(y_test,dectree_test_set_predictions)\n",
    "dt_confusion_matrix=confusion_matrix(y_test,dectree_test_set_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dt_mse\\n\",dt_mse)\n",
    "print(\"dt_rmse\\n\",dt_rmse)\n",
    "print(\"dt_accuracy\\n\",dt_accuracy)\n",
    "print(dt_confusion_matrix)\n",
    "print(\"dt_accuracy = %.1f\"%(dt_accuracy*100),\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train xgboost regression model on training set against class label\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "xgb_class=xgb.XGBClassifier()\n",
    "xgb_class.fit(X_train_scaled,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "xgb_train_set_predictions=xgb_class.predict(X_train_scaled)\n",
    "\n",
    "#test model on test set\n",
    "y_pred=xgb_class.predict(X_test_scaled)\n",
    "\n",
    "#convert y_pred\n",
    "y_pred=np.round(y_pred)\n",
    "y_pred=le.inverse_transform(y_pred.astype(int))\n",
    "\n",
    "xgb_accuracy=accuracy_score(y_test,y_pred)\n",
    "xgb_confusion_matrix=confusion_matrix(y_test,y_pred)\n",
    "xgb_classification_report=classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"xgb_accuracy\\n\",xgb_accuracy)\n",
    "print(xgb_confusion_matrix)\n",
    "print(xgb_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train catboost regression model on training set against class label\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "cat_reg=CatBoostClassifier()\n",
    "cat_reg.fit(X_train_scaled,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "cat_train_set_predictions=cat_reg.predict(X_train_scaled)\n",
    "\n",
    "\n",
    "#test model on test set\n",
    "cat_test_set_predictions=cat_reg.predict(X_test_scaled)\n",
    "\n",
    "#convert y_pred\n",
    "cat_test_set_predictions=np.round(cat_test_set_predictions)\n",
    "cat_test_set_predictions=le.inverse_transform(cat_test_set_predictions.astype(int))\n",
    "\n",
    "cat_accuracy=accuracy_score(y_test,cat_test_set_predictions)\n",
    "cat_confusion_matrix=confusion_matrix(y_test,cat_test_set_predictions)\n",
    "cat_classification_report=classification_report(y_test,cat_test_set_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cat_accuracy\\n\",cat_accuracy)\n",
    "print(cat_confusion_matrix)\n",
    "print(cat_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune hyperparameters for catboost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "cat_reg=CatBoostClassifier()\n",
    "\n",
    "# define the grid of hyperparameters to search\n",
    "search_space = {'iterations': [100, 200, 500],\n",
    "                'learning_rate': [0.01, 0.05, 0.1],\n",
    "                'depth': [3, 5, 7]}\n",
    "# define search\n",
    "grid_search = GridSearchCV(cat_reg, search_space, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "# execute search\n",
    "grid_result = grid_search.fit(X_train_scaled, y_trainLE)\n",
    "# summarize result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM (can't install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#train lightgbm regression model on training set against class label\n",
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "lgb_reg=lgb.LGBMClassifier()\n",
    "lgb_reg.fit(X_train_scaled,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "lgb_train_set_predictions=lgb_reg.predict(X_train_scaled)\n",
    "\n",
    "#test model on test set\n",
    "lgb_test_set_predictions=lgb_reg.predict(X_test_scaled)\n",
    "\n",
    "#convert y_pred\n",
    "lgb_test_set_predictions=np.round(lgb_test_set_predictions)\n",
    "lgb_test_set_predictions=le.inverse_transform(lgb_test_set_predictions.astype(int))\n",
    "\n",
    "lgb_accuracy=accuracy_score(y_test,lgb_test_set_predictions)\n",
    "lgb_confusion_matrix=confusion_matrix(y_test,lgb_test_set_predictions)\n",
    "lgb_classification_report=classification_report(y_test,lgb_test_set_predictions)\n",
    "\n",
    "print(\"lgb_accuracy\\n\",lgb_accuracy)\n",
    "print(lgb_confusion_matrix)\n",
    "print(lgb_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune hyperparameters for lightgbm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "lgb_reg=lgb.LGBMClassifier()\n",
    "\n",
    "# define the grid of hyperparameters to search\n",
    "search_space = {'n_estimators': [100, 200, 500],\n",
    "                'learning_rate': [0.01, 0.05, 0.1],\n",
    "                'max_depth': [3, 5, 7]}\n",
    "# define search\n",
    "grid_search = GridSearchCV(lgb_reg, search_space, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "# execute search\n",
    "grid_result = grid_search.fit(X_train_scaled, y_trainLE)\n",
    "# summarize result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
