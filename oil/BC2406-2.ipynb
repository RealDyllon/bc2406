{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fgOzXxjH_iw"
   },
   "source": [
    "# BC2406 Project\n",
    "\n",
    "3 types:\n",
    "* lin reg\n",
    "* logistic reg\n",
    "* CART (dec tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import required modules\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# rest of the code\n",
    "\n",
    "#import csv files\n",
    "# print(csv_files)\n",
    "path=os.path.join(os.getcwd(),'data','3')\n",
    "csv_files=glob.glob(path + \"/*.csv\")\n",
    "\n",
    "#remove BC2406.ipynb from csv_files\n",
    "# csv_files.remove('BC2406.ipynb')\n",
    "\n",
    "# remove all files whose file name (not path) starts with SIMULATED\n",
    "csv_files=[csv_file for csv_file in csv_files if not os.path.basename(csv_file).startswith('SIMULATED')]\n",
    "\n",
    "dataframes={}\n",
    "\n",
    "print(csv_files)\n",
    "for csv_file in csv_files:\n",
    "  # print(csv_file)\n",
    "  well_name=os.path.splitext(csv_file)[0]\n",
    "  # print(\"file path\")\n",
    "  # print(os.path.join(csv_directory,csv_file))\n",
    "  df=pd.read_csv(csv_file)\n",
    "  dataframes[well_name]=df\n",
    "\n",
    "for well_name,df in dataframes.items():\n",
    "  df.insert(0,'name',well_name.split('_')[0].split('/')[-1])\n",
    "  df.insert(1,'id',well_name.split('_')[1])\n",
    "\n",
    "df=pd.concat(dataframes.values(),ignore_index=True)\n",
    "\n",
    "distinct_wells=df['name'].unique()\n",
    "for name in distinct_wells:\n",
    "  print(name)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all values in column class\n",
    "print(df['class'].unique())\n",
    "\n",
    "#count number of 0, 3 in class label\n",
    "print(\"count of 0 in class label: \",len(df[df['class']==0])) # normal state\n",
    "print(\"count of 3 in class label: \",len(df[df['class']==3]))  # warning state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()\n",
    "#clean dataset to remove name, id, timestamp\n",
    "df=df.drop(['name','id','timestamp'],axis=1)\n",
    "\n",
    "df=df.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop(['class'],axis=1)\n",
    "y=df['class']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train logistic regression model on training set against class label\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# #train model on training set\n",
    "# log_reg=LogisticRegression(max_iter=1000)\n",
    "# log_reg.fit(X_train,y_train)\n",
    "\n",
    "# #predict class label on training set\n",
    "# logreg_train_set_predictions=log_reg.predict(X_train)\n",
    "\n",
    "# #test model on test set\n",
    "# logreg_test_set_predictions=log_reg.predict(X_test)\n",
    "# log_accuracy=accuracy_score(y_test,logreg_test_set_predictions)\n",
    "# log_confusion_matrix=confusion_matrix(y_test,logreg_test_set_predictions)\n",
    "# log_classification_report=classification_report(y_test,logreg_test_set_predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 5 (Rapid Productivity Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T04:50:25.384500Z",
     "start_time": "2023-09-22T04:50:25.335250Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "pHKtXRpNq5LX",
    "outputId": "aeadf773-ad99-4bee-eb0a-38efafe4814a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00015_20171013140047.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00016_20180517222322.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00017_20140319141450.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00016_20180405020345.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00016_20180426142005.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00017_20140318160220.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00015_20170620160349.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00017_20140314180000.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00017_20140318023141.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00017_20140317151743.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00017_20140319040453.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00016_20180426145108.csv']\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00015\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00016\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:47.000000</td>\n",
       "      <td>23639730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3509006.0</td>\n",
       "      <td>42.35576</td>\n",
       "      <td>19960610.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.288151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:48.000000</td>\n",
       "      <td>23640270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3483324.0</td>\n",
       "      <td>42.35957</td>\n",
       "      <td>19978070.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.291373</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:49.000000</td>\n",
       "      <td>23640810.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3449990.0</td>\n",
       "      <td>42.36337</td>\n",
       "      <td>19995540.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.294595</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:50.000000</td>\n",
       "      <td>23641350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3416657.0</td>\n",
       "      <td>42.36717</td>\n",
       "      <td>20013010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.297816</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:51.000000</td>\n",
       "      <td>23641890.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3383324.0</td>\n",
       "      <td>42.37098</td>\n",
       "      <td>20030480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.302506</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361993</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20180426145108</td>\n",
       "      <td>2018-04-26 15:44:16.000000</td>\n",
       "      <td>24660500.0</td>\n",
       "      <td>11091050.0</td>\n",
       "      <td>16.99739</td>\n",
       "      <td>845799.3</td>\n",
       "      <td>50.32685</td>\n",
       "      <td>18913280.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.766007</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361994</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20180426145108</td>\n",
       "      <td>2018-04-26 15:44:17.000000</td>\n",
       "      <td>24660460.0</td>\n",
       "      <td>11091230.0</td>\n",
       "      <td>16.99959</td>\n",
       "      <td>845819.6</td>\n",
       "      <td>50.32632</td>\n",
       "      <td>18913740.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.736611</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361995</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20180426145108</td>\n",
       "      <td>2018-04-26 15:44:18.000000</td>\n",
       "      <td>24660420.0</td>\n",
       "      <td>11091420.0</td>\n",
       "      <td>17.00179</td>\n",
       "      <td>845840.0</td>\n",
       "      <td>50.32579</td>\n",
       "      <td>18914190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.707214</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361996</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20180426145108</td>\n",
       "      <td>2018-04-26 15:44:19.000000</td>\n",
       "      <td>24660380.0</td>\n",
       "      <td>11091610.0</td>\n",
       "      <td>17.00399</td>\n",
       "      <td>845860.3</td>\n",
       "      <td>50.32526</td>\n",
       "      <td>18914650.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.677818</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361997</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20180426145108</td>\n",
       "      <td>2018-04-26 15:44:20.000000</td>\n",
       "      <td>24660340.0</td>\n",
       "      <td>11091800.0</td>\n",
       "      <td>17.00619</td>\n",
       "      <td>845880.7</td>\n",
       "      <td>50.32472</td>\n",
       "      <td>18915110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.648421</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361998 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name              id  \\\n",
       "0       /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "1       /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "2       /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "3       /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "4       /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "...                                                   ...             ...   \n",
       "361993  /Users/dyllon/Library/Mobile Documents/com~app...  20180426145108   \n",
       "361994  /Users/dyllon/Library/Mobile Documents/com~app...  20180426145108   \n",
       "361995  /Users/dyllon/Library/Mobile Documents/com~app...  20180426145108   \n",
       "361996  /Users/dyllon/Library/Mobile Documents/com~app...  20180426145108   \n",
       "361997  /Users/dyllon/Library/Mobile Documents/com~app...  20180426145108   \n",
       "\n",
       "                         timestamp       P-PDG       P-TPT     T-TPT  \\\n",
       "0       2017-10-13 14:00:47.000000  23639730.0         0.0   0.00000   \n",
       "1       2017-10-13 14:00:48.000000  23640270.0         0.0   0.00000   \n",
       "2       2017-10-13 14:00:49.000000  23640810.0         0.0   0.00000   \n",
       "3       2017-10-13 14:00:50.000000  23641350.0         0.0   0.00000   \n",
       "4       2017-10-13 14:00:51.000000  23641890.0         0.0   0.00000   \n",
       "...                            ...         ...         ...       ...   \n",
       "361993  2018-04-26 15:44:16.000000  24660500.0  11091050.0  16.99739   \n",
       "361994  2018-04-26 15:44:17.000000  24660460.0  11091230.0  16.99959   \n",
       "361995  2018-04-26 15:44:18.000000  24660420.0  11091420.0  17.00179   \n",
       "361996  2018-04-26 15:44:19.000000  24660380.0  11091610.0  17.00399   \n",
       "361997  2018-04-26 15:44:20.000000  24660340.0  11091800.0  17.00619   \n",
       "\n",
       "        P-MON-CKP  T-JUS-CKP  P-JUS-CKGL  T-JUS-CKGL       QGL  class  \n",
       "0       3509006.0   42.35576  19960610.0         NaN  1.288151    0.0  \n",
       "1       3483324.0   42.35957  19978070.0         NaN  1.291373    0.0  \n",
       "2       3449990.0   42.36337  19995540.0         NaN  1.294595    0.0  \n",
       "3       3416657.0   42.36717  20013010.0         NaN  1.297816    0.0  \n",
       "4       3383324.0   42.37098  20030480.0         NaN  1.302506    0.0  \n",
       "...           ...        ...         ...         ...       ...    ...  \n",
       "361993   845799.3   50.32685  18913280.0         NaN  1.766007    5.0  \n",
       "361994   845819.6   50.32632  18913740.0         NaN  1.736611    5.0  \n",
       "361995   845840.0   50.32579  18914190.0         NaN  1.707214    5.0  \n",
       "361996   845860.3   50.32526  18914650.0         NaN  1.677818    5.0  \n",
       "361997   845880.7   50.32472  18915110.0         NaN  1.648421    5.0  \n",
       "\n",
       "[361998 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#import csv files\n",
    "# print(csv_files)\n",
    "path=os.path.join(os.getcwd(),'data','5')\n",
    "csv_files=glob.glob(path + \"/*.csv\")\n",
    "\n",
    "#remove BC2406.ipynb from csv_files\n",
    "# csv_files.remove('BC2406.ipynb')\n",
    "\n",
    "dataframes={}\n",
    "\n",
    "print(csv_files)\n",
    "for csv_file in csv_files:\n",
    "  # print(csv_file)\n",
    "  well_name=os.path.splitext(csv_file)[0]\n",
    "  # print(\"file path\")\n",
    "  # print(os.path.join(csv_directory,csv_file))\n",
    "  df=pd.read_csv(csv_file)\n",
    "  dataframes[well_name]=df\n",
    "\n",
    "for well_name,df in dataframes.items():\n",
    "  df.insert(0,'name',well_name.split('_')[0])\n",
    "  df.insert(1,'id',well_name.split('_')[1])\n",
    "\n",
    "df=pd.concat(dataframes.values(),ignore_index=True)\n",
    "\n",
    "distinct_wells=df['name'].unique()\n",
    "for name in distinct_wells:\n",
    "  print(name)\n",
    "\n",
    "df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Yh4MOPXnycvE",
    "outputId": "b8d4d1e1-ab7b-4018-fa87-1768072034c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:47.000000</td>\n",
       "      <td>23639730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3509006.0</td>\n",
       "      <td>42.35576</td>\n",
       "      <td>19960610.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.288151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:48.000000</td>\n",
       "      <td>23640270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3483324.0</td>\n",
       "      <td>42.35957</td>\n",
       "      <td>19978070.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.291373</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:49.000000</td>\n",
       "      <td>23640810.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3449990.0</td>\n",
       "      <td>42.36337</td>\n",
       "      <td>19995540.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.294595</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:50.000000</td>\n",
       "      <td>23641350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3416657.0</td>\n",
       "      <td>42.36717</td>\n",
       "      <td>20013010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.297816</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:51.000000</td>\n",
       "      <td>23641890.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3383324.0</td>\n",
       "      <td>42.37098</td>\n",
       "      <td>20030480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.302506</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name              id  \\\n",
       "0  /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "1  /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "2  /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "3  /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "4  /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "\n",
       "                    timestamp       P-PDG  P-TPT  T-TPT  P-MON-CKP  T-JUS-CKP  \\\n",
       "0  2017-10-13 14:00:47.000000  23639730.0    0.0    0.0  3509006.0   42.35576   \n",
       "1  2017-10-13 14:00:48.000000  23640270.0    0.0    0.0  3483324.0   42.35957   \n",
       "2  2017-10-13 14:00:49.000000  23640810.0    0.0    0.0  3449990.0   42.36337   \n",
       "3  2017-10-13 14:00:50.000000  23641350.0    0.0    0.0  3416657.0   42.36717   \n",
       "4  2017-10-13 14:00:51.000000  23641890.0    0.0    0.0  3383324.0   42.37098   \n",
       "\n",
       "   P-JUS-CKGL  T-JUS-CKGL       QGL  class  \n",
       "0  19960610.0         NaN  1.288151    0.0  \n",
       "1  19978070.0         NaN  1.291373    0.0  \n",
       "2  19995540.0         NaN  1.294595    0.0  \n",
       "3  20013010.0         NaN  1.297816    0.0  \n",
       "4  20030480.0         NaN  1.302506    0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T04:36:10.826099Z",
     "start_time": "2023-09-22T04:36:10.619736Z"
    },
    "id": "zgQmxqNA3EIU"
   },
   "outputs": [],
   "source": [
    "df.dropna()\n",
    "#clean dataset to remove name, id, timestamp\n",
    "df=df.drop(['name','id','timestamp'],axis=1)\n",
    "\n",
    "#replace all NaN with 0\n",
    "df=df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of 0 in class label 33693\n",
      "count of 5 in class label 10147\n",
      "count of 105 in class label 318158\n"
     ]
    }
   ],
   "source": [
    "#count number of 0, 5 and 105 in class label\n",
    "print(\"count of 0 in class label\",len(df[df['class']==0])) # normal state\n",
    "print(\"count of 5 in class label\",len(df[df['class']==5]))  # warning state\n",
    "print(\"count of 105 in class label\",len(df[df['class']==105])) # abnormal state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop(['class'],axis=1)\n",
    "y=df['class']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train logistic regression model on training set against class label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#train model on training set\n",
    "log_reg=LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "logreg_train_set_predictions=log_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "logreg_test_set_predictions=log_reg.predict(X_test)\n",
    "log_accuracy=accuracy_score(y_test,logreg_test_set_predictions)\n",
    "log_confusion_matrix=confusion_matrix(y_test,logreg_test_set_predictions)\n",
    "log_classification_report=classification_report(y_test,logreg_test_set_predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"log_accuracy\\n\",log_accuracy)\n",
    "print(log_confusion_matrix)\n",
    "print(log_classification_report)\n",
    "print(\"log_accuracy = %.1f\"%(log_accuracy*100),\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train decision tree regression model on training set against class label\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "#train model on training set\n",
    "dt_reg=DecisionTreeRegressor()\n",
    "dt_reg.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "dectree_train_set_predictions=dt_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "dectree_test_set_predictions=dt_reg.predict(X_test)\n",
    "dt_mse=mean_squared_error(y_test,dectree_test_set_predictions)\n",
    "dt_rmse=np.sqrt(dt_mse)\n",
    "dt_accuracy=accuracy_score(y_test,dectree_test_set_predictions)\n",
    "dt_confusion_matrix=confusion_matrix(y_test,dectree_test_set_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dt_mse\\n\",dt_mse)\n",
    "print(\"dt_rmse\\n\",dt_rmse)\n",
    "print(\"dt_accuracy\\n\",dt_accuracy)\n",
    "print(dt_confusion_matrix)\n",
    "print(\"dt_accuracy = %.1f\"%(dt_accuracy*100),\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add rolling mean and rolling standard deviation\n",
    "\n",
    "make ensemble model ?\n",
    "\n",
    "hyperparam fine tuning (ie optuna)\n",
    "\n",
    "wrap with flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg=xgb.XGBRegressor()\n",
    "xgb_reg.fit(X_train,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "xgb_train_set_predictions=xgb_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "y_pred=xgb_reg.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train logistic regression model on training set against class label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#convert y_pred to 0,5,105\n",
    "y_pred=np.round(y_pred)\n",
    "y_pred=le.inverse_transform(y_pred.astype(int))\n",
    "\n",
    "xgb_accuracy=accuracy_score(y_test,y_pred)\n",
    "xgb_confusion_matrix=confusion_matrix(y_test,y_pred)\n",
    "xgb_classification_report=classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"xgb_accuracy\\n\",xgb_accuracy)\n",
    "print(xgb_confusion_matrix)\n",
    "print(xgb_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --no-build-isolation catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cat_reg=CatBoostRegressor()\n",
    "cat_reg.fit(X_train,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "cat_train_set_predictions=cat_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "cat_test_set_predictions=cat_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert y_pred to 0,5,105\n",
    "cat_test_set_predictions=np.round(cat_test_set_predictions)\n",
    "cat_test_set_predictions=le.inverse_transform(cat_test_set_predictions.astype(int))\n",
    "\n",
    "cat_accuracy=accuracy_score(y_test,cat_test_set_predictions)\n",
    "cat_confusion_matrix=confusion_matrix(y_test,cat_test_set_predictions)\n",
    "\n",
    "print(\"cat_accuracy\\n\",cat_accuracy)\n",
    "print(cat_confusion_matrix)\n",
    "print(xgb_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train lightgbm regression model on training set against class label\n",
    "\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "lgb_reg=lgb.LGBMRegressor()\n",
    "lgb_reg.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "lgb_train_set_predictions=lgb_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "lgb_test_set_predictions=lgb_reg.predict(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_test_set_predictions=np.round(lgb_test_set_predictions)\n",
    "lgb_test_set_predictions=le.inverse_transform(lgb_test_set_predictions.astype(int))\n",
    "\n",
    "lgb_accuracy=accuracy_score(y_test,lgb_test_set_predictions)\n",
    "lgb_confusion_matrix=confusion_matrix(y_test,lgb_test_set_predictions)\n",
    "lgb_classification_report=classification_report(y_test,lgb_test_set_predictions)\n",
    "\n",
    "print(\"lgb_accuracy\\n\",lgb_accuracy)\n",
    "print(lgb_confusion_matrix)\n",
    "print(xgb_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare both models with f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# calculate F1 scores for both models\n",
    "logreg_f1 = f1_score(y_test, logreg_test_set_predictions, average='weighted')\n",
    "dectree_f1 = f1_score(y_test, dectree_test_set_predictions, average='weighted')\n",
    "\n",
    "# print\n",
    "print(\"F1 scores:\")\n",
    "print(\"Logistic Regression: \", logreg_f1)\n",
    "print(\"Decision Tree Regressor: \", dectree_f1)\n",
    "\n",
    "# compare F1 scores\n",
    "if logreg_f1 > dectree_f1:\n",
    "    print(\"Logistic Regression has a higher F1 score.\")\n",
    "elif logreg_f1 < dectree_f1:\n",
    "    print(\"Decision Tree has a higher F1 score.\")\n",
    "else:\n",
    "    print(\"Both models have the same F1 score.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#import csv files\n",
    "# print(csv_files)\n",
    "path=os.path.join(os.getcwd(),'data','7')\n",
    "csv_files=glob.glob(path + \"/*.csv\")\n",
    "\n",
    "#remove BC2406.ipynb from csv_files\n",
    "# csv_files.remove('BC2406.ipynb')\n",
    "\n",
    "# remove all files whose file name (not path) starts with SIMULATED\n",
    "csv_files=[csv_file for csv_file in csv_files if not os.path.basename(csv_file).startswith('DRAWN')]\n",
    "\n",
    "dataframes={}\n",
    "\n",
    "print(csv_files)\n",
    "for csv_file in csv_files:\n",
    "  # print(csv_file)\n",
    "  well_name=os.path.splitext(csv_file)[0]\n",
    "  # print(\"file path\")\n",
    "  # print(os.path.join(csv_directory,csv_file))\n",
    "  df=pd.read_csv(csv_file)\n",
    "  dataframes[well_name]=df\n",
    "\n",
    "for well_name,df in dataframes.items():\n",
    "  df.insert(0,'name',well_name.split('_')[0].split('/')[-1])\n",
    "  df.insert(1,'id',well_name.split('_')[1])\n",
    "\n",
    "df=pd.concat(dataframes.values(),ignore_index=True)\n",
    "\n",
    "distinct_wells=df['name'].unique()\n",
    "for name in distinct_wells:\n",
    "  print(name)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()\n",
    "#clean dataset to remove name, id, timestamp\n",
    "df=df.drop(['name','id','timestamp', 'T-JUS-CKGL'],axis=1)\n",
    "\n",
    "#replace all NaN with 0\n",
    "# df=df.fillna(0)\n",
    "\n",
    "# drop all rows with class NaN\n",
    "df=df.dropna(subset=['class'])\n",
    "\n",
    "# print NaN in any column\n",
    "\n",
    "# drop all rows where P-PDG is NaN\n",
    "df=df.dropna(subset=['P-PDG'])\n",
    "\n",
    "print(df[df.isna().any(axis=1)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all values in column class\n",
    "print(df['class'].unique())\n",
    "\n",
    "# print 5 rows where class = NaN\n",
    "print(df[df['class'].isna()].head())\n",
    "\n",
    "#count number of 0, 3 in class label\n",
    "print(\"count of 0 in class label: \",len(df[df['class']==0])) # normal state\n",
    "print(\"count of NaN in class label: \",len(df[df['class'].isna()])) # normal state\n",
    "print(\"count of 7 in class label: \",len(df[df['class']==7]))  # warning state\n",
    "print(\"count of 107 in class label: \",len(df[df['class']==107]))  # error state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop(['class'],axis=1)\n",
    "y=df['class']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train logistic regression model on training set against class label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#train model on training set\n",
    "log_reg=LogisticRegression(max_iter=100000)\n",
    "log_reg.fit(X_train_scaled,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "logreg_train_set_predictions=log_reg.predict(X_train_scaled)\n",
    "\n",
    "#test model on test set\n",
    "logreg_test_set_predictions=log_reg.predict(X_test_scaled)\n",
    "log_accuracy=accuracy_score(y_test,logreg_test_set_predictions)\n",
    "log_confusion_matrix=confusion_matrix(y_test,logreg_test_set_predictions)\n",
    "log_classification_report=classification_report(y_test,logreg_test_set_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"log_accuracy\\n\",log_accuracy)\n",
    "print(log_confusion_matrix)\n",
    "print(log_classification_report)\n",
    "print(\"log_accuracy = %.1f\"%(log_accuracy*100),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train decision tree regression model on training set against class label\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train = np.nan_to_num(X_train.astype(np.float64))\n",
    "X_test = np.nan_to_num(X_test.astype(np.float64))\n",
    "\n",
    "# check for infinite or NaN values in X_train and X_test\n",
    "if not np.isfinite(X_train).all() or not np.isfinite(X_test).all():\n",
    "    print(\"Input data contains infinite or NaN values.\")\n",
    "\n",
    "#train model on training set\n",
    "dt_reg=DecisionTreeRegressor()\n",
    "dt_reg.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "dectree_train_set_predictions=dt_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "dectree_test_set_predictions=dt_reg.predict(X_test)\n",
    "dt_mse=mean_squared_error(y_test,dectree_test_set_predictions)\n",
    "dt_rmse=np.sqrt(dt_mse)\n",
    "dt_accuracy=accuracy_score(y_test,dectree_test_set_predictions)\n",
    "dt_confusion_matrix=confusion_matrix(y_test,dectree_test_set_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dt_mse\\n\",dt_mse)\n",
    "print(\"dt_rmse\\n\",dt_rmse)\n",
    "print(\"dt_accuracy\\n\",dt_accuracy)\n",
    "print(dt_confusion_matrix)\n",
    "print(\"dt_accuracy = %.1f\"%(dt_accuracy*100),\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
