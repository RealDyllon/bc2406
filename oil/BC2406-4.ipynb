{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fgOzXxjH_iw"
   },
   "source": [
    "# BC2406 Project\n",
    "\n",
    "3 types:\n",
    "* lin reg\n",
    "* logistic reg\n",
    "* CART (dec tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yq/y019q7w56tjfl0mnh_pf1rtc0000gn/T/ipykernel_39140/3329494568.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwell_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mdistinct_wells\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \"\"\"\n\u001b[0;32m--> 294\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import csv files\n",
    "# print(csv_files)\n",
    "path=os.path.join(os.getcwd(),'data','1')\n",
    "csv_files=glob.glob(path + \"/*.csv\")\n",
    "\n",
    "#remove BC2406.ipynb from csv_files\n",
    "# csv_files.remove('BC2406.ipynb')\n",
    "\n",
    "# remove all files whose file name (not path) starts with SIMULATED\n",
    "csv_files=[csv_file for csv_file in csv_files if not os.path.basename(csv_file).startswith('SIMULATED')]\n",
    "\n",
    "dataframes={}\n",
    "\n",
    "print(csv_files)\n",
    "for csv_file in csv_files:\n",
    "  # print(csv_file)\n",
    "  well_name=os.path.splitext(csv_file)[0]\n",
    "  # print(\"file path\")\n",
    "  # print(os.path.join(csv_directory,csv_file))\n",
    "\n",
    "  df = pd.read_csv(csv_file)\n",
    "  # df_test = pd.read_csv(csv_file, nrows=100)\n",
    "\n",
    "  # float_cols = [c for c in df_test if df_test[c].dtype == \"float64\"]\n",
    "  # float32_cols = {c: np.float32 for c in float_cols}\n",
    "\n",
    "  # df=pd.read_csv(csv_file, engine='c', dtype=float32_cols)\n",
    "  dataframes[well_name]=df\n",
    "\n",
    "for well_name,df in dataframes.items():\n",
    "  df.insert(0,'name',well_name.split('_')[0].split('/')[-1])\n",
    "  df.insert(1,'id',well_name.split('_')[1])\n",
    "\n",
    "df=pd.concat(dataframes.values(),ignore_index=True)\n",
    "\n",
    "distinct_wells=df['name'].unique()\n",
    "for name in distinct_wells:\n",
    "  print(name)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>DRAWN</td>\n",
       "      <td>00001</td>\n",
       "      <td>2014-01-24 21:31:36.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>1.907455e+01</td>\n",
       "      <td>5.710797</td>\n",
       "      <td>1.004756e+01</td>\n",
       "      <td>30.03085</td>\n",
       "      <td>-300917.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180618060245</td>\n",
       "      <td>2018-09-07 20:44:35.000000</td>\n",
       "      <td>4.485805e+07</td>\n",
       "      <td>2.078746e+07</td>\n",
       "      <td>123.600300</td>\n",
       "      <td>1.011330e+07</td>\n",
       "      <td>173.09610</td>\n",
       "      <td>4600253.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name              id                   timestamp         P-PDG  \\\n",
       "min       DRAWN           00001  2014-01-24 21:31:36.000000 -1.180116e+42   \n",
       "max  WELL-00006  20180618060245  2018-09-07 20:44:35.000000  4.485805e+07   \n",
       "\n",
       "            P-TPT       T-TPT     P-MON-CKP  T-JUS-CKP  P-JUS-CKGL  \\\n",
       "min  1.907455e+01    5.710797  1.004756e+01   30.03085   -300917.8   \n",
       "max  2.078746e+07  123.600300  1.011330e+07  173.09610   4600253.0   \n",
       "\n",
       "     T-JUS-CKGL  QGL  class  \n",
       "min         NaN  0.0    0.0  \n",
       "max         NaN  0.0  101.0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59256</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180618060245</td>\n",
       "      <td>2018-06-18 06:02:45.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>20787460.0</td>\n",
       "      <td>117.9124</td>\n",
       "      <td>10085640.0</td>\n",
       "      <td>70.86996</td>\n",
       "      <td>4096358.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59257</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180618060245</td>\n",
       "      <td>2018-06-18 06:02:46.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>20787460.0</td>\n",
       "      <td>117.9123</td>\n",
       "      <td>10085720.0</td>\n",
       "      <td>70.86991</td>\n",
       "      <td>4096360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59258</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180618060245</td>\n",
       "      <td>2018-06-18 06:02:47.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>20787460.0</td>\n",
       "      <td>117.9122</td>\n",
       "      <td>10085810.0</td>\n",
       "      <td>70.86987</td>\n",
       "      <td>4096363.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59259</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180618060245</td>\n",
       "      <td>2018-06-18 06:02:48.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>20787460.0</td>\n",
       "      <td>117.9120</td>\n",
       "      <td>10085930.0</td>\n",
       "      <td>70.86981</td>\n",
       "      <td>4096365.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59260</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180618060245</td>\n",
       "      <td>2018-06-18 06:02:49.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>20787460.0</td>\n",
       "      <td>117.9119</td>\n",
       "      <td>10086050.0</td>\n",
       "      <td>70.86977</td>\n",
       "      <td>4096367.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76216</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180618060245</td>\n",
       "      <td>2018-06-18 10:45:25.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>20619450.0</td>\n",
       "      <td>118.2390</td>\n",
       "      <td>9992133.0</td>\n",
       "      <td>71.26657</td>\n",
       "      <td>4108511.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76217</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180618060245</td>\n",
       "      <td>2018-06-18 10:45:26.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>20619480.0</td>\n",
       "      <td>118.2390</td>\n",
       "      <td>9992676.0</td>\n",
       "      <td>71.26487</td>\n",
       "      <td>4108512.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76218</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180618060245</td>\n",
       "      <td>2018-06-18 10:45:27.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>20619520.0</td>\n",
       "      <td>118.2390</td>\n",
       "      <td>9993218.0</td>\n",
       "      <td>71.26317</td>\n",
       "      <td>4108512.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76219</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180618060245</td>\n",
       "      <td>2018-06-18 10:45:28.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>20619550.0</td>\n",
       "      <td>118.2390</td>\n",
       "      <td>9993761.0</td>\n",
       "      <td>71.26147</td>\n",
       "      <td>4108512.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76220</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180618060245</td>\n",
       "      <td>2018-06-18 10:45:29.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>20619590.0</td>\n",
       "      <td>118.2390</td>\n",
       "      <td>9994304.0</td>\n",
       "      <td>71.25977</td>\n",
       "      <td>4108513.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16965 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name              id                   timestamp         P-PDG  \\\n",
       "59256  WELL-00006  20180618060245  2018-06-18 06:02:45.000000 -1.180116e+42   \n",
       "59257  WELL-00006  20180618060245  2018-06-18 06:02:46.000000 -1.180116e+42   \n",
       "59258  WELL-00006  20180618060245  2018-06-18 06:02:47.000000 -1.180116e+42   \n",
       "59259  WELL-00006  20180618060245  2018-06-18 06:02:48.000000 -1.180116e+42   \n",
       "59260  WELL-00006  20180618060245  2018-06-18 06:02:49.000000 -1.180116e+42   \n",
       "...           ...             ...                         ...           ...   \n",
       "76216  WELL-00006  20180618060245  2018-06-18 10:45:25.000000 -1.180116e+42   \n",
       "76217  WELL-00006  20180618060245  2018-06-18 10:45:26.000000 -1.180116e+42   \n",
       "76218  WELL-00006  20180618060245  2018-06-18 10:45:27.000000 -1.180116e+42   \n",
       "76219  WELL-00006  20180618060245  2018-06-18 10:45:28.000000 -1.180116e+42   \n",
       "76220  WELL-00006  20180618060245  2018-06-18 10:45:29.000000 -1.180116e+42   \n",
       "\n",
       "            P-TPT     T-TPT   P-MON-CKP  T-JUS-CKP  P-JUS-CKGL  T-JUS-CKGL  \\\n",
       "59256  20787460.0  117.9124  10085640.0   70.86996   4096358.0         NaN   \n",
       "59257  20787460.0  117.9123  10085720.0   70.86991   4096360.0         NaN   \n",
       "59258  20787460.0  117.9122  10085810.0   70.86987   4096363.0         NaN   \n",
       "59259  20787460.0  117.9120  10085930.0   70.86981   4096365.0         NaN   \n",
       "59260  20787460.0  117.9119  10086050.0   70.86977   4096367.0         NaN   \n",
       "...           ...       ...         ...        ...         ...         ...   \n",
       "76216  20619450.0  118.2390   9992133.0   71.26657   4108511.0         NaN   \n",
       "76217  20619480.0  118.2390   9992676.0   71.26487   4108512.0         NaN   \n",
       "76218  20619520.0  118.2390   9993218.0   71.26317   4108512.0         NaN   \n",
       "76219  20619550.0  118.2390   9993761.0   71.26147   4108512.0         NaN   \n",
       "76220  20619590.0  118.2390   9994304.0   71.25977   4108513.0         NaN   \n",
       "\n",
       "       QGL  class  \n",
       "59256  0.0    0.0  \n",
       "59257  0.0    0.0  \n",
       "59258  0.0    0.0  \n",
       "59259  0.0    0.0  \n",
       "59260  0.0    0.0  \n",
       "...    ...    ...  \n",
       "76216  0.0  101.0  \n",
       "76217  0.0  101.0  \n",
       "76218  0.0  101.0  \n",
       "76219  0.0  101.0  \n",
       "76220  0.0  101.0  \n",
       "\n",
       "[16965 rows x 12 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print rows where P-PDG is less than 1e+07\n",
    "df[df['P-PDG']<-1e+07]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:134: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>DRAWN</td>\n",
       "      <td>00001</td>\n",
       "      <td>2014-01-24 21:31:36.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>1.907455e+01</td>\n",
       "      <td>5.710797</td>\n",
       "      <td>1.004756e+01</td>\n",
       "      <td>30.030849</td>\n",
       "      <td>-3.009178e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180618060245</td>\n",
       "      <td>2018-09-07 20:44:35.000000</td>\n",
       "      <td>44858048.0</td>\n",
       "      <td>2.078746e+07</td>\n",
       "      <td>123.600304</td>\n",
       "      <td>1.011330e+07</td>\n",
       "      <td>173.096100</td>\n",
       "      <td>4.600253e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name              id                   timestamp       P-PDG  \\\n",
       "min       DRAWN           00001  2014-01-24 21:31:36.000000        -inf   \n",
       "max  WELL-00006  20180618060245  2018-09-07 20:44:35.000000  44858048.0   \n",
       "\n",
       "            P-TPT       T-TPT     P-MON-CKP   T-JUS-CKP    P-JUS-CKGL  \\\n",
       "min  1.907455e+01    5.710797  1.004756e+01   30.030849 -3.009178e+05   \n",
       "max  2.078746e+07  123.600304  1.011330e+07  173.096100  4.600253e+06   \n",
       "\n",
       "     T-JUS-CKGL  QGL  class  \n",
       "min         NaN  0.0    0.0  \n",
       "max         NaN  0.0  101.0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert df columns with float64 to float32\n",
    "float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "float32_cols = {c: np.float32 for c in float_cols}\n",
    "df=df.astype(float32_cols)\n",
    "df.agg([\"min\", \"max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>DRAWN</td>\n",
       "      <td>00001</td>\n",
       "      <td>2014-01-24 21:31:36.000000</td>\n",
       "      <td>-10000000.0</td>\n",
       "      <td>1.907455e+01</td>\n",
       "      <td>5.710797</td>\n",
       "      <td>1.004756e+01</td>\n",
       "      <td>30.030849</td>\n",
       "      <td>-3.009178e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180618060245</td>\n",
       "      <td>2018-09-07 20:44:35.000000</td>\n",
       "      <td>44858048.0</td>\n",
       "      <td>2.078746e+07</td>\n",
       "      <td>123.600304</td>\n",
       "      <td>1.011330e+07</td>\n",
       "      <td>173.096100</td>\n",
       "      <td>4.600253e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name              id                   timestamp       P-PDG  \\\n",
       "min       DRAWN           00001  2014-01-24 21:31:36.000000 -10000000.0   \n",
       "max  WELL-00006  20180618060245  2018-09-07 20:44:35.000000  44858048.0   \n",
       "\n",
       "            P-TPT       T-TPT     P-MON-CKP   T-JUS-CKP    P-JUS-CKGL  \\\n",
       "min  1.907455e+01    5.710797  1.004756e+01   30.030849 -3.009178e+05   \n",
       "max  2.078746e+07  123.600304  1.011330e+07  173.096100  4.600253e+06   \n",
       "\n",
       "     T-JUS-CKGL  QGL  class  \n",
       "min         NaN  0.0    0.0  \n",
       "max         NaN  0.0  101.0  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace all values of P-PDG less than -1e+07 with -1e+07\n",
    "df.loc[df['P-PDG']<-1e+07,'P-PDG']=-1e+07\n",
    "\n",
    "df.agg([\"min\", \"max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0. 101.   1.  nan]\n",
      "count of 0 in class label:  119319\n",
      "count of 1 in class label:  33261\n",
      "count of 101 in class label:  511895\n"
     ]
    }
   ],
   "source": [
    "# show all values in column class\n",
    "print(df['class'].unique())\n",
    "\n",
    "#count number of 0, 3 in class label\n",
    "print(\"count of 0 in class label: \",len(df[df['class']==0])) # normal state\n",
    "print(\"count of 1 in class label: \",len(df[df['class']==1]))  # warning state\n",
    "print(\"count of 101 in class label: \",len(df[df['class']==101]))  # warning state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()\n",
    "#clean dataset to remove name, id, timestamp\n",
    "df=df.drop(['name','id','timestamp'],axis=1)\n",
    "\n",
    "df=df.fillna(0)\n",
    "\n",
    "df.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop(['class'],axis=1)\n",
    "y=df['class']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-PDG         float32\n",
      "P-TPT         float32\n",
      "T-TPT         float32\n",
      "P-MON-CKP     float32\n",
      "T-JUS-CKP     float32\n",
      "P-JUS-CKGL    float32\n",
      "T-JUS-CKGL    float32\n",
      "QGL           float32\n",
      "class         float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_accuracy\n",
      " 0.04702362262896404\n",
      "[[ 2546     0     0]\n",
      " [  162     0     0]\n",
      " [51435     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.05      1.00      0.09      2546\n",
      "         7.0       0.00      0.00      0.00       162\n",
      "       107.0       0.00      0.00      0.00     51435\n",
      "\n",
      "    accuracy                           0.05     54143\n",
      "   macro avg       0.02      0.33      0.03     54143\n",
      "weighted avg       0.00      0.05      0.00     54143\n",
      "\n",
      "log_accuracy = 4.7 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamiegoh/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jamiegoh/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jamiegoh/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jamiegoh/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#train logistic regression model on training set against class label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#train model on training set\n",
    "log_reg=LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "logreg_train_set_predictions=log_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "logreg_test_set_predictions=log_reg.predict(X_test)\n",
    "log_accuracy=accuracy_score(y_test,logreg_test_set_predictions)\n",
    "log_confusion_matrix=confusion_matrix(y_test,logreg_test_set_predictions)\n",
    "log_classification_report=classification_report(y_test,logreg_test_set_predictions)\n",
    "\n",
    "print(\"log_accuracy\\n\",log_accuracy)\n",
    "print(log_confusion_matrix)\n",
    "print(log_classification_report)\n",
    "print(\"log_accuracy = %.1f\"%(log_accuracy*100),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-PDG         float64\n",
      "P-TPT         float64\n",
      "T-TPT         float64\n",
      "P-MON-CKP     float64\n",
      "T-JUS-CKP     float64\n",
      "P-JUS-CKGL    float64\n",
      "QGL           float64\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yq/y019q7w56tjfl0mnh_pf1rtc0000gn/T/ipykernel_39922/3214190178.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#train model on training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdt_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdt_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \"\"\"\n\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    904\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             X, y = self._validate_data(X, y,\n\u001b[0m\u001b[1;32m    158\u001b[0m                                        validate_separately=(check_X_params,\n\u001b[1;32m    159\u001b[0m                                                             check_y_params))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;31m# :(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "#train decision tree regression model on training set against class label\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "print(X_train.dtypes)\n",
    "\n",
    "#train model on training set\n",
    "dt_class=DecisionTreeClassifier()\n",
    "dt_class.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#predict class label on training set\n",
    "dectree_train_set_predictions=dt_class.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "dectree_test_set_predictions=dt_class.predict(X_test)\n",
    "dt_mse=mean_squared_error(y_test,dectree_test_set_predictions)\n",
    "dt_rmse=np.sqrt(dt_mse)\n",
    "dt_accuracy=accuracy_score(y_test,dectree_test_set_predictions)\n",
    "dt_confusion_matrix=confusion_matrix(y_test,dectree_test_set_predictions)\n",
    "\n",
    "print(\"dt_mse\\n\",dt_mse)\n",
    "print(\"dt_rmse\\n\",dt_rmse)\n",
    "print(\"dt_accuracy\\n\",dt_accuracy)\n",
    "print(dt_confusion_matrix)\n",
    "print(\"dt_accuracy = %.1f\"%(dt_accuracy*100),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170921200114.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170925160218.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170926170228.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170920010042.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170920060228.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170921050404.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170921100155.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00001_20170320130025.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170920110053.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170922060124.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170926020340.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20171028130000.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170925210042.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20171028080000.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170921000053.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170919210016.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170925060042.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20171028180038.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170920190207.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170925010031.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170918020114.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170917200000.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170926070042.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170922010042.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170922110042.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170918120103.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170921150042.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170926120103.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170918070135.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170922160249.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170925110124.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/3/WELL-00014_20170917150000.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WELL-00014\n",
      "WELL-00001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WELL-00014</td>\n",
       "      <td>20170921200114</td>\n",
       "      <td>2017-09-21 20:01:14.000000</td>\n",
       "      <td>24389400.0</td>\n",
       "      <td>15923800.0</td>\n",
       "      <td>43.65952</td>\n",
       "      <td>1490977.0</td>\n",
       "      <td>31.00947</td>\n",
       "      <td>19415620.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.243595</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WELL-00014</td>\n",
       "      <td>20170921200114</td>\n",
       "      <td>2017-09-21 20:01:15.000000</td>\n",
       "      <td>24388900.0</td>\n",
       "      <td>15923280.0</td>\n",
       "      <td>43.65860</td>\n",
       "      <td>1492114.0</td>\n",
       "      <td>31.00781</td>\n",
       "      <td>19415860.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.239152</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WELL-00014</td>\n",
       "      <td>20170921200114</td>\n",
       "      <td>2017-09-21 20:01:16.000000</td>\n",
       "      <td>24388410.0</td>\n",
       "      <td>15922750.0</td>\n",
       "      <td>43.65767</td>\n",
       "      <td>1493250.0</td>\n",
       "      <td>31.00614</td>\n",
       "      <td>19416100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.234708</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WELL-00014</td>\n",
       "      <td>20170921200114</td>\n",
       "      <td>2017-09-21 20:01:17.000000</td>\n",
       "      <td>24388120.0</td>\n",
       "      <td>15921120.0</td>\n",
       "      <td>43.65464</td>\n",
       "      <td>1494386.0</td>\n",
       "      <td>31.00448</td>\n",
       "      <td>19416350.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.230265</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WELL-00014</td>\n",
       "      <td>20170921200114</td>\n",
       "      <td>2017-09-21 20:01:18.000000</td>\n",
       "      <td>24387820.0</td>\n",
       "      <td>15919480.0</td>\n",
       "      <td>43.65160</td>\n",
       "      <td>1495523.0</td>\n",
       "      <td>31.00282</td>\n",
       "      <td>19416590.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.225821</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569147</th>\n",
       "      <td>WELL-00014</td>\n",
       "      <td>20170917150000</td>\n",
       "      <td>2017-09-17 19:56:11.000000</td>\n",
       "      <td>23525310.0</td>\n",
       "      <td>13954990.0</td>\n",
       "      <td>56.54493</td>\n",
       "      <td>1893704.0</td>\n",
       "      <td>38.29067</td>\n",
       "      <td>19560470.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.265560</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569148</th>\n",
       "      <td>WELL-00014</td>\n",
       "      <td>20170917150000</td>\n",
       "      <td>2017-09-17 19:56:12.000000</td>\n",
       "      <td>23525260.0</td>\n",
       "      <td>13955230.0</td>\n",
       "      <td>56.54481</td>\n",
       "      <td>1894765.0</td>\n",
       "      <td>38.29134</td>\n",
       "      <td>19561440.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.278255</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569149</th>\n",
       "      <td>WELL-00014</td>\n",
       "      <td>20170917150000</td>\n",
       "      <td>2017-09-17 19:56:13.000000</td>\n",
       "      <td>23525200.0</td>\n",
       "      <td>13955470.0</td>\n",
       "      <td>56.54469</td>\n",
       "      <td>1895825.0</td>\n",
       "      <td>38.29200</td>\n",
       "      <td>19562410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.290949</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569150</th>\n",
       "      <td>WELL-00014</td>\n",
       "      <td>20170917150000</td>\n",
       "      <td>2017-09-17 19:56:14.000000</td>\n",
       "      <td>23525150.0</td>\n",
       "      <td>13955710.0</td>\n",
       "      <td>56.54458</td>\n",
       "      <td>1896431.0</td>\n",
       "      <td>38.29267</td>\n",
       "      <td>19563380.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.303643</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569151</th>\n",
       "      <td>WELL-00014</td>\n",
       "      <td>20170917150000</td>\n",
       "      <td>2017-09-17 19:56:15.000000</td>\n",
       "      <td>23525100.0</td>\n",
       "      <td>13955950.0</td>\n",
       "      <td>56.54446</td>\n",
       "      <td>1897037.0</td>\n",
       "      <td>38.29333</td>\n",
       "      <td>19564350.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.316338</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569152 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name              id                   timestamp       P-PDG  \\\n",
       "0       WELL-00014  20170921200114  2017-09-21 20:01:14.000000  24389400.0   \n",
       "1       WELL-00014  20170921200114  2017-09-21 20:01:15.000000  24388900.0   \n",
       "2       WELL-00014  20170921200114  2017-09-21 20:01:16.000000  24388410.0   \n",
       "3       WELL-00014  20170921200114  2017-09-21 20:01:17.000000  24388120.0   \n",
       "4       WELL-00014  20170921200114  2017-09-21 20:01:18.000000  24387820.0   \n",
       "...            ...             ...                         ...         ...   \n",
       "569147  WELL-00014  20170917150000  2017-09-17 19:56:11.000000  23525310.0   \n",
       "569148  WELL-00014  20170917150000  2017-09-17 19:56:12.000000  23525260.0   \n",
       "569149  WELL-00014  20170917150000  2017-09-17 19:56:13.000000  23525200.0   \n",
       "569150  WELL-00014  20170917150000  2017-09-17 19:56:14.000000  23525150.0   \n",
       "569151  WELL-00014  20170917150000  2017-09-17 19:56:15.000000  23525100.0   \n",
       "\n",
       "             P-TPT     T-TPT  P-MON-CKP  T-JUS-CKP  P-JUS-CKGL  T-JUS-CKGL  \\\n",
       "0       15923800.0  43.65952  1490977.0   31.00947  19415620.0         NaN   \n",
       "1       15923280.0  43.65860  1492114.0   31.00781  19415860.0         NaN   \n",
       "2       15922750.0  43.65767  1493250.0   31.00614  19416100.0         NaN   \n",
       "3       15921120.0  43.65464  1494386.0   31.00448  19416350.0         NaN   \n",
       "4       15919480.0  43.65160  1495523.0   31.00282  19416590.0         NaN   \n",
       "...            ...       ...        ...        ...         ...         ...   \n",
       "569147  13954990.0  56.54493  1893704.0   38.29067  19560470.0         NaN   \n",
       "569148  13955230.0  56.54481  1894765.0   38.29134  19561440.0         NaN   \n",
       "569149  13955470.0  56.54469  1895825.0   38.29200  19562410.0         NaN   \n",
       "569150  13955710.0  56.54458  1896431.0   38.29267  19563380.0         NaN   \n",
       "569151  13955950.0  56.54446  1897037.0   38.29333  19564350.0         NaN   \n",
       "\n",
       "             QGL  class  \n",
       "0       1.243595      3  \n",
       "1       1.239152      3  \n",
       "2       1.234708      3  \n",
       "3       1.230265      3  \n",
       "4       1.225821      3  \n",
       "...          ...    ...  \n",
       "569147  1.265560      3  \n",
       "569148  1.278255      3  \n",
       "569149  1.290949      3  \n",
       "569150  1.303643      3  \n",
       "569151  1.316338      3  \n",
       "\n",
       "[569152 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#import csv files\n",
    "# print(csv_files)\n",
    "path=os.path.join(os.getcwd(),'data','3')\n",
    "csv_files=glob.glob(path + \"/*.csv\")\n",
    "\n",
    "#remove BC2406.ipynb from csv_files\n",
    "# csv_files.remove('BC2406.ipynb')\n",
    "\n",
    "# remove all files whose file name (not path) starts with SIMULATED\n",
    "csv_files=[csv_file for csv_file in csv_files if not os.path.basename(csv_file).startswith('SIMULATED')]\n",
    "\n",
    "dataframes={}\n",
    "\n",
    "print(csv_files)\n",
    "for csv_file in csv_files:\n",
    "  # print(csv_file)\n",
    "  well_name=os.path.splitext(csv_file)[0]\n",
    "  # print(\"file path\")\n",
    "  # print(os.path.join(csv_directory,csv_file))\n",
    "  df=pd.read_csv(csv_file)\n",
    "  dataframes[well_name]=df\n",
    "\n",
    "for well_name,df in dataframes.items():\n",
    "  df.insert(0,'name',well_name.split('_')[0].split('/')[-1])\n",
    "  df.insert(1,'id',well_name.split('_')[1])\n",
    "\n",
    "df=pd.concat(dataframes.values(),ignore_index=True)\n",
    "\n",
    "distinct_wells=df['name'].unique()\n",
    "for name in distinct_wells:\n",
    "  print(name)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "count of 0 in class label:  0\n",
      "count of 3 in class label:  569152\n"
     ]
    }
   ],
   "source": [
    "# show all values in column class\n",
    "print(df['class'].unique())\n",
    "\n",
    "#count number of 0, 3 in class label\n",
    "print(\"count of 0 in class label: \",len(df[df['class']==0])) # normal state\n",
    "print(\"count of 3 in class label: \",len(df[df['class']==3]))  # warning state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()\n",
    "#clean dataset to remove name, id, timestamp\n",
    "df=df.drop(['name','id','timestamp'],axis=1)\n",
    "\n",
    "df=df.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop(['class'],axis=1)\n",
    "y=df['class']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train logistic regression model on training set against class label\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# #train model on training set\n",
    "# log_reg=LogisticRegression(max_iter=1000)\n",
    "# log_reg.fit(X_train,y_train)\n",
    "\n",
    "# #predict class label on training set\n",
    "# logreg_train_set_predictions=log_reg.predict(X_train)\n",
    "\n",
    "# #test model on test set\n",
    "# logreg_test_set_predictions=log_reg.predict(X_test)\n",
    "# log_accuracy=accuracy_score(y_test,logreg_test_set_predictions)\n",
    "# log_confusion_matrix=confusion_matrix(y_test,logreg_test_set_predictions)\n",
    "# log_classification_report=classification_report(y_test,logreg_test_set_predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yq/y019q7w56tjfl0mnh_pf1rtc0000gn/T/ipykernel_39922/335965752.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#train model on training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdt_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdt_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#predict class label on training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \"\"\"\n\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    904\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             X, y = self._validate_data(X, y,\n\u001b[0m\u001b[1;32m    158\u001b[0m                                        validate_separately=(check_X_params,\n\u001b[1;32m    159\u001b[0m                                                             check_y_params))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;31m# :(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "#train decision tree regression model on training set against class label\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "#train model on training set\n",
    "dt_class=DecisionTreeClassifier()\n",
    "dt_class.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "dectree_train_set_predictions=dt_class.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "dectree_test_set_predictions=dt_class.predict(X_test)\n",
    "dt_mse=mean_squared_error(y_test,dectree_test_set_predictions)\n",
    "dt_rmse=np.sqrt(dt_mse)\n",
    "dt_accuracy=accuracy_score(y_test,dectree_test_set_predictions)\n",
    "dt_confusion_matrix=confusion_matrix(y_test,dectree_test_set_predictions)\n",
    "\n",
    "print(\"dt_mse\\n\",dt_mse)\n",
    "print(\"dt_rmse\\n\",dt_rmse)\n",
    "print(\"dt_accuracy\\n\",dt_accuracy)\n",
    "print(dt_confusion_matrix)\n",
    "print(\"dt_accuracy = %.1f\"%(dt_accuracy*100),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 5 (Rapid Productivity Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T04:50:25.384500Z",
     "start_time": "2023-09-22T04:50:25.335250Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "pHKtXRpNq5LX",
    "outputId": "aeadf773-ad99-4bee-eb0a-38efafe4814a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00015_20171013140047.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00016_20180517222322.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00017_20140319141450.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00016_20180405020345.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00016_20180426142005.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00017_20140318160220.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00015_20170620160349.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00017_20140314180000.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00017_20140318023141.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00017_20140317151743.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00017_20140319040453.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00016_20180426145108.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00015\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00016\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/5/WELL-00017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:47.000000</td>\n",
       "      <td>23639730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3509006.0</td>\n",
       "      <td>42.35576</td>\n",
       "      <td>19960610.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.288151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:48.000000</td>\n",
       "      <td>23640270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3483324.0</td>\n",
       "      <td>42.35957</td>\n",
       "      <td>19978070.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.291373</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:49.000000</td>\n",
       "      <td>23640810.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3449990.0</td>\n",
       "      <td>42.36337</td>\n",
       "      <td>19995540.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.294595</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:50.000000</td>\n",
       "      <td>23641350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3416657.0</td>\n",
       "      <td>42.36717</td>\n",
       "      <td>20013010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.297816</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:51.000000</td>\n",
       "      <td>23641890.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3383324.0</td>\n",
       "      <td>42.37098</td>\n",
       "      <td>20030480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.302506</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361993</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20180426145108</td>\n",
       "      <td>2018-04-26 15:44:16.000000</td>\n",
       "      <td>24660500.0</td>\n",
       "      <td>11091050.0</td>\n",
       "      <td>16.99739</td>\n",
       "      <td>845799.3</td>\n",
       "      <td>50.32685</td>\n",
       "      <td>18913280.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.766007</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361994</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20180426145108</td>\n",
       "      <td>2018-04-26 15:44:17.000000</td>\n",
       "      <td>24660460.0</td>\n",
       "      <td>11091230.0</td>\n",
       "      <td>16.99959</td>\n",
       "      <td>845819.6</td>\n",
       "      <td>50.32632</td>\n",
       "      <td>18913740.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.736611</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361995</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20180426145108</td>\n",
       "      <td>2018-04-26 15:44:18.000000</td>\n",
       "      <td>24660420.0</td>\n",
       "      <td>11091420.0</td>\n",
       "      <td>17.00179</td>\n",
       "      <td>845840.0</td>\n",
       "      <td>50.32579</td>\n",
       "      <td>18914190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.707214</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361996</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20180426145108</td>\n",
       "      <td>2018-04-26 15:44:19.000000</td>\n",
       "      <td>24660380.0</td>\n",
       "      <td>11091610.0</td>\n",
       "      <td>17.00399</td>\n",
       "      <td>845860.3</td>\n",
       "      <td>50.32526</td>\n",
       "      <td>18914650.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.677818</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361997</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20180426145108</td>\n",
       "      <td>2018-04-26 15:44:20.000000</td>\n",
       "      <td>24660340.0</td>\n",
       "      <td>11091800.0</td>\n",
       "      <td>17.00619</td>\n",
       "      <td>845880.7</td>\n",
       "      <td>50.32472</td>\n",
       "      <td>18915110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.648421</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361998 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name              id  \\\n",
       "0       /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "1       /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "2       /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "3       /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "4       /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "...                                                   ...             ...   \n",
       "361993  /Users/dyllon/Library/Mobile Documents/com~app...  20180426145108   \n",
       "361994  /Users/dyllon/Library/Mobile Documents/com~app...  20180426145108   \n",
       "361995  /Users/dyllon/Library/Mobile Documents/com~app...  20180426145108   \n",
       "361996  /Users/dyllon/Library/Mobile Documents/com~app...  20180426145108   \n",
       "361997  /Users/dyllon/Library/Mobile Documents/com~app...  20180426145108   \n",
       "\n",
       "                         timestamp       P-PDG       P-TPT     T-TPT  \\\n",
       "0       2017-10-13 14:00:47.000000  23639730.0         0.0   0.00000   \n",
       "1       2017-10-13 14:00:48.000000  23640270.0         0.0   0.00000   \n",
       "2       2017-10-13 14:00:49.000000  23640810.0         0.0   0.00000   \n",
       "3       2017-10-13 14:00:50.000000  23641350.0         0.0   0.00000   \n",
       "4       2017-10-13 14:00:51.000000  23641890.0         0.0   0.00000   \n",
       "...                            ...         ...         ...       ...   \n",
       "361993  2018-04-26 15:44:16.000000  24660500.0  11091050.0  16.99739   \n",
       "361994  2018-04-26 15:44:17.000000  24660460.0  11091230.0  16.99959   \n",
       "361995  2018-04-26 15:44:18.000000  24660420.0  11091420.0  17.00179   \n",
       "361996  2018-04-26 15:44:19.000000  24660380.0  11091610.0  17.00399   \n",
       "361997  2018-04-26 15:44:20.000000  24660340.0  11091800.0  17.00619   \n",
       "\n",
       "        P-MON-CKP  T-JUS-CKP  P-JUS-CKGL  T-JUS-CKGL       QGL  class  \n",
       "0       3509006.0   42.35576  19960610.0         NaN  1.288151    0.0  \n",
       "1       3483324.0   42.35957  19978070.0         NaN  1.291373    0.0  \n",
       "2       3449990.0   42.36337  19995540.0         NaN  1.294595    0.0  \n",
       "3       3416657.0   42.36717  20013010.0         NaN  1.297816    0.0  \n",
       "4       3383324.0   42.37098  20030480.0         NaN  1.302506    0.0  \n",
       "...           ...        ...         ...         ...       ...    ...  \n",
       "361993   845799.3   50.32685  18913280.0         NaN  1.766007    5.0  \n",
       "361994   845819.6   50.32632  18913740.0         NaN  1.736611    5.0  \n",
       "361995   845840.0   50.32579  18914190.0         NaN  1.707214    5.0  \n",
       "361996   845860.3   50.32526  18914650.0         NaN  1.677818    5.0  \n",
       "361997   845880.7   50.32472  18915110.0         NaN  1.648421    5.0  \n",
       "\n",
       "[361998 rows x 12 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#import csv files\n",
    "# print(csv_files)\n",
    "path=os.path.join(os.getcwd(),'data','5')\n",
    "csv_files=glob.glob(path + \"/*.csv\")\n",
    "\n",
    "#remove BC2406.ipynb from csv_files\n",
    "# csv_files.remove('BC2406.ipynb')\n",
    "\n",
    "dataframes={}\n",
    "\n",
    "print(csv_files)\n",
    "for csv_file in csv_files:\n",
    "  # print(csv_file)\n",
    "  well_name=os.path.splitext(csv_file)[0]\n",
    "  # print(\"file path\")\n",
    "  # print(os.path.join(csv_directory,csv_file))\n",
    "  df=pd.read_csv(csv_file)\n",
    "  dataframes[well_name]=df\n",
    "\n",
    "for well_name,df in dataframes.items():\n",
    "  df.insert(0,'name',well_name.split('_')[0])\n",
    "  df.insert(1,'id',well_name.split('_')[1])\n",
    "\n",
    "df=pd.concat(dataframes.values(),ignore_index=True)\n",
    "\n",
    "distinct_wells=df['name'].unique()\n",
    "for name in distinct_wells:\n",
    "  print(name)\n",
    "\n",
    "df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Yh4MOPXnycvE",
    "outputId": "b8d4d1e1-ab7b-4018-fa87-1768072034c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:47.000000</td>\n",
       "      <td>23639730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3509006.0</td>\n",
       "      <td>42.35576</td>\n",
       "      <td>19960610.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.288151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:48.000000</td>\n",
       "      <td>23640270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3483324.0</td>\n",
       "      <td>42.35957</td>\n",
       "      <td>19978070.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.291373</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:49.000000</td>\n",
       "      <td>23640810.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3449990.0</td>\n",
       "      <td>42.36337</td>\n",
       "      <td>19995540.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.294595</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:50.000000</td>\n",
       "      <td>23641350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3416657.0</td>\n",
       "      <td>42.36717</td>\n",
       "      <td>20013010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.297816</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/dyllon/Library/Mobile Documents/com~app...</td>\n",
       "      <td>20171013140047</td>\n",
       "      <td>2017-10-13 14:00:51.000000</td>\n",
       "      <td>23641890.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3383324.0</td>\n",
       "      <td>42.37098</td>\n",
       "      <td>20030480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.302506</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name              id  \\\n",
       "0  /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "1  /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "2  /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "3  /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "4  /Users/dyllon/Library/Mobile Documents/com~app...  20171013140047   \n",
       "\n",
       "                    timestamp       P-PDG  P-TPT  T-TPT  P-MON-CKP  T-JUS-CKP  \\\n",
       "0  2017-10-13 14:00:47.000000  23639730.0    0.0    0.0  3509006.0   42.35576   \n",
       "1  2017-10-13 14:00:48.000000  23640270.0    0.0    0.0  3483324.0   42.35957   \n",
       "2  2017-10-13 14:00:49.000000  23640810.0    0.0    0.0  3449990.0   42.36337   \n",
       "3  2017-10-13 14:00:50.000000  23641350.0    0.0    0.0  3416657.0   42.36717   \n",
       "4  2017-10-13 14:00:51.000000  23641890.0    0.0    0.0  3383324.0   42.37098   \n",
       "\n",
       "   P-JUS-CKGL  T-JUS-CKGL       QGL  class  \n",
       "0  19960610.0         NaN  1.288151    0.0  \n",
       "1  19978070.0         NaN  1.291373    0.0  \n",
       "2  19995540.0         NaN  1.294595    0.0  \n",
       "3  20013010.0         NaN  1.297816    0.0  \n",
       "4  20030480.0         NaN  1.302506    0.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T04:36:10.826099Z",
     "start_time": "2023-09-22T04:36:10.619736Z"
    },
    "id": "zgQmxqNA3EIU"
   },
   "outputs": [],
   "source": [
    "df.dropna()\n",
    "#clean dataset to remove name, id, timestamp\n",
    "df=df.drop(['name','id','timestamp'],axis=1)\n",
    "\n",
    "#replace all NaN with 0\n",
    "df=df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of 0 in class label 33693\n",
      "count of 5 in class label 10147\n",
      "count of 105 in class label 318158\n"
     ]
    }
   ],
   "source": [
    "#count number of 0, 5 and 105 in class label\n",
    "print(\"count of 0 in class label\",len(df[df['class']==0])) # normal state\n",
    "print(\"count of 5 in class label\",len(df[df['class']==5]))  # warning state\n",
    "print(\"count of 105 in class label\",len(df[df['class']==105])) # abnormal state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop(['class'],axis=1)\n",
    "y=df['class']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train logistic regression model on training set against class label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#train model on training set\n",
    "log_reg=LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "logreg_train_set_predictions=log_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "logreg_test_set_predictions=log_reg.predict(X_test)\n",
    "log_accuracy=accuracy_score(y_test,logreg_test_set_predictions)\n",
    "log_confusion_matrix=confusion_matrix(y_test,logreg_test_set_predictions)\n",
    "log_classification_report=classification_report(y_test,logreg_test_set_predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_accuracy\n",
      " 0.8598066298342542\n",
      "[[  402   415  5987]\n",
      " [    0   659  1324]\n",
      " [  867  1557 61189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.32      0.06      0.10      6804\n",
      "         5.0       0.25      0.33      0.29      1983\n",
      "       105.0       0.89      0.96      0.93     63613\n",
      "\n",
      "    accuracy                           0.86     72400\n",
      "   macro avg       0.49      0.45      0.44     72400\n",
      "weighted avg       0.82      0.86      0.83     72400\n",
      "\n",
      "log_accuracy = 86.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"log_accuracy\\n\",log_accuracy)\n",
    "print(log_confusion_matrix)\n",
    "print(log_classification_report)\n",
    "print(\"log_accuracy = %.1f\"%(log_accuracy*100),\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train decision tree regression model on training set against class label\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "#train model on training set\n",
    "# print(X_train.dtypes)\n",
    "\n",
    "dt_class=DecisionTreeClassifier()\n",
    "dt_class.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "dectree_train_set_predictions=dt_class.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "dectree_test_set_predictions=dt_class.predict(X_test)\n",
    "dt_mse=mean_squared_error(y_test,dectree_test_set_predictions)\n",
    "dt_rmse=np.sqrt(dt_mse)\n",
    "dt_accuracy=accuracy_score(y_test,dectree_test_set_predictions)\n",
    "dt_confusion_matrix=confusion_matrix(y_test,dectree_test_set_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_mse\n",
      " 0.762085635359116\n",
      "dt_rmse\n",
      " 0.8729751630826137\n",
      "dt_accuracy\n",
      " 0.999903314917127\n",
      "[[ 6800     1     3]\n",
      " [    1  1982     0]\n",
      " [    2     0 63611]]\n",
      "dt_accuracy = 100.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"dt_mse\\n\",dt_mse)\n",
    "print(\"dt_rmse\\n\",dt_rmse)\n",
    "print(\"dt_accuracy\\n\",dt_accuracy)\n",
    "print(dt_confusion_matrix)\n",
    "print(\"dt_accuracy = %.1f\"%(dt_accuracy*100),\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_class=xgb.XGBClassifier()\n",
    "xgb_class.fit(X_train,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "xgb_train_set_predictions=xgb_class.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "y_pred=xgb_class.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_accuracy\n",
      " 0.9997651933701658\n",
      "[[ 6793     6     5]\n",
      " [    0  1983     0]\n",
      " [    6     0 63607]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      6804\n",
      "         5.0       1.00      1.00      1.00      1983\n",
      "       105.0       1.00      1.00      1.00     63613\n",
      "\n",
      "    accuracy                           1.00     72400\n",
      "   macro avg       1.00      1.00      1.00     72400\n",
      "weighted avg       1.00      1.00      1.00     72400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train logistic regression model on training set against class label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#convert y_pred to 0,5,105\n",
    "y_pred=np.round(y_pred)\n",
    "y_pred=le.inverse_transform(y_pred.astype(int))\n",
    "\n",
    "xgb_accuracy=accuracy_score(y_test,y_pred)\n",
    "xgb_confusion_matrix=confusion_matrix(y_test,y_pred)\n",
    "xgb_classification_report=classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"xgb_accuracy\\n\",xgb_accuracy)\n",
    "print(xgb_confusion_matrix)\n",
    "print(xgb_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --no-build-isolation catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.105651\n",
      "0:\tlearn: 0.9236072\ttotal: 59.6ms\tremaining: 59.6s\n",
      "1:\tlearn: 0.7914485\ttotal: 100ms\tremaining: 49.9s\n",
      "2:\tlearn: 0.6879227\ttotal: 133ms\tremaining: 44.3s\n",
      "3:\tlearn: 0.6063271\ttotal: 165ms\tremaining: 41.2s\n",
      "4:\tlearn: 0.5346120\ttotal: 210ms\tremaining: 41.8s\n",
      "5:\tlearn: 0.4746592\ttotal: 285ms\tremaining: 47.3s\n",
      "6:\tlearn: 0.4235376\ttotal: 328ms\tremaining: 46.5s\n",
      "7:\tlearn: 0.3807083\ttotal: 361ms\tremaining: 44.7s\n",
      "8:\tlearn: 0.3422057\ttotal: 394ms\tremaining: 43.4s\n",
      "9:\tlearn: 0.3083072\ttotal: 434ms\tremaining: 42.9s\n",
      "10:\tlearn: 0.2802932\ttotal: 474ms\tremaining: 42.7s\n",
      "11:\tlearn: 0.2546340\ttotal: 509ms\tremaining: 41.9s\n",
      "12:\tlearn: 0.2324941\ttotal: 546ms\tremaining: 41.4s\n",
      "13:\tlearn: 0.2125383\ttotal: 587ms\tremaining: 41.3s\n",
      "14:\tlearn: 0.1946054\ttotal: 640ms\tremaining: 42s\n",
      "15:\tlearn: 0.1786510\ttotal: 694ms\tremaining: 42.7s\n",
      "16:\tlearn: 0.1657458\ttotal: 736ms\tremaining: 42.5s\n",
      "17:\tlearn: 0.1552057\ttotal: 776ms\tremaining: 42.3s\n",
      "18:\tlearn: 0.1437041\ttotal: 825ms\tremaining: 42.6s\n",
      "19:\tlearn: 0.1336077\ttotal: 873ms\tremaining: 42.8s\n",
      "20:\tlearn: 0.1233562\ttotal: 921ms\tremaining: 42.9s\n",
      "21:\tlearn: 0.1150303\ttotal: 967ms\tremaining: 43s\n",
      "22:\tlearn: 0.1075453\ttotal: 1.02s\tremaining: 43.2s\n",
      "23:\tlearn: 0.1006048\ttotal: 1.06s\tremaining: 43.1s\n",
      "24:\tlearn: 0.0941276\ttotal: 1.1s\tremaining: 42.9s\n",
      "25:\tlearn: 0.0889553\ttotal: 1.15s\tremaining: 43.1s\n",
      "26:\tlearn: 0.0838462\ttotal: 1.22s\tremaining: 43.8s\n",
      "27:\tlearn: 0.0789214\ttotal: 1.26s\tremaining: 43.7s\n",
      "28:\tlearn: 0.0748039\ttotal: 1.3s\tremaining: 43.5s\n",
      "29:\tlearn: 0.0709722\ttotal: 1.34s\tremaining: 43.3s\n",
      "30:\tlearn: 0.0677669\ttotal: 1.38s\tremaining: 43.2s\n",
      "31:\tlearn: 0.0641825\ttotal: 1.42s\tremaining: 42.9s\n",
      "32:\tlearn: 0.0615643\ttotal: 1.45s\tremaining: 42.6s\n",
      "33:\tlearn: 0.0589519\ttotal: 1.48s\tremaining: 42.2s\n",
      "34:\tlearn: 0.0564311\ttotal: 1.53s\tremaining: 42.1s\n",
      "35:\tlearn: 0.0537700\ttotal: 1.56s\tremaining: 41.8s\n",
      "36:\tlearn: 0.0516727\ttotal: 1.6s\tremaining: 41.6s\n",
      "37:\tlearn: 0.0492000\ttotal: 1.63s\tremaining: 41.3s\n",
      "38:\tlearn: 0.0470861\ttotal: 1.67s\tremaining: 41.1s\n",
      "39:\tlearn: 0.0452516\ttotal: 1.7s\tremaining: 40.8s\n",
      "40:\tlearn: 0.0437112\ttotal: 1.73s\tremaining: 40.5s\n",
      "41:\tlearn: 0.0424594\ttotal: 1.76s\tremaining: 40.3s\n",
      "42:\tlearn: 0.0411051\ttotal: 1.8s\tremaining: 40s\n",
      "43:\tlearn: 0.0399964\ttotal: 1.83s\tremaining: 39.8s\n",
      "44:\tlearn: 0.0389496\ttotal: 1.86s\tremaining: 39.6s\n",
      "45:\tlearn: 0.0373997\ttotal: 1.92s\tremaining: 39.8s\n",
      "46:\tlearn: 0.0360989\ttotal: 1.99s\tremaining: 40.4s\n",
      "47:\tlearn: 0.0347908\ttotal: 2.05s\tremaining: 40.7s\n",
      "48:\tlearn: 0.0337673\ttotal: 2.1s\tremaining: 40.7s\n",
      "49:\tlearn: 0.0328993\ttotal: 2.13s\tremaining: 40.5s\n",
      "50:\tlearn: 0.0319900\ttotal: 2.17s\tremaining: 40.3s\n",
      "51:\tlearn: 0.0308403\ttotal: 2.21s\tremaining: 40.2s\n",
      "52:\tlearn: 0.0300091\ttotal: 2.24s\tremaining: 40s\n",
      "53:\tlearn: 0.0294667\ttotal: 2.27s\tremaining: 39.8s\n",
      "54:\tlearn: 0.0286975\ttotal: 2.3s\tremaining: 39.6s\n",
      "55:\tlearn: 0.0278382\ttotal: 2.33s\tremaining: 39.4s\n",
      "56:\tlearn: 0.0271940\ttotal: 2.37s\tremaining: 39.2s\n",
      "57:\tlearn: 0.0266274\ttotal: 2.42s\tremaining: 39.3s\n",
      "58:\tlearn: 0.0259135\ttotal: 2.46s\tremaining: 39.3s\n",
      "59:\tlearn: 0.0254660\ttotal: 2.5s\tremaining: 39.2s\n",
      "60:\tlearn: 0.0247941\ttotal: 2.54s\tremaining: 39.1s\n",
      "61:\tlearn: 0.0243342\ttotal: 2.58s\tremaining: 39s\n",
      "62:\tlearn: 0.0239058\ttotal: 2.62s\tremaining: 38.9s\n",
      "63:\tlearn: 0.0233231\ttotal: 2.66s\tremaining: 38.9s\n",
      "64:\tlearn: 0.0229192\ttotal: 2.7s\tremaining: 38.9s\n",
      "65:\tlearn: 0.0225765\ttotal: 2.74s\tremaining: 38.8s\n",
      "66:\tlearn: 0.0221834\ttotal: 2.79s\tremaining: 38.9s\n",
      "67:\tlearn: 0.0217790\ttotal: 2.82s\tremaining: 38.7s\n",
      "68:\tlearn: 0.0214424\ttotal: 2.85s\tremaining: 38.5s\n",
      "69:\tlearn: 0.0212101\ttotal: 2.89s\tremaining: 38.3s\n",
      "70:\tlearn: 0.0209461\ttotal: 2.92s\tremaining: 38.2s\n",
      "71:\tlearn: 0.0203700\ttotal: 2.96s\tremaining: 38.1s\n",
      "72:\tlearn: 0.0201130\ttotal: 2.99s\tremaining: 38s\n",
      "73:\tlearn: 0.0198659\ttotal: 3.03s\tremaining: 37.9s\n",
      "74:\tlearn: 0.0196063\ttotal: 3.06s\tremaining: 37.7s\n",
      "75:\tlearn: 0.0192834\ttotal: 3.09s\tremaining: 37.5s\n",
      "76:\tlearn: 0.0187227\ttotal: 3.13s\tremaining: 37.5s\n",
      "77:\tlearn: 0.0183366\ttotal: 3.16s\tremaining: 37.3s\n",
      "78:\tlearn: 0.0179053\ttotal: 3.2s\tremaining: 37.3s\n",
      "79:\tlearn: 0.0177132\ttotal: 3.23s\tremaining: 37.1s\n",
      "80:\tlearn: 0.0175604\ttotal: 3.26s\tremaining: 37s\n",
      "81:\tlearn: 0.0171037\ttotal: 3.29s\tremaining: 36.9s\n",
      "82:\tlearn: 0.0169096\ttotal: 3.32s\tremaining: 36.7s\n",
      "83:\tlearn: 0.0167839\ttotal: 3.36s\tremaining: 36.6s\n",
      "84:\tlearn: 0.0164075\ttotal: 3.4s\tremaining: 36.6s\n",
      "85:\tlearn: 0.0161711\ttotal: 3.44s\tremaining: 36.6s\n",
      "86:\tlearn: 0.0159422\ttotal: 3.48s\tremaining: 36.5s\n",
      "87:\tlearn: 0.0158246\ttotal: 3.52s\tremaining: 36.4s\n",
      "88:\tlearn: 0.0155120\ttotal: 3.56s\tremaining: 36.4s\n",
      "89:\tlearn: 0.0152161\ttotal: 3.6s\tremaining: 36.4s\n",
      "90:\tlearn: 0.0151053\ttotal: 3.65s\tremaining: 36.4s\n",
      "91:\tlearn: 0.0149851\ttotal: 3.68s\tremaining: 36.4s\n",
      "92:\tlearn: 0.0147690\ttotal: 3.72s\tremaining: 36.3s\n",
      "93:\tlearn: 0.0146303\ttotal: 3.76s\tremaining: 36.3s\n",
      "94:\tlearn: 0.0145439\ttotal: 3.8s\tremaining: 36.2s\n",
      "95:\tlearn: 0.0142268\ttotal: 3.85s\tremaining: 36.2s\n",
      "96:\tlearn: 0.0141128\ttotal: 3.88s\tremaining: 36.1s\n",
      "97:\tlearn: 0.0139268\ttotal: 3.92s\tremaining: 36.1s\n",
      "98:\tlearn: 0.0137950\ttotal: 3.96s\tremaining: 36s\n",
      "99:\tlearn: 0.0137004\ttotal: 3.99s\tremaining: 35.9s\n",
      "100:\tlearn: 0.0135885\ttotal: 4.02s\tremaining: 35.8s\n",
      "101:\tlearn: 0.0134846\ttotal: 4.06s\tremaining: 35.7s\n",
      "102:\tlearn: 0.0132441\ttotal: 4.1s\tremaining: 35.7s\n",
      "103:\tlearn: 0.0130354\ttotal: 4.14s\tremaining: 35.6s\n",
      "104:\tlearn: 0.0129239\ttotal: 4.17s\tremaining: 35.5s\n",
      "105:\tlearn: 0.0128161\ttotal: 4.2s\tremaining: 35.4s\n",
      "106:\tlearn: 0.0125795\ttotal: 4.24s\tremaining: 35.4s\n",
      "107:\tlearn: 0.0123728\ttotal: 4.28s\tremaining: 35.3s\n",
      "108:\tlearn: 0.0122969\ttotal: 4.31s\tremaining: 35.3s\n",
      "109:\tlearn: 0.0121541\ttotal: 4.34s\tremaining: 35.2s\n",
      "110:\tlearn: 0.0120300\ttotal: 4.38s\tremaining: 35.1s\n",
      "111:\tlearn: 0.0119477\ttotal: 4.41s\tremaining: 35s\n",
      "112:\tlearn: 0.0118812\ttotal: 4.44s\tremaining: 34.8s\n",
      "113:\tlearn: 0.0117760\ttotal: 4.47s\tremaining: 34.7s\n",
      "114:\tlearn: 0.0114826\ttotal: 4.51s\tremaining: 34.7s\n",
      "115:\tlearn: 0.0114073\ttotal: 4.54s\tremaining: 34.6s\n",
      "116:\tlearn: 0.0113395\ttotal: 4.57s\tremaining: 34.5s\n",
      "117:\tlearn: 0.0112712\ttotal: 4.61s\tremaining: 34.4s\n",
      "118:\tlearn: 0.0112007\ttotal: 4.64s\tremaining: 34.4s\n",
      "119:\tlearn: 0.0111112\ttotal: 4.67s\tremaining: 34.3s\n",
      "120:\tlearn: 0.0110480\ttotal: 4.71s\tremaining: 34.2s\n",
      "121:\tlearn: 0.0108696\ttotal: 4.75s\tremaining: 34.2s\n",
      "122:\tlearn: 0.0107988\ttotal: 4.78s\tremaining: 34.1s\n",
      "123:\tlearn: 0.0105968\ttotal: 4.81s\tremaining: 34s\n",
      "124:\tlearn: 0.0105420\ttotal: 4.84s\tremaining: 33.9s\n",
      "125:\tlearn: 0.0103695\ttotal: 4.88s\tremaining: 33.8s\n",
      "126:\tlearn: 0.0103206\ttotal: 4.91s\tremaining: 33.7s\n",
      "127:\tlearn: 0.0102660\ttotal: 5s\tremaining: 34s\n",
      "128:\tlearn: 0.0101062\ttotal: 5.03s\tremaining: 34s\n",
      "129:\tlearn: 0.0100324\ttotal: 5.06s\tremaining: 33.9s\n",
      "130:\tlearn: 0.0099828\ttotal: 5.09s\tremaining: 33.8s\n",
      "131:\tlearn: 0.0099277\ttotal: 5.12s\tremaining: 33.7s\n",
      "132:\tlearn: 0.0097469\ttotal: 5.16s\tremaining: 33.6s\n",
      "133:\tlearn: 0.0097120\ttotal: 5.18s\tremaining: 33.5s\n",
      "134:\tlearn: 0.0096453\ttotal: 5.22s\tremaining: 33.4s\n",
      "135:\tlearn: 0.0095890\ttotal: 5.25s\tremaining: 33.4s\n",
      "136:\tlearn: 0.0095134\ttotal: 5.29s\tremaining: 33.3s\n",
      "137:\tlearn: 0.0094714\ttotal: 5.32s\tremaining: 33.2s\n",
      "138:\tlearn: 0.0094132\ttotal: 5.36s\tremaining: 33.2s\n",
      "139:\tlearn: 0.0093764\ttotal: 5.39s\tremaining: 33.1s\n",
      "140:\tlearn: 0.0093209\ttotal: 5.42s\tremaining: 33s\n",
      "141:\tlearn: 0.0091829\ttotal: 5.46s\tremaining: 33s\n",
      "142:\tlearn: 0.0091500\ttotal: 5.49s\tremaining: 32.9s\n",
      "143:\tlearn: 0.0091056\ttotal: 5.52s\tremaining: 32.8s\n",
      "144:\tlearn: 0.0089944\ttotal: 5.55s\tremaining: 32.7s\n",
      "145:\tlearn: 0.0088223\ttotal: 5.59s\tremaining: 32.7s\n",
      "146:\tlearn: 0.0087931\ttotal: 5.62s\tremaining: 32.6s\n",
      "147:\tlearn: 0.0086996\ttotal: 5.65s\tremaining: 32.5s\n",
      "148:\tlearn: 0.0086753\ttotal: 5.68s\tremaining: 32.4s\n",
      "149:\tlearn: 0.0084997\ttotal: 5.72s\tremaining: 32.4s\n",
      "150:\tlearn: 0.0084570\ttotal: 5.75s\tremaining: 32.3s\n",
      "151:\tlearn: 0.0083454\ttotal: 5.79s\tremaining: 32.3s\n",
      "152:\tlearn: 0.0082207\ttotal: 5.82s\tremaining: 32.2s\n",
      "153:\tlearn: 0.0081829\ttotal: 5.86s\tremaining: 32.2s\n",
      "154:\tlearn: 0.0080836\ttotal: 5.9s\tremaining: 32.2s\n",
      "155:\tlearn: 0.0080564\ttotal: 5.93s\tremaining: 32.1s\n",
      "156:\tlearn: 0.0079464\ttotal: 5.97s\tremaining: 32s\n",
      "157:\tlearn: 0.0079163\ttotal: 6s\tremaining: 31.9s\n",
      "158:\tlearn: 0.0078170\ttotal: 6.03s\tremaining: 31.9s\n",
      "159:\tlearn: 0.0077771\ttotal: 6.06s\tremaining: 31.8s\n",
      "160:\tlearn: 0.0077433\ttotal: 6.09s\tremaining: 31.7s\n",
      "161:\tlearn: 0.0077200\ttotal: 6.12s\tremaining: 31.7s\n",
      "162:\tlearn: 0.0076801\ttotal: 6.16s\tremaining: 31.6s\n",
      "163:\tlearn: 0.0075924\ttotal: 6.2s\tremaining: 31.6s\n",
      "164:\tlearn: 0.0075733\ttotal: 6.23s\tremaining: 31.5s\n",
      "165:\tlearn: 0.0075264\ttotal: 6.26s\tremaining: 31.5s\n",
      "166:\tlearn: 0.0074342\ttotal: 6.3s\tremaining: 31.4s\n",
      "167:\tlearn: 0.0073068\ttotal: 6.33s\tremaining: 31.4s\n",
      "168:\tlearn: 0.0072388\ttotal: 6.37s\tremaining: 31.3s\n",
      "169:\tlearn: 0.0072058\ttotal: 6.41s\tremaining: 31.3s\n",
      "170:\tlearn: 0.0071619\ttotal: 6.44s\tremaining: 31.2s\n",
      "171:\tlearn: 0.0071277\ttotal: 6.47s\tremaining: 31.2s\n",
      "172:\tlearn: 0.0070854\ttotal: 6.51s\tremaining: 31.1s\n",
      "173:\tlearn: 0.0070654\ttotal: 6.54s\tremaining: 31s\n",
      "174:\tlearn: 0.0070372\ttotal: 6.57s\tremaining: 31s\n",
      "175:\tlearn: 0.0069973\ttotal: 6.6s\tremaining: 30.9s\n",
      "176:\tlearn: 0.0069759\ttotal: 6.63s\tremaining: 30.8s\n",
      "177:\tlearn: 0.0069476\ttotal: 6.66s\tremaining: 30.7s\n",
      "178:\tlearn: 0.0068748\ttotal: 6.69s\tremaining: 30.7s\n",
      "179:\tlearn: 0.0067777\ttotal: 6.73s\tremaining: 30.6s\n",
      "180:\tlearn: 0.0067149\ttotal: 6.76s\tremaining: 30.6s\n",
      "181:\tlearn: 0.0066906\ttotal: 6.79s\tremaining: 30.5s\n",
      "182:\tlearn: 0.0066679\ttotal: 6.82s\tremaining: 30.4s\n",
      "183:\tlearn: 0.0066545\ttotal: 6.85s\tremaining: 30.4s\n",
      "184:\tlearn: 0.0066290\ttotal: 6.89s\tremaining: 30.3s\n",
      "185:\tlearn: 0.0065895\ttotal: 6.93s\tremaining: 30.3s\n",
      "186:\tlearn: 0.0065145\ttotal: 6.96s\tremaining: 30.3s\n",
      "187:\tlearn: 0.0064465\ttotal: 7s\tremaining: 30.2s\n",
      "188:\tlearn: 0.0063860\ttotal: 7.04s\tremaining: 30.2s\n",
      "189:\tlearn: 0.0062922\ttotal: 7.07s\tremaining: 30.1s\n",
      "190:\tlearn: 0.0062745\ttotal: 7.1s\tremaining: 30.1s\n",
      "191:\tlearn: 0.0062565\ttotal: 7.13s\tremaining: 30s\n",
      "192:\tlearn: 0.0062370\ttotal: 7.16s\tremaining: 29.9s\n",
      "193:\tlearn: 0.0062226\ttotal: 7.19s\tremaining: 29.9s\n",
      "194:\tlearn: 0.0061425\ttotal: 7.23s\tremaining: 29.8s\n",
      "195:\tlearn: 0.0060567\ttotal: 7.26s\tremaining: 29.8s\n",
      "196:\tlearn: 0.0059877\ttotal: 7.3s\tremaining: 29.8s\n",
      "197:\tlearn: 0.0059530\ttotal: 7.33s\tremaining: 29.7s\n",
      "198:\tlearn: 0.0059390\ttotal: 7.36s\tremaining: 29.6s\n",
      "199:\tlearn: 0.0059292\ttotal: 7.39s\tremaining: 29.5s\n",
      "200:\tlearn: 0.0058587\ttotal: 7.42s\tremaining: 29.5s\n",
      "201:\tlearn: 0.0058379\ttotal: 7.45s\tremaining: 29.4s\n",
      "202:\tlearn: 0.0058243\ttotal: 7.49s\tremaining: 29.4s\n",
      "203:\tlearn: 0.0057680\ttotal: 7.53s\tremaining: 29.4s\n",
      "204:\tlearn: 0.0057046\ttotal: 7.57s\tremaining: 29.4s\n",
      "205:\tlearn: 0.0056895\ttotal: 7.61s\tremaining: 29.3s\n",
      "206:\tlearn: 0.0056183\ttotal: 7.65s\tremaining: 29.3s\n",
      "207:\tlearn: 0.0056068\ttotal: 7.68s\tremaining: 29.2s\n",
      "208:\tlearn: 0.0055545\ttotal: 7.71s\tremaining: 29.2s\n",
      "209:\tlearn: 0.0055383\ttotal: 7.75s\tremaining: 29.2s\n",
      "210:\tlearn: 0.0054820\ttotal: 7.79s\tremaining: 29.1s\n",
      "211:\tlearn: 0.0054017\ttotal: 7.83s\tremaining: 29.1s\n",
      "212:\tlearn: 0.0053871\ttotal: 7.87s\tremaining: 29.1s\n",
      "213:\tlearn: 0.0053060\ttotal: 7.92s\tremaining: 29.1s\n",
      "214:\tlearn: 0.0052645\ttotal: 7.95s\tremaining: 29s\n",
      "215:\tlearn: 0.0052516\ttotal: 7.99s\tremaining: 29s\n",
      "216:\tlearn: 0.0052259\ttotal: 8.02s\tremaining: 28.9s\n",
      "217:\tlearn: 0.0052030\ttotal: 8.05s\tremaining: 28.9s\n",
      "218:\tlearn: 0.0051481\ttotal: 8.09s\tremaining: 28.8s\n",
      "219:\tlearn: 0.0051024\ttotal: 8.13s\tremaining: 28.8s\n",
      "220:\tlearn: 0.0050886\ttotal: 8.16s\tremaining: 28.8s\n",
      "221:\tlearn: 0.0050801\ttotal: 8.19s\tremaining: 28.7s\n",
      "222:\tlearn: 0.0050319\ttotal: 8.23s\tremaining: 28.7s\n",
      "223:\tlearn: 0.0050134\ttotal: 8.26s\tremaining: 28.6s\n",
      "224:\tlearn: 0.0049621\ttotal: 8.3s\tremaining: 28.6s\n",
      "225:\tlearn: 0.0049469\ttotal: 8.34s\tremaining: 28.6s\n",
      "226:\tlearn: 0.0049392\ttotal: 8.37s\tremaining: 28.5s\n",
      "227:\tlearn: 0.0048952\ttotal: 8.41s\tremaining: 28.5s\n",
      "228:\tlearn: 0.0048662\ttotal: 8.44s\tremaining: 28.4s\n",
      "229:\tlearn: 0.0048526\ttotal: 8.47s\tremaining: 28.4s\n",
      "230:\tlearn: 0.0048223\ttotal: 8.5s\tremaining: 28.3s\n",
      "231:\tlearn: 0.0048020\ttotal: 8.53s\tremaining: 28.2s\n",
      "232:\tlearn: 0.0047750\ttotal: 8.56s\tremaining: 28.2s\n",
      "233:\tlearn: 0.0047556\ttotal: 8.59s\tremaining: 28.1s\n",
      "234:\tlearn: 0.0047479\ttotal: 8.62s\tremaining: 28.1s\n",
      "235:\tlearn: 0.0047388\ttotal: 8.65s\tremaining: 28s\n",
      "236:\tlearn: 0.0047272\ttotal: 8.68s\tremaining: 28s\n",
      "237:\tlearn: 0.0047130\ttotal: 8.71s\tremaining: 27.9s\n",
      "238:\tlearn: 0.0046723\ttotal: 8.75s\tremaining: 27.9s\n",
      "239:\tlearn: 0.0046267\ttotal: 8.78s\tremaining: 27.8s\n",
      "240:\tlearn: 0.0045832\ttotal: 8.82s\tremaining: 27.8s\n",
      "241:\tlearn: 0.0045666\ttotal: 8.86s\tremaining: 27.7s\n",
      "242:\tlearn: 0.0045589\ttotal: 8.89s\tremaining: 27.7s\n",
      "243:\tlearn: 0.0045493\ttotal: 8.92s\tremaining: 27.6s\n",
      "244:\tlearn: 0.0045422\ttotal: 8.95s\tremaining: 27.6s\n",
      "245:\tlearn: 0.0045294\ttotal: 8.98s\tremaining: 27.5s\n",
      "246:\tlearn: 0.0045131\ttotal: 9.01s\tremaining: 27.5s\n",
      "247:\tlearn: 0.0045033\ttotal: 9.04s\tremaining: 27.4s\n",
      "248:\tlearn: 0.0044550\ttotal: 9.08s\tremaining: 27.4s\n",
      "249:\tlearn: 0.0044342\ttotal: 9.12s\tremaining: 27.3s\n",
      "250:\tlearn: 0.0044254\ttotal: 9.14s\tremaining: 27.3s\n",
      "251:\tlearn: 0.0043922\ttotal: 9.18s\tremaining: 27.2s\n",
      "252:\tlearn: 0.0043391\ttotal: 9.21s\tremaining: 27.2s\n",
      "253:\tlearn: 0.0043182\ttotal: 9.24s\tremaining: 27.2s\n",
      "254:\tlearn: 0.0042838\ttotal: 9.29s\tremaining: 27.1s\n",
      "255:\tlearn: 0.0042353\ttotal: 9.32s\tremaining: 27.1s\n",
      "256:\tlearn: 0.0042142\ttotal: 9.36s\tremaining: 27.1s\n",
      "257:\tlearn: 0.0041682\ttotal: 9.39s\tremaining: 27s\n",
      "258:\tlearn: 0.0041618\ttotal: 9.43s\tremaining: 27s\n",
      "259:\tlearn: 0.0041573\ttotal: 9.45s\tremaining: 26.9s\n",
      "260:\tlearn: 0.0041170\ttotal: 9.49s\tremaining: 26.9s\n",
      "261:\tlearn: 0.0041046\ttotal: 9.52s\tremaining: 26.8s\n",
      "262:\tlearn: 0.0040689\ttotal: 9.56s\tremaining: 26.8s\n",
      "263:\tlearn: 0.0040631\ttotal: 9.59s\tremaining: 26.7s\n",
      "264:\tlearn: 0.0040550\ttotal: 9.62s\tremaining: 26.7s\n",
      "265:\tlearn: 0.0040225\ttotal: 9.65s\tremaining: 26.6s\n",
      "266:\tlearn: 0.0040126\ttotal: 9.69s\tremaining: 26.6s\n",
      "267:\tlearn: 0.0040036\ttotal: 9.72s\tremaining: 26.5s\n",
      "268:\tlearn: 0.0039915\ttotal: 9.75s\tremaining: 26.5s\n",
      "269:\tlearn: 0.0039828\ttotal: 9.78s\tremaining: 26.4s\n",
      "270:\tlearn: 0.0039384\ttotal: 9.81s\tremaining: 26.4s\n",
      "271:\tlearn: 0.0039335\ttotal: 9.84s\tremaining: 26.3s\n",
      "272:\tlearn: 0.0039249\ttotal: 9.88s\tremaining: 26.3s\n",
      "273:\tlearn: 0.0039198\ttotal: 9.91s\tremaining: 26.3s\n",
      "274:\tlearn: 0.0038884\ttotal: 9.94s\tremaining: 26.2s\n",
      "275:\tlearn: 0.0038807\ttotal: 9.97s\tremaining: 26.2s\n",
      "276:\tlearn: 0.0038335\ttotal: 10s\tremaining: 26.1s\n",
      "277:\tlearn: 0.0038037\ttotal: 10s\tremaining: 26.1s\n",
      "278:\tlearn: 0.0037747\ttotal: 10.1s\tremaining: 26s\n",
      "279:\tlearn: 0.0037693\ttotal: 10.1s\tremaining: 26s\n",
      "280:\tlearn: 0.0037440\ttotal: 10.1s\tremaining: 26s\n",
      "281:\tlearn: 0.0037403\ttotal: 10.2s\tremaining: 25.9s\n",
      "282:\tlearn: 0.0037274\ttotal: 10.2s\tremaining: 25.9s\n",
      "283:\tlearn: 0.0037181\ttotal: 10.2s\tremaining: 25.8s\n",
      "284:\tlearn: 0.0037117\ttotal: 10.3s\tremaining: 25.8s\n",
      "285:\tlearn: 0.0037067\ttotal: 10.3s\tremaining: 25.7s\n",
      "286:\tlearn: 0.0036996\ttotal: 10.3s\tremaining: 25.7s\n",
      "287:\tlearn: 0.0036958\ttotal: 10.4s\tremaining: 25.6s\n",
      "288:\tlearn: 0.0036872\ttotal: 10.4s\tremaining: 25.6s\n",
      "289:\tlearn: 0.0036836\ttotal: 10.4s\tremaining: 25.5s\n",
      "290:\tlearn: 0.0036789\ttotal: 10.5s\tremaining: 25.5s\n",
      "291:\tlearn: 0.0036516\ttotal: 10.5s\tremaining: 25.4s\n",
      "292:\tlearn: 0.0036067\ttotal: 10.5s\tremaining: 25.4s\n",
      "293:\tlearn: 0.0035903\ttotal: 10.6s\tremaining: 25.4s\n",
      "294:\tlearn: 0.0035518\ttotal: 10.6s\tremaining: 25.3s\n",
      "295:\tlearn: 0.0035407\ttotal: 10.6s\tremaining: 25.3s\n",
      "296:\tlearn: 0.0035381\ttotal: 10.7s\tremaining: 25.2s\n",
      "297:\tlearn: 0.0035335\ttotal: 10.7s\tremaining: 25.2s\n",
      "298:\tlearn: 0.0034984\ttotal: 10.7s\tremaining: 25.1s\n",
      "299:\tlearn: 0.0034712\ttotal: 10.8s\tremaining: 25.1s\n",
      "300:\tlearn: 0.0034500\ttotal: 10.8s\tremaining: 25.1s\n",
      "301:\tlearn: 0.0034358\ttotal: 10.8s\tremaining: 25.1s\n",
      "302:\tlearn: 0.0034186\ttotal: 10.9s\tremaining: 25.1s\n",
      "303:\tlearn: 0.0033873\ttotal: 11s\tremaining: 25.1s\n",
      "304:\tlearn: 0.0033792\ttotal: 11s\tremaining: 25.1s\n",
      "305:\tlearn: 0.0033765\ttotal: 11s\tremaining: 25s\n",
      "306:\tlearn: 0.0033677\ttotal: 11.1s\tremaining: 25s\n",
      "307:\tlearn: 0.0033394\ttotal: 11.1s\tremaining: 25s\n",
      "308:\tlearn: 0.0033311\ttotal: 11.2s\tremaining: 25s\n",
      "309:\tlearn: 0.0033020\ttotal: 11.2s\tremaining: 24.9s\n",
      "310:\tlearn: 0.0032904\ttotal: 11.2s\tremaining: 24.9s\n",
      "311:\tlearn: 0.0032773\ttotal: 11.3s\tremaining: 24.9s\n",
      "312:\tlearn: 0.0032522\ttotal: 11.3s\tremaining: 24.8s\n",
      "313:\tlearn: 0.0032267\ttotal: 11.3s\tremaining: 24.8s\n",
      "314:\tlearn: 0.0032204\ttotal: 11.4s\tremaining: 24.8s\n",
      "315:\tlearn: 0.0032157\ttotal: 11.4s\tremaining: 24.7s\n",
      "316:\tlearn: 0.0031853\ttotal: 11.4s\tremaining: 24.7s\n",
      "317:\tlearn: 0.0031566\ttotal: 11.5s\tremaining: 24.6s\n",
      "318:\tlearn: 0.0031446\ttotal: 11.5s\tremaining: 24.6s\n",
      "319:\tlearn: 0.0031358\ttotal: 11.5s\tremaining: 24.5s\n",
      "320:\tlearn: 0.0031128\ttotal: 11.6s\tremaining: 24.5s\n",
      "321:\tlearn: 0.0031093\ttotal: 11.6s\tremaining: 24.5s\n",
      "322:\tlearn: 0.0031025\ttotal: 11.6s\tremaining: 24.4s\n",
      "323:\tlearn: 0.0030958\ttotal: 11.7s\tremaining: 24.4s\n",
      "324:\tlearn: 0.0030886\ttotal: 11.7s\tremaining: 24.3s\n",
      "325:\tlearn: 0.0030665\ttotal: 11.7s\tremaining: 24.3s\n",
      "326:\tlearn: 0.0030574\ttotal: 11.8s\tremaining: 24.2s\n",
      "327:\tlearn: 0.0030526\ttotal: 11.8s\tremaining: 24.2s\n",
      "328:\tlearn: 0.0030488\ttotal: 11.9s\tremaining: 24.2s\n",
      "329:\tlearn: 0.0030441\ttotal: 11.9s\tremaining: 24.1s\n",
      "330:\tlearn: 0.0030347\ttotal: 11.9s\tremaining: 24.1s\n",
      "331:\tlearn: 0.0030324\ttotal: 11.9s\tremaining: 24s\n",
      "332:\tlearn: 0.0030099\ttotal: 12s\tremaining: 24s\n",
      "333:\tlearn: 0.0029988\ttotal: 12s\tremaining: 24s\n",
      "334:\tlearn: 0.0029895\ttotal: 12.1s\tremaining: 23.9s\n",
      "335:\tlearn: 0.0029740\ttotal: 12.1s\tremaining: 23.9s\n",
      "336:\tlearn: 0.0029688\ttotal: 12.1s\tremaining: 23.8s\n",
      "337:\tlearn: 0.0029659\ttotal: 12.1s\tremaining: 23.8s\n",
      "338:\tlearn: 0.0029626\ttotal: 12.2s\tremaining: 23.7s\n",
      "339:\tlearn: 0.0029615\ttotal: 12.2s\tremaining: 23.7s\n",
      "340:\tlearn: 0.0029318\ttotal: 12.2s\tremaining: 23.6s\n",
      "341:\tlearn: 0.0029234\ttotal: 12.3s\tremaining: 23.6s\n",
      "342:\tlearn: 0.0029006\ttotal: 12.3s\tremaining: 23.6s\n",
      "343:\tlearn: 0.0028947\ttotal: 12.3s\tremaining: 23.5s\n",
      "344:\tlearn: 0.0028706\ttotal: 12.4s\tremaining: 23.5s\n",
      "345:\tlearn: 0.0028540\ttotal: 12.4s\tremaining: 23.4s\n",
      "346:\tlearn: 0.0028494\ttotal: 12.4s\tremaining: 23.4s\n",
      "347:\tlearn: 0.0028457\ttotal: 12.5s\tremaining: 23.3s\n",
      "348:\tlearn: 0.0028382\ttotal: 12.5s\tremaining: 23.3s\n",
      "349:\tlearn: 0.0028363\ttotal: 12.5s\tremaining: 23.3s\n",
      "350:\tlearn: 0.0028329\ttotal: 12.5s\tremaining: 23.2s\n",
      "351:\tlearn: 0.0028276\ttotal: 12.6s\tremaining: 23.2s\n",
      "352:\tlearn: 0.0028170\ttotal: 12.6s\tremaining: 23.1s\n",
      "353:\tlearn: 0.0027919\ttotal: 12.6s\tremaining: 23.1s\n",
      "354:\tlearn: 0.0027703\ttotal: 12.7s\tremaining: 23s\n",
      "355:\tlearn: 0.0027532\ttotal: 12.7s\tremaining: 23s\n",
      "356:\tlearn: 0.0027458\ttotal: 12.8s\tremaining: 23s\n",
      "357:\tlearn: 0.0027298\ttotal: 12.8s\tremaining: 23s\n",
      "358:\tlearn: 0.0027282\ttotal: 12.9s\tremaining: 23s\n",
      "359:\tlearn: 0.0027218\ttotal: 12.9s\tremaining: 22.9s\n",
      "360:\tlearn: 0.0027179\ttotal: 12.9s\tremaining: 22.9s\n",
      "361:\tlearn: 0.0027130\ttotal: 13s\tremaining: 22.9s\n",
      "362:\tlearn: 0.0026931\ttotal: 13s\tremaining: 22.9s\n",
      "363:\tlearn: 0.0026895\ttotal: 13.1s\tremaining: 22.9s\n",
      "364:\tlearn: 0.0026842\ttotal: 13.1s\tremaining: 22.8s\n",
      "365:\tlearn: 0.0026792\ttotal: 13.2s\tremaining: 22.8s\n",
      "366:\tlearn: 0.0026763\ttotal: 13.2s\tremaining: 22.7s\n",
      "367:\tlearn: 0.0026572\ttotal: 13.2s\tremaining: 22.7s\n",
      "368:\tlearn: 0.0026534\ttotal: 13.3s\tremaining: 22.7s\n",
      "369:\tlearn: 0.0026413\ttotal: 13.3s\tremaining: 22.7s\n",
      "370:\tlearn: 0.0026361\ttotal: 13.3s\tremaining: 22.6s\n",
      "371:\tlearn: 0.0026251\ttotal: 13.4s\tremaining: 22.6s\n",
      "372:\tlearn: 0.0026094\ttotal: 13.4s\tremaining: 22.6s\n",
      "373:\tlearn: 0.0025889\ttotal: 13.5s\tremaining: 22.6s\n",
      "374:\tlearn: 0.0025777\ttotal: 13.6s\tremaining: 22.6s\n",
      "375:\tlearn: 0.0025678\ttotal: 13.6s\tremaining: 22.6s\n",
      "376:\tlearn: 0.0025551\ttotal: 13.6s\tremaining: 22.5s\n",
      "377:\tlearn: 0.0025185\ttotal: 13.7s\tremaining: 22.5s\n",
      "378:\tlearn: 0.0025095\ttotal: 13.7s\tremaining: 22.5s\n",
      "379:\tlearn: 0.0024954\ttotal: 13.7s\tremaining: 22.4s\n",
      "380:\tlearn: 0.0024740\ttotal: 13.8s\tremaining: 22.4s\n",
      "381:\tlearn: 0.0024676\ttotal: 13.8s\tremaining: 22.4s\n",
      "382:\tlearn: 0.0024668\ttotal: 13.9s\tremaining: 22.3s\n",
      "383:\tlearn: 0.0024522\ttotal: 13.9s\tremaining: 22.3s\n",
      "384:\tlearn: 0.0024503\ttotal: 13.9s\tremaining: 22.3s\n",
      "385:\tlearn: 0.0024460\ttotal: 14s\tremaining: 22.2s\n",
      "386:\tlearn: 0.0024416\ttotal: 14s\tremaining: 22.2s\n",
      "387:\tlearn: 0.0024249\ttotal: 14.1s\tremaining: 22.2s\n",
      "388:\tlearn: 0.0024194\ttotal: 14.1s\tremaining: 22.2s\n",
      "389:\tlearn: 0.0024174\ttotal: 14.2s\tremaining: 22.2s\n",
      "390:\tlearn: 0.0024061\ttotal: 14.2s\tremaining: 22.2s\n",
      "391:\tlearn: 0.0024051\ttotal: 14.3s\tremaining: 22.1s\n",
      "392:\tlearn: 0.0024018\ttotal: 14.3s\tremaining: 22.1s\n",
      "393:\tlearn: 0.0024011\ttotal: 14.3s\tremaining: 22.1s\n",
      "394:\tlearn: 0.0023925\ttotal: 14.4s\tremaining: 22s\n",
      "395:\tlearn: 0.0023848\ttotal: 14.4s\tremaining: 22s\n",
      "396:\tlearn: 0.0023686\ttotal: 14.4s\tremaining: 21.9s\n",
      "397:\tlearn: 0.0023677\ttotal: 14.5s\tremaining: 21.9s\n",
      "398:\tlearn: 0.0023658\ttotal: 14.5s\tremaining: 21.8s\n",
      "399:\tlearn: 0.0023607\ttotal: 14.5s\tremaining: 21.8s\n",
      "400:\tlearn: 0.0023565\ttotal: 14.6s\tremaining: 21.8s\n",
      "401:\tlearn: 0.0023525\ttotal: 14.6s\tremaining: 21.7s\n",
      "402:\tlearn: 0.0023420\ttotal: 14.6s\tremaining: 21.7s\n",
      "403:\tlearn: 0.0023379\ttotal: 14.7s\tremaining: 21.7s\n",
      "404:\tlearn: 0.0023372\ttotal: 14.7s\tremaining: 21.6s\n",
      "405:\tlearn: 0.0023326\ttotal: 14.8s\tremaining: 21.6s\n",
      "406:\tlearn: 0.0023170\ttotal: 14.8s\tremaining: 21.6s\n",
      "407:\tlearn: 0.0023030\ttotal: 14.8s\tremaining: 21.5s\n",
      "408:\tlearn: 0.0023012\ttotal: 14.9s\tremaining: 21.5s\n",
      "409:\tlearn: 0.0022993\ttotal: 14.9s\tremaining: 21.5s\n",
      "410:\tlearn: 0.0022849\ttotal: 15s\tremaining: 21.4s\n",
      "411:\tlearn: 0.0022820\ttotal: 15s\tremaining: 21.4s\n",
      "412:\tlearn: 0.0022794\ttotal: 15s\tremaining: 21.4s\n",
      "413:\tlearn: 0.0022786\ttotal: 15.1s\tremaining: 21.3s\n",
      "414:\tlearn: 0.0022773\ttotal: 15.1s\tremaining: 21.3s\n",
      "415:\tlearn: 0.0022749\ttotal: 15.1s\tremaining: 21.2s\n",
      "416:\tlearn: 0.0022722\ttotal: 15.1s\tremaining: 21.2s\n",
      "417:\tlearn: 0.0022684\ttotal: 15.2s\tremaining: 21.1s\n",
      "418:\tlearn: 0.0022658\ttotal: 15.2s\tremaining: 21.1s\n",
      "419:\tlearn: 0.0022578\ttotal: 15.2s\tremaining: 21s\n",
      "420:\tlearn: 0.0022440\ttotal: 15.3s\tremaining: 21s\n",
      "421:\tlearn: 0.0022414\ttotal: 15.3s\tremaining: 21s\n",
      "422:\tlearn: 0.0022347\ttotal: 15.3s\tremaining: 20.9s\n",
      "423:\tlearn: 0.0022312\ttotal: 15.4s\tremaining: 20.9s\n",
      "424:\tlearn: 0.0022057\ttotal: 15.4s\tremaining: 20.8s\n",
      "425:\tlearn: 0.0021983\ttotal: 15.4s\tremaining: 20.8s\n",
      "426:\tlearn: 0.0021967\ttotal: 15.5s\tremaining: 20.7s\n",
      "427:\tlearn: 0.0021747\ttotal: 15.5s\tremaining: 20.7s\n",
      "428:\tlearn: 0.0021658\ttotal: 15.5s\tremaining: 20.7s\n",
      "429:\tlearn: 0.0021616\ttotal: 15.6s\tremaining: 20.6s\n",
      "430:\tlearn: 0.0021607\ttotal: 15.6s\tremaining: 20.6s\n",
      "431:\tlearn: 0.0021563\ttotal: 15.6s\tremaining: 20.6s\n",
      "432:\tlearn: 0.0021550\ttotal: 15.7s\tremaining: 20.5s\n",
      "433:\tlearn: 0.0021531\ttotal: 15.7s\tremaining: 20.5s\n",
      "434:\tlearn: 0.0021509\ttotal: 15.7s\tremaining: 20.4s\n",
      "435:\tlearn: 0.0021500\ttotal: 15.8s\tremaining: 20.4s\n",
      "436:\tlearn: 0.0021440\ttotal: 15.8s\tremaining: 20.4s\n",
      "437:\tlearn: 0.0021422\ttotal: 15.8s\tremaining: 20.3s\n",
      "438:\tlearn: 0.0021386\ttotal: 15.9s\tremaining: 20.3s\n",
      "439:\tlearn: 0.0021359\ttotal: 15.9s\tremaining: 20.3s\n",
      "440:\tlearn: 0.0021233\ttotal: 16s\tremaining: 20.2s\n",
      "441:\tlearn: 0.0021218\ttotal: 16s\tremaining: 20.2s\n",
      "442:\tlearn: 0.0021109\ttotal: 16s\tremaining: 20.2s\n",
      "443:\tlearn: 0.0021052\ttotal: 16.1s\tremaining: 20.1s\n",
      "444:\tlearn: 0.0020915\ttotal: 16.1s\tremaining: 20.1s\n",
      "445:\tlearn: 0.0020807\ttotal: 16.2s\tremaining: 20.1s\n",
      "446:\tlearn: 0.0020801\ttotal: 16.2s\tremaining: 20s\n",
      "447:\tlearn: 0.0020775\ttotal: 16.2s\tremaining: 20s\n",
      "448:\tlearn: 0.0020770\ttotal: 16.3s\tremaining: 20s\n",
      "449:\tlearn: 0.0020748\ttotal: 16.3s\tremaining: 19.9s\n",
      "450:\tlearn: 0.0020726\ttotal: 16.3s\tremaining: 19.9s\n",
      "451:\tlearn: 0.0020661\ttotal: 16.4s\tremaining: 19.8s\n",
      "452:\tlearn: 0.0020647\ttotal: 16.4s\tremaining: 19.8s\n",
      "453:\tlearn: 0.0020629\ttotal: 16.4s\tremaining: 19.7s\n",
      "454:\tlearn: 0.0020618\ttotal: 16.5s\tremaining: 19.7s\n",
      "455:\tlearn: 0.0020549\ttotal: 16.5s\tremaining: 19.7s\n",
      "456:\tlearn: 0.0020535\ttotal: 16.5s\tremaining: 19.6s\n",
      "457:\tlearn: 0.0020516\ttotal: 16.6s\tremaining: 19.6s\n",
      "458:\tlearn: 0.0020478\ttotal: 16.6s\tremaining: 19.6s\n",
      "459:\tlearn: 0.0020467\ttotal: 16.6s\tremaining: 19.5s\n",
      "460:\tlearn: 0.0020444\ttotal: 16.6s\tremaining: 19.5s\n",
      "461:\tlearn: 0.0020415\ttotal: 16.7s\tremaining: 19.4s\n",
      "462:\tlearn: 0.0020381\ttotal: 16.7s\tremaining: 19.4s\n",
      "463:\tlearn: 0.0020331\ttotal: 16.7s\tremaining: 19.3s\n",
      "464:\tlearn: 0.0020199\ttotal: 16.8s\tremaining: 19.3s\n",
      "465:\tlearn: 0.0020159\ttotal: 16.8s\tremaining: 19.3s\n",
      "466:\tlearn: 0.0020154\ttotal: 16.8s\tremaining: 19.2s\n",
      "467:\tlearn: 0.0019970\ttotal: 16.9s\tremaining: 19.2s\n",
      "468:\tlearn: 0.0019949\ttotal: 16.9s\tremaining: 19.1s\n",
      "469:\tlearn: 0.0019926\ttotal: 16.9s\tremaining: 19.1s\n",
      "470:\tlearn: 0.0019911\ttotal: 17s\tremaining: 19.1s\n",
      "471:\tlearn: 0.0019755\ttotal: 17s\tremaining: 19s\n",
      "472:\tlearn: 0.0019710\ttotal: 17s\tremaining: 19s\n",
      "473:\tlearn: 0.0019676\ttotal: 17.1s\tremaining: 18.9s\n",
      "474:\tlearn: 0.0019672\ttotal: 17.1s\tremaining: 18.9s\n",
      "475:\tlearn: 0.0019575\ttotal: 17.1s\tremaining: 18.9s\n",
      "476:\tlearn: 0.0019554\ttotal: 17.2s\tremaining: 18.8s\n",
      "477:\tlearn: 0.0019540\ttotal: 17.2s\tremaining: 18.8s\n",
      "478:\tlearn: 0.0019536\ttotal: 17.2s\tremaining: 18.7s\n",
      "479:\tlearn: 0.0019474\ttotal: 17.3s\tremaining: 18.7s\n",
      "480:\tlearn: 0.0019457\ttotal: 17.3s\tremaining: 18.7s\n",
      "481:\tlearn: 0.0019440\ttotal: 17.3s\tremaining: 18.6s\n",
      "482:\tlearn: 0.0019395\ttotal: 17.4s\tremaining: 18.6s\n",
      "483:\tlearn: 0.0019378\ttotal: 17.4s\tremaining: 18.5s\n",
      "484:\tlearn: 0.0019272\ttotal: 17.4s\tremaining: 18.5s\n",
      "485:\tlearn: 0.0019250\ttotal: 17.5s\tremaining: 18.5s\n",
      "486:\tlearn: 0.0019159\ttotal: 17.5s\tremaining: 18.4s\n",
      "487:\tlearn: 0.0019156\ttotal: 17.5s\tremaining: 18.4s\n",
      "488:\tlearn: 0.0019145\ttotal: 17.6s\tremaining: 18.4s\n",
      "489:\tlearn: 0.0019019\ttotal: 17.6s\tremaining: 18.3s\n",
      "490:\tlearn: 0.0018967\ttotal: 17.6s\tremaining: 18.3s\n",
      "491:\tlearn: 0.0018947\ttotal: 17.7s\tremaining: 18.3s\n",
      "492:\tlearn: 0.0018944\ttotal: 17.7s\tremaining: 18.2s\n",
      "493:\tlearn: 0.0018819\ttotal: 17.8s\tremaining: 18.2s\n",
      "494:\tlearn: 0.0018801\ttotal: 17.8s\tremaining: 18.2s\n",
      "495:\tlearn: 0.0018796\ttotal: 17.8s\tremaining: 18.1s\n",
      "496:\tlearn: 0.0018779\ttotal: 17.9s\tremaining: 18.1s\n",
      "497:\tlearn: 0.0018761\ttotal: 17.9s\tremaining: 18s\n",
      "498:\tlearn: 0.0018736\ttotal: 17.9s\tremaining: 18s\n",
      "499:\tlearn: 0.0018716\ttotal: 17.9s\tremaining: 17.9s\n",
      "500:\tlearn: 0.0018713\ttotal: 18s\tremaining: 17.9s\n",
      "501:\tlearn: 0.0018704\ttotal: 18s\tremaining: 17.9s\n",
      "502:\tlearn: 0.0018701\ttotal: 18s\tremaining: 17.8s\n",
      "503:\tlearn: 0.0018695\ttotal: 18.1s\tremaining: 17.8s\n",
      "504:\tlearn: 0.0018693\ttotal: 18.1s\tremaining: 17.7s\n",
      "505:\tlearn: 0.0018676\ttotal: 18.1s\tremaining: 17.7s\n",
      "506:\tlearn: 0.0018667\ttotal: 18.2s\tremaining: 17.7s\n",
      "507:\tlearn: 0.0018579\ttotal: 18.2s\tremaining: 17.6s\n",
      "508:\tlearn: 0.0018562\ttotal: 18.2s\tremaining: 17.6s\n",
      "509:\tlearn: 0.0018506\ttotal: 18.3s\tremaining: 17.6s\n",
      "510:\tlearn: 0.0018488\ttotal: 18.3s\tremaining: 17.5s\n",
      "511:\tlearn: 0.0018471\ttotal: 18.3s\tremaining: 17.5s\n",
      "512:\tlearn: 0.0018463\ttotal: 18.4s\tremaining: 17.4s\n",
      "513:\tlearn: 0.0018438\ttotal: 18.4s\tremaining: 17.4s\n",
      "514:\tlearn: 0.0018427\ttotal: 18.4s\tremaining: 17.4s\n",
      "515:\tlearn: 0.0018409\ttotal: 18.5s\tremaining: 17.3s\n",
      "516:\tlearn: 0.0018384\ttotal: 18.5s\tremaining: 17.3s\n",
      "517:\tlearn: 0.0018374\ttotal: 18.5s\tremaining: 17.2s\n",
      "518:\tlearn: 0.0018327\ttotal: 18.6s\tremaining: 17.2s\n",
      "519:\tlearn: 0.0018205\ttotal: 18.6s\tremaining: 17.2s\n",
      "520:\tlearn: 0.0018190\ttotal: 18.6s\tremaining: 17.1s\n",
      "521:\tlearn: 0.0018159\ttotal: 18.7s\tremaining: 17.1s\n",
      "522:\tlearn: 0.0018148\ttotal: 18.7s\tremaining: 17s\n",
      "523:\tlearn: 0.0018132\ttotal: 18.7s\tremaining: 17s\n",
      "524:\tlearn: 0.0018112\ttotal: 18.8s\tremaining: 17s\n",
      "525:\tlearn: 0.0018087\ttotal: 18.8s\tremaining: 16.9s\n",
      "526:\tlearn: 0.0017971\ttotal: 18.8s\tremaining: 16.9s\n",
      "527:\tlearn: 0.0017954\ttotal: 18.9s\tremaining: 16.9s\n",
      "528:\tlearn: 0.0017944\ttotal: 18.9s\tremaining: 16.8s\n",
      "529:\tlearn: 0.0017934\ttotal: 18.9s\tremaining: 16.8s\n",
      "530:\tlearn: 0.0017933\ttotal: 18.9s\tremaining: 16.7s\n",
      "531:\tlearn: 0.0017825\ttotal: 19s\tremaining: 16.7s\n",
      "532:\tlearn: 0.0017815\ttotal: 19s\tremaining: 16.7s\n",
      "533:\tlearn: 0.0017712\ttotal: 19s\tremaining: 16.6s\n",
      "534:\tlearn: 0.0017694\ttotal: 19.1s\tremaining: 16.6s\n",
      "535:\tlearn: 0.0017692\ttotal: 19.1s\tremaining: 16.5s\n",
      "536:\tlearn: 0.0017589\ttotal: 19.1s\tremaining: 16.5s\n",
      "537:\tlearn: 0.0017581\ttotal: 19.2s\tremaining: 16.5s\n",
      "538:\tlearn: 0.0017567\ttotal: 19.2s\tremaining: 16.4s\n",
      "539:\tlearn: 0.0017458\ttotal: 19.2s\tremaining: 16.4s\n",
      "540:\tlearn: 0.0017457\ttotal: 19.3s\tremaining: 16.4s\n",
      "541:\tlearn: 0.0017440\ttotal: 19.3s\tremaining: 16.3s\n",
      "542:\tlearn: 0.0017429\ttotal: 19.3s\tremaining: 16.3s\n",
      "543:\tlearn: 0.0017341\ttotal: 19.4s\tremaining: 16.2s\n",
      "544:\tlearn: 0.0017329\ttotal: 19.4s\tremaining: 16.2s\n",
      "545:\tlearn: 0.0017323\ttotal: 19.4s\tremaining: 16.2s\n",
      "546:\tlearn: 0.0017249\ttotal: 19.5s\tremaining: 16.1s\n",
      "547:\tlearn: 0.0017239\ttotal: 19.5s\tremaining: 16.1s\n",
      "548:\tlearn: 0.0017224\ttotal: 19.5s\tremaining: 16s\n",
      "549:\tlearn: 0.0017134\ttotal: 19.6s\tremaining: 16s\n",
      "550:\tlearn: 0.0017125\ttotal: 19.6s\tremaining: 16s\n",
      "551:\tlearn: 0.0017112\ttotal: 19.6s\tremaining: 15.9s\n",
      "552:\tlearn: 0.0017106\ttotal: 19.7s\tremaining: 15.9s\n",
      "553:\tlearn: 0.0017094\ttotal: 19.7s\tremaining: 15.8s\n",
      "554:\tlearn: 0.0017092\ttotal: 19.7s\tremaining: 15.8s\n",
      "555:\tlearn: 0.0017071\ttotal: 19.7s\tremaining: 15.8s\n",
      "556:\tlearn: 0.0016991\ttotal: 19.8s\tremaining: 15.7s\n",
      "557:\tlearn: 0.0016974\ttotal: 19.8s\tremaining: 15.7s\n",
      "558:\tlearn: 0.0016957\ttotal: 19.8s\tremaining: 15.7s\n",
      "559:\tlearn: 0.0016865\ttotal: 19.9s\tremaining: 15.6s\n",
      "560:\tlearn: 0.0016829\ttotal: 19.9s\tremaining: 15.6s\n",
      "561:\tlearn: 0.0016777\ttotal: 19.9s\tremaining: 15.5s\n",
      "562:\tlearn: 0.0016771\ttotal: 20s\tremaining: 15.5s\n",
      "563:\tlearn: 0.0016769\ttotal: 20s\tremaining: 15.5s\n",
      "564:\tlearn: 0.0016757\ttotal: 20s\tremaining: 15.4s\n",
      "565:\tlearn: 0.0016679\ttotal: 20.1s\tremaining: 15.4s\n",
      "566:\tlearn: 0.0016554\ttotal: 20.1s\tremaining: 15.3s\n",
      "567:\tlearn: 0.0016487\ttotal: 20.1s\tremaining: 15.3s\n",
      "568:\tlearn: 0.0016466\ttotal: 20.2s\tremaining: 15.3s\n",
      "569:\tlearn: 0.0016450\ttotal: 20.2s\tremaining: 15.2s\n",
      "570:\tlearn: 0.0016341\ttotal: 20.2s\tremaining: 15.2s\n",
      "571:\tlearn: 0.0016310\ttotal: 20.3s\tremaining: 15.2s\n",
      "572:\tlearn: 0.0016307\ttotal: 20.3s\tremaining: 15.1s\n",
      "573:\tlearn: 0.0016294\ttotal: 20.3s\tremaining: 15.1s\n",
      "574:\tlearn: 0.0016288\ttotal: 20.3s\tremaining: 15s\n",
      "575:\tlearn: 0.0016252\ttotal: 20.4s\tremaining: 15s\n",
      "576:\tlearn: 0.0016222\ttotal: 20.4s\tremaining: 15s\n",
      "577:\tlearn: 0.0016215\ttotal: 20.4s\tremaining: 14.9s\n",
      "578:\tlearn: 0.0016184\ttotal: 20.5s\tremaining: 14.9s\n",
      "579:\tlearn: 0.0016110\ttotal: 20.5s\tremaining: 14.9s\n",
      "580:\tlearn: 0.0016034\ttotal: 20.5s\tremaining: 14.8s\n",
      "581:\tlearn: 0.0015982\ttotal: 20.6s\tremaining: 14.8s\n",
      "582:\tlearn: 0.0015916\ttotal: 20.6s\tremaining: 14.7s\n",
      "583:\tlearn: 0.0015853\ttotal: 20.7s\tremaining: 14.7s\n",
      "584:\tlearn: 0.0015808\ttotal: 20.7s\tremaining: 14.7s\n",
      "585:\tlearn: 0.0015745\ttotal: 20.7s\tremaining: 14.6s\n",
      "586:\tlearn: 0.0015732\ttotal: 20.8s\tremaining: 14.6s\n",
      "587:\tlearn: 0.0015730\ttotal: 20.8s\tremaining: 14.6s\n",
      "588:\tlearn: 0.0015725\ttotal: 20.8s\tremaining: 14.5s\n",
      "589:\tlearn: 0.0015692\ttotal: 20.8s\tremaining: 14.5s\n",
      "590:\tlearn: 0.0015690\ttotal: 20.9s\tremaining: 14.4s\n",
      "591:\tlearn: 0.0015607\ttotal: 20.9s\tremaining: 14.4s\n",
      "592:\tlearn: 0.0015601\ttotal: 20.9s\tremaining: 14.4s\n",
      "593:\tlearn: 0.0015590\ttotal: 21s\tremaining: 14.3s\n",
      "594:\tlearn: 0.0015589\ttotal: 21s\tremaining: 14.3s\n",
      "595:\tlearn: 0.0015579\ttotal: 21s\tremaining: 14.3s\n",
      "596:\tlearn: 0.0015495\ttotal: 21.1s\tremaining: 14.2s\n",
      "597:\tlearn: 0.0015428\ttotal: 21.1s\tremaining: 14.2s\n",
      "598:\tlearn: 0.0015418\ttotal: 21.1s\tremaining: 14.1s\n",
      "599:\tlearn: 0.0015390\ttotal: 21.2s\tremaining: 14.1s\n",
      "600:\tlearn: 0.0015377\ttotal: 21.2s\tremaining: 14.1s\n",
      "601:\tlearn: 0.0015364\ttotal: 21.2s\tremaining: 14s\n",
      "602:\tlearn: 0.0015360\ttotal: 21.3s\tremaining: 14s\n",
      "603:\tlearn: 0.0015319\ttotal: 21.3s\tremaining: 14s\n",
      "604:\tlearn: 0.0015310\ttotal: 21.3s\tremaining: 13.9s\n",
      "605:\tlearn: 0.0015296\ttotal: 21.4s\tremaining: 13.9s\n",
      "606:\tlearn: 0.0015291\ttotal: 21.4s\tremaining: 13.8s\n",
      "607:\tlearn: 0.0015231\ttotal: 21.4s\tremaining: 13.8s\n",
      "608:\tlearn: 0.0015221\ttotal: 21.5s\tremaining: 13.8s\n",
      "609:\tlearn: 0.0015215\ttotal: 21.5s\tremaining: 13.7s\n",
      "610:\tlearn: 0.0015185\ttotal: 21.5s\tremaining: 13.7s\n",
      "611:\tlearn: 0.0015173\ttotal: 21.5s\tremaining: 13.7s\n",
      "612:\tlearn: 0.0015135\ttotal: 21.6s\tremaining: 13.6s\n",
      "613:\tlearn: 0.0015125\ttotal: 21.6s\tremaining: 13.6s\n",
      "614:\tlearn: 0.0015110\ttotal: 21.6s\tremaining: 13.5s\n",
      "615:\tlearn: 0.0015109\ttotal: 21.7s\tremaining: 13.5s\n",
      "616:\tlearn: 0.0015103\ttotal: 21.7s\tremaining: 13.5s\n",
      "617:\tlearn: 0.0015006\ttotal: 21.7s\tremaining: 13.4s\n",
      "618:\tlearn: 0.0015002\ttotal: 21.8s\tremaining: 13.4s\n",
      "619:\tlearn: 0.0014985\ttotal: 21.8s\tremaining: 13.4s\n",
      "620:\tlearn: 0.0014970\ttotal: 21.8s\tremaining: 13.3s\n",
      "621:\tlearn: 0.0014967\ttotal: 21.9s\tremaining: 13.3s\n",
      "622:\tlearn: 0.0014964\ttotal: 21.9s\tremaining: 13.2s\n",
      "623:\tlearn: 0.0014957\ttotal: 21.9s\tremaining: 13.2s\n",
      "624:\tlearn: 0.0014955\ttotal: 22s\tremaining: 13.2s\n",
      "625:\tlearn: 0.0014947\ttotal: 22s\tremaining: 13.1s\n",
      "626:\tlearn: 0.0014943\ttotal: 22s\tremaining: 13.1s\n",
      "627:\tlearn: 0.0014941\ttotal: 22s\tremaining: 13.1s\n",
      "628:\tlearn: 0.0014934\ttotal: 22.1s\tremaining: 13s\n",
      "629:\tlearn: 0.0014930\ttotal: 22.1s\tremaining: 13s\n",
      "630:\tlearn: 0.0014919\ttotal: 22.1s\tremaining: 12.9s\n",
      "631:\tlearn: 0.0014892\ttotal: 22.2s\tremaining: 12.9s\n",
      "632:\tlearn: 0.0014808\ttotal: 22.2s\tremaining: 12.9s\n",
      "633:\tlearn: 0.0014726\ttotal: 22.2s\tremaining: 12.8s\n",
      "634:\tlearn: 0.0014722\ttotal: 22.3s\tremaining: 12.8s\n",
      "635:\tlearn: 0.0014715\ttotal: 22.3s\tremaining: 12.8s\n",
      "636:\tlearn: 0.0014699\ttotal: 22.3s\tremaining: 12.7s\n",
      "637:\tlearn: 0.0014697\ttotal: 22.4s\tremaining: 12.7s\n",
      "638:\tlearn: 0.0014626\ttotal: 22.4s\tremaining: 12.7s\n",
      "639:\tlearn: 0.0014625\ttotal: 22.4s\tremaining: 12.6s\n",
      "640:\tlearn: 0.0014611\ttotal: 22.5s\tremaining: 12.6s\n",
      "641:\tlearn: 0.0014607\ttotal: 22.5s\tremaining: 12.5s\n",
      "642:\tlearn: 0.0014605\ttotal: 22.5s\tremaining: 12.5s\n",
      "643:\tlearn: 0.0014594\ttotal: 22.5s\tremaining: 12.5s\n",
      "644:\tlearn: 0.0014486\ttotal: 22.6s\tremaining: 12.4s\n",
      "645:\tlearn: 0.0014480\ttotal: 22.6s\tremaining: 12.4s\n",
      "646:\tlearn: 0.0014435\ttotal: 22.6s\tremaining: 12.4s\n",
      "647:\tlearn: 0.0014407\ttotal: 22.7s\tremaining: 12.3s\n",
      "648:\tlearn: 0.0014401\ttotal: 22.7s\tremaining: 12.3s\n",
      "649:\tlearn: 0.0014397\ttotal: 22.7s\tremaining: 12.2s\n",
      "650:\tlearn: 0.0014389\ttotal: 22.8s\tremaining: 12.2s\n",
      "651:\tlearn: 0.0014382\ttotal: 22.8s\tremaining: 12.2s\n",
      "652:\tlearn: 0.0014380\ttotal: 22.8s\tremaining: 12.1s\n",
      "653:\tlearn: 0.0014361\ttotal: 22.9s\tremaining: 12.1s\n",
      "654:\tlearn: 0.0014356\ttotal: 22.9s\tremaining: 12.1s\n",
      "655:\tlearn: 0.0014354\ttotal: 22.9s\tremaining: 12s\n",
      "656:\tlearn: 0.0014339\ttotal: 23s\tremaining: 12s\n",
      "657:\tlearn: 0.0014302\ttotal: 23s\tremaining: 11.9s\n",
      "658:\tlearn: 0.0014285\ttotal: 23s\tremaining: 11.9s\n",
      "659:\tlearn: 0.0014283\ttotal: 23.1s\tremaining: 11.9s\n",
      "660:\tlearn: 0.0014275\ttotal: 23.1s\tremaining: 11.8s\n",
      "661:\tlearn: 0.0014274\ttotal: 23.1s\tremaining: 11.8s\n",
      "662:\tlearn: 0.0014269\ttotal: 23.2s\tremaining: 11.8s\n",
      "663:\tlearn: 0.0014189\ttotal: 23.2s\tremaining: 11.7s\n",
      "664:\tlearn: 0.0014189\ttotal: 23.2s\tremaining: 11.7s\n",
      "665:\tlearn: 0.0014186\ttotal: 23.3s\tremaining: 11.7s\n",
      "666:\tlearn: 0.0014116\ttotal: 23.3s\tremaining: 11.6s\n",
      "667:\tlearn: 0.0014114\ttotal: 23.3s\tremaining: 11.6s\n",
      "668:\tlearn: 0.0014108\ttotal: 23.3s\tremaining: 11.6s\n",
      "669:\tlearn: 0.0014104\ttotal: 23.4s\tremaining: 11.5s\n",
      "670:\tlearn: 0.0014096\ttotal: 23.4s\tremaining: 11.5s\n",
      "671:\tlearn: 0.0014092\ttotal: 23.4s\tremaining: 11.4s\n",
      "672:\tlearn: 0.0014086\ttotal: 23.5s\tremaining: 11.4s\n",
      "673:\tlearn: 0.0014016\ttotal: 23.5s\tremaining: 11.4s\n",
      "674:\tlearn: 0.0014013\ttotal: 23.5s\tremaining: 11.3s\n",
      "675:\tlearn: 0.0014009\ttotal: 23.6s\tremaining: 11.3s\n",
      "676:\tlearn: 0.0013978\ttotal: 23.6s\tremaining: 11.3s\n",
      "677:\tlearn: 0.0013969\ttotal: 23.6s\tremaining: 11.2s\n",
      "678:\tlearn: 0.0013963\ttotal: 23.7s\tremaining: 11.2s\n",
      "679:\tlearn: 0.0013962\ttotal: 23.7s\tremaining: 11.2s\n",
      "680:\tlearn: 0.0013958\ttotal: 23.7s\tremaining: 11.1s\n",
      "681:\tlearn: 0.0013958\ttotal: 23.8s\tremaining: 11.1s\n",
      "682:\tlearn: 0.0013953\ttotal: 23.8s\tremaining: 11s\n",
      "683:\tlearn: 0.0013952\ttotal: 23.8s\tremaining: 11s\n",
      "684:\tlearn: 0.0013952\ttotal: 23.9s\tremaining: 11s\n",
      "685:\tlearn: 0.0013951\ttotal: 23.9s\tremaining: 10.9s\n",
      "686:\tlearn: 0.0013950\ttotal: 23.9s\tremaining: 10.9s\n",
      "687:\tlearn: 0.0013946\ttotal: 24s\tremaining: 10.9s\n",
      "688:\tlearn: 0.0013942\ttotal: 24s\tremaining: 10.8s\n",
      "689:\tlearn: 0.0013939\ttotal: 24s\tremaining: 10.8s\n",
      "690:\tlearn: 0.0013938\ttotal: 24s\tremaining: 10.7s\n",
      "691:\tlearn: 0.0013937\ttotal: 24.1s\tremaining: 10.7s\n",
      "692:\tlearn: 0.0013934\ttotal: 24.2s\tremaining: 10.7s\n",
      "693:\tlearn: 0.0013933\ttotal: 24.2s\tremaining: 10.7s\n",
      "694:\tlearn: 0.0013922\ttotal: 24.2s\tremaining: 10.6s\n",
      "695:\tlearn: 0.0013911\ttotal: 24.2s\tremaining: 10.6s\n",
      "696:\tlearn: 0.0013908\ttotal: 24.3s\tremaining: 10.6s\n",
      "697:\tlearn: 0.0013900\ttotal: 24.3s\tremaining: 10.5s\n",
      "698:\tlearn: 0.0013899\ttotal: 24.3s\tremaining: 10.5s\n",
      "699:\tlearn: 0.0013891\ttotal: 24.4s\tremaining: 10.4s\n",
      "700:\tlearn: 0.0013882\ttotal: 24.4s\tremaining: 10.4s\n",
      "701:\tlearn: 0.0013878\ttotal: 24.4s\tremaining: 10.4s\n",
      "702:\tlearn: 0.0013869\ttotal: 24.5s\tremaining: 10.3s\n",
      "703:\tlearn: 0.0013865\ttotal: 24.5s\tremaining: 10.3s\n",
      "704:\tlearn: 0.0013865\ttotal: 24.5s\tremaining: 10.3s\n",
      "705:\tlearn: 0.0013860\ttotal: 24.6s\tremaining: 10.2s\n",
      "706:\tlearn: 0.0013859\ttotal: 24.6s\tremaining: 10.2s\n",
      "707:\tlearn: 0.0013780\ttotal: 24.6s\tremaining: 10.2s\n",
      "708:\tlearn: 0.0013770\ttotal: 24.7s\tremaining: 10.1s\n",
      "709:\tlearn: 0.0013764\ttotal: 24.7s\tremaining: 10.1s\n",
      "710:\tlearn: 0.0013763\ttotal: 24.7s\tremaining: 10s\n",
      "711:\tlearn: 0.0013760\ttotal: 24.7s\tremaining: 10s\n",
      "712:\tlearn: 0.0013759\ttotal: 24.8s\tremaining: 9.97s\n",
      "713:\tlearn: 0.0013691\ttotal: 24.8s\tremaining: 9.94s\n",
      "714:\tlearn: 0.0013691\ttotal: 24.8s\tremaining: 9.9s\n",
      "715:\tlearn: 0.0013630\ttotal: 24.9s\tremaining: 9.87s\n",
      "716:\tlearn: 0.0013599\ttotal: 24.9s\tremaining: 9.83s\n",
      "717:\tlearn: 0.0013595\ttotal: 24.9s\tremaining: 9.79s\n",
      "718:\tlearn: 0.0013587\ttotal: 25s\tremaining: 9.76s\n",
      "719:\tlearn: 0.0013579\ttotal: 25s\tremaining: 9.72s\n",
      "720:\tlearn: 0.0013549\ttotal: 25s\tremaining: 9.68s\n",
      "721:\tlearn: 0.0013540\ttotal: 25.1s\tremaining: 9.65s\n",
      "722:\tlearn: 0.0013538\ttotal: 25.1s\tremaining: 9.61s\n",
      "723:\tlearn: 0.0013491\ttotal: 25.1s\tremaining: 9.58s\n",
      "724:\tlearn: 0.0013481\ttotal: 25.2s\tremaining: 9.54s\n",
      "725:\tlearn: 0.0013478\ttotal: 25.2s\tremaining: 9.51s\n",
      "726:\tlearn: 0.0013395\ttotal: 25.2s\tremaining: 9.47s\n",
      "727:\tlearn: 0.0013386\ttotal: 25.3s\tremaining: 9.44s\n",
      "728:\tlearn: 0.0013382\ttotal: 25.3s\tremaining: 9.4s\n",
      "729:\tlearn: 0.0013382\ttotal: 25.3s\tremaining: 9.36s\n",
      "730:\tlearn: 0.0013380\ttotal: 25.3s\tremaining: 9.32s\n",
      "731:\tlearn: 0.0013378\ttotal: 25.4s\tremaining: 9.29s\n",
      "732:\tlearn: 0.0013373\ttotal: 25.4s\tremaining: 9.26s\n",
      "733:\tlearn: 0.0013366\ttotal: 25.4s\tremaining: 9.22s\n",
      "734:\tlearn: 0.0013304\ttotal: 25.5s\tremaining: 9.19s\n",
      "735:\tlearn: 0.0013255\ttotal: 25.5s\tremaining: 9.15s\n",
      "736:\tlearn: 0.0013213\ttotal: 25.5s\tremaining: 9.12s\n",
      "737:\tlearn: 0.0013211\ttotal: 25.6s\tremaining: 9.08s\n",
      "738:\tlearn: 0.0013211\ttotal: 25.6s\tremaining: 9.04s\n",
      "739:\tlearn: 0.0013168\ttotal: 25.6s\tremaining: 9.01s\n",
      "740:\tlearn: 0.0013158\ttotal: 25.7s\tremaining: 8.97s\n",
      "741:\tlearn: 0.0013156\ttotal: 25.7s\tremaining: 8.94s\n",
      "742:\tlearn: 0.0013092\ttotal: 25.7s\tremaining: 8.9s\n",
      "743:\tlearn: 0.0013091\ttotal: 25.8s\tremaining: 8.87s\n",
      "744:\tlearn: 0.0013075\ttotal: 25.8s\tremaining: 8.83s\n",
      "745:\tlearn: 0.0013074\ttotal: 25.8s\tremaining: 8.79s\n",
      "746:\tlearn: 0.0013014\ttotal: 25.9s\tremaining: 8.76s\n",
      "747:\tlearn: 0.0012962\ttotal: 25.9s\tremaining: 8.73s\n",
      "748:\tlearn: 0.0012962\ttotal: 25.9s\tremaining: 8.69s\n",
      "749:\tlearn: 0.0012957\ttotal: 26s\tremaining: 8.65s\n",
      "750:\tlearn: 0.0012951\ttotal: 26s\tremaining: 8.62s\n",
      "751:\tlearn: 0.0012947\ttotal: 26s\tremaining: 8.58s\n",
      "752:\tlearn: 0.0012944\ttotal: 26.1s\tremaining: 8.55s\n",
      "753:\tlearn: 0.0012940\ttotal: 26.1s\tremaining: 8.51s\n",
      "754:\tlearn: 0.0012907\ttotal: 26.1s\tremaining: 8.48s\n",
      "755:\tlearn: 0.0012902\ttotal: 26.2s\tremaining: 8.44s\n",
      "756:\tlearn: 0.0012900\ttotal: 26.2s\tremaining: 8.4s\n",
      "757:\tlearn: 0.0012891\ttotal: 26.2s\tremaining: 8.37s\n",
      "758:\tlearn: 0.0012890\ttotal: 26.2s\tremaining: 8.33s\n",
      "759:\tlearn: 0.0012886\ttotal: 26.3s\tremaining: 8.29s\n",
      "760:\tlearn: 0.0012882\ttotal: 26.3s\tremaining: 8.26s\n",
      "761:\tlearn: 0.0012878\ttotal: 26.3s\tremaining: 8.22s\n",
      "762:\tlearn: 0.0012844\ttotal: 26.4s\tremaining: 8.19s\n",
      "763:\tlearn: 0.0012839\ttotal: 26.4s\tremaining: 8.15s\n",
      "764:\tlearn: 0.0012832\ttotal: 26.4s\tremaining: 8.12s\n",
      "765:\tlearn: 0.0012824\ttotal: 26.5s\tremaining: 8.08s\n",
      "766:\tlearn: 0.0012811\ttotal: 26.5s\tremaining: 8.04s\n",
      "767:\tlearn: 0.0012754\ttotal: 26.5s\tremaining: 8.01s\n",
      "768:\tlearn: 0.0012753\ttotal: 26.5s\tremaining: 7.97s\n",
      "769:\tlearn: 0.0012753\ttotal: 26.6s\tremaining: 7.94s\n",
      "770:\tlearn: 0.0012680\ttotal: 26.6s\tremaining: 7.9s\n",
      "771:\tlearn: 0.0012665\ttotal: 26.6s\tremaining: 7.87s\n",
      "772:\tlearn: 0.0012651\ttotal: 26.7s\tremaining: 7.83s\n",
      "773:\tlearn: 0.0012649\ttotal: 26.7s\tremaining: 7.8s\n",
      "774:\tlearn: 0.0012642\ttotal: 26.7s\tremaining: 7.76s\n",
      "775:\tlearn: 0.0012631\ttotal: 26.8s\tremaining: 7.73s\n",
      "776:\tlearn: 0.0012631\ttotal: 26.8s\tremaining: 7.69s\n",
      "777:\tlearn: 0.0012631\ttotal: 26.8s\tremaining: 7.66s\n",
      "778:\tlearn: 0.0012556\ttotal: 26.9s\tremaining: 7.62s\n",
      "779:\tlearn: 0.0012548\ttotal: 26.9s\tremaining: 7.59s\n",
      "780:\tlearn: 0.0012546\ttotal: 26.9s\tremaining: 7.55s\n",
      "781:\tlearn: 0.0012543\ttotal: 27s\tremaining: 7.51s\n",
      "782:\tlearn: 0.0012512\ttotal: 27s\tremaining: 7.48s\n",
      "783:\tlearn: 0.0012467\ttotal: 27s\tremaining: 7.44s\n",
      "784:\tlearn: 0.0012466\ttotal: 27.1s\tremaining: 7.41s\n",
      "785:\tlearn: 0.0012462\ttotal: 27.1s\tremaining: 7.37s\n",
      "786:\tlearn: 0.0012461\ttotal: 27.1s\tremaining: 7.34s\n",
      "787:\tlearn: 0.0012441\ttotal: 27.1s\tremaining: 7.3s\n",
      "788:\tlearn: 0.0012439\ttotal: 27.2s\tremaining: 7.27s\n",
      "789:\tlearn: 0.0012436\ttotal: 27.2s\tremaining: 7.23s\n",
      "790:\tlearn: 0.0012435\ttotal: 27.2s\tremaining: 7.2s\n",
      "791:\tlearn: 0.0012435\ttotal: 27.3s\tremaining: 7.16s\n",
      "792:\tlearn: 0.0012431\ttotal: 27.3s\tremaining: 7.13s\n",
      "793:\tlearn: 0.0012430\ttotal: 27.3s\tremaining: 7.09s\n",
      "794:\tlearn: 0.0012426\ttotal: 27.4s\tremaining: 7.05s\n",
      "795:\tlearn: 0.0012418\ttotal: 27.4s\tremaining: 7.02s\n",
      "796:\tlearn: 0.0012418\ttotal: 27.4s\tremaining: 6.98s\n",
      "797:\tlearn: 0.0012417\ttotal: 27.4s\tremaining: 6.95s\n",
      "798:\tlearn: 0.0012409\ttotal: 27.5s\tremaining: 6.91s\n",
      "799:\tlearn: 0.0012409\ttotal: 27.5s\tremaining: 6.88s\n",
      "800:\tlearn: 0.0012402\ttotal: 27.5s\tremaining: 6.84s\n",
      "801:\tlearn: 0.0012402\ttotal: 27.6s\tremaining: 6.81s\n",
      "802:\tlearn: 0.0012397\ttotal: 27.6s\tremaining: 6.77s\n",
      "803:\tlearn: 0.0012365\ttotal: 27.6s\tremaining: 6.74s\n",
      "804:\tlearn: 0.0012362\ttotal: 27.7s\tremaining: 6.7s\n",
      "805:\tlearn: 0.0012299\ttotal: 27.7s\tremaining: 6.67s\n",
      "806:\tlearn: 0.0012295\ttotal: 27.7s\tremaining: 6.63s\n",
      "807:\tlearn: 0.0012248\ttotal: 27.8s\tremaining: 6.6s\n",
      "808:\tlearn: 0.0012248\ttotal: 27.8s\tremaining: 6.57s\n",
      "809:\tlearn: 0.0012242\ttotal: 27.8s\tremaining: 6.53s\n",
      "810:\tlearn: 0.0012234\ttotal: 27.9s\tremaining: 6.5s\n",
      "811:\tlearn: 0.0012215\ttotal: 27.9s\tremaining: 6.46s\n",
      "812:\tlearn: 0.0012215\ttotal: 27.9s\tremaining: 6.42s\n",
      "813:\tlearn: 0.0012167\ttotal: 28s\tremaining: 6.39s\n",
      "814:\tlearn: 0.0012167\ttotal: 28s\tremaining: 6.36s\n",
      "815:\tlearn: 0.0012148\ttotal: 28.1s\tremaining: 6.33s\n",
      "816:\tlearn: 0.0012138\ttotal: 28.1s\tremaining: 6.29s\n",
      "817:\tlearn: 0.0012138\ttotal: 28.1s\tremaining: 6.25s\n",
      "818:\tlearn: 0.0012138\ttotal: 28.1s\tremaining: 6.22s\n",
      "819:\tlearn: 0.0012133\ttotal: 28.2s\tremaining: 6.18s\n",
      "820:\tlearn: 0.0012128\ttotal: 28.2s\tremaining: 6.15s\n",
      "821:\tlearn: 0.0012122\ttotal: 28.2s\tremaining: 6.12s\n",
      "822:\tlearn: 0.0012101\ttotal: 28.3s\tremaining: 6.08s\n",
      "823:\tlearn: 0.0012080\ttotal: 28.3s\tremaining: 6.05s\n",
      "824:\tlearn: 0.0012060\ttotal: 28.3s\tremaining: 6.01s\n",
      "825:\tlearn: 0.0012059\ttotal: 28.4s\tremaining: 5.97s\n",
      "826:\tlearn: 0.0012050\ttotal: 28.4s\tremaining: 5.94s\n",
      "827:\tlearn: 0.0012048\ttotal: 28.4s\tremaining: 5.91s\n",
      "828:\tlearn: 0.0012048\ttotal: 28.5s\tremaining: 5.87s\n",
      "829:\tlearn: 0.0012047\ttotal: 28.5s\tremaining: 5.83s\n",
      "830:\tlearn: 0.0012047\ttotal: 28.5s\tremaining: 5.8s\n",
      "831:\tlearn: 0.0012045\ttotal: 28.5s\tremaining: 5.76s\n",
      "832:\tlearn: 0.0012034\ttotal: 28.6s\tremaining: 5.73s\n",
      "833:\tlearn: 0.0012032\ttotal: 28.6s\tremaining: 5.69s\n",
      "834:\tlearn: 0.0012024\ttotal: 28.6s\tremaining: 5.66s\n",
      "835:\tlearn: 0.0012018\ttotal: 28.7s\tremaining: 5.63s\n",
      "836:\tlearn: 0.0012017\ttotal: 28.7s\tremaining: 5.59s\n",
      "837:\tlearn: 0.0012011\ttotal: 28.7s\tremaining: 5.55s\n",
      "838:\tlearn: 0.0011983\ttotal: 28.8s\tremaining: 5.52s\n",
      "839:\tlearn: 0.0011906\ttotal: 28.8s\tremaining: 5.49s\n",
      "840:\tlearn: 0.0011906\ttotal: 28.8s\tremaining: 5.45s\n",
      "841:\tlearn: 0.0011901\ttotal: 28.9s\tremaining: 5.42s\n",
      "842:\tlearn: 0.0011899\ttotal: 28.9s\tremaining: 5.38s\n",
      "843:\tlearn: 0.0011896\ttotal: 28.9s\tremaining: 5.35s\n",
      "844:\tlearn: 0.0011896\ttotal: 29s\tremaining: 5.31s\n",
      "845:\tlearn: 0.0011887\ttotal: 29s\tremaining: 5.28s\n",
      "846:\tlearn: 0.0011886\ttotal: 29s\tremaining: 5.24s\n",
      "847:\tlearn: 0.0011884\ttotal: 29.1s\tremaining: 5.21s\n",
      "848:\tlearn: 0.0011881\ttotal: 29.1s\tremaining: 5.17s\n",
      "849:\tlearn: 0.0011881\ttotal: 29.1s\tremaining: 5.14s\n",
      "850:\tlearn: 0.0011879\ttotal: 29.1s\tremaining: 5.1s\n",
      "851:\tlearn: 0.0011875\ttotal: 29.2s\tremaining: 5.07s\n",
      "852:\tlearn: 0.0011838\ttotal: 29.2s\tremaining: 5.03s\n",
      "853:\tlearn: 0.0011798\ttotal: 29.2s\tremaining: 5s\n",
      "854:\tlearn: 0.0011796\ttotal: 29.3s\tremaining: 4.96s\n",
      "855:\tlearn: 0.0011795\ttotal: 29.3s\tremaining: 4.93s\n",
      "856:\tlearn: 0.0011789\ttotal: 29.3s\tremaining: 4.89s\n",
      "857:\tlearn: 0.0011788\ttotal: 29.4s\tremaining: 4.86s\n",
      "858:\tlearn: 0.0011780\ttotal: 29.4s\tremaining: 4.83s\n",
      "859:\tlearn: 0.0011779\ttotal: 29.4s\tremaining: 4.79s\n",
      "860:\tlearn: 0.0011779\ttotal: 29.5s\tremaining: 4.75s\n",
      "861:\tlearn: 0.0011773\ttotal: 29.5s\tremaining: 4.72s\n",
      "862:\tlearn: 0.0011772\ttotal: 29.5s\tremaining: 4.69s\n",
      "863:\tlearn: 0.0011771\ttotal: 29.6s\tremaining: 4.65s\n",
      "864:\tlearn: 0.0011770\ttotal: 29.6s\tremaining: 4.62s\n",
      "865:\tlearn: 0.0011769\ttotal: 29.6s\tremaining: 4.58s\n",
      "866:\tlearn: 0.0011767\ttotal: 29.7s\tremaining: 4.55s\n",
      "867:\tlearn: 0.0011766\ttotal: 29.7s\tremaining: 4.51s\n",
      "868:\tlearn: 0.0011762\ttotal: 29.7s\tremaining: 4.48s\n",
      "869:\tlearn: 0.0011718\ttotal: 29.8s\tremaining: 4.45s\n",
      "870:\tlearn: 0.0011706\ttotal: 29.8s\tremaining: 4.41s\n",
      "871:\tlearn: 0.0011703\ttotal: 29.8s\tremaining: 4.38s\n",
      "872:\tlearn: 0.0011701\ttotal: 29.8s\tremaining: 4.34s\n",
      "873:\tlearn: 0.0011691\ttotal: 29.9s\tremaining: 4.31s\n",
      "874:\tlearn: 0.0011684\ttotal: 29.9s\tremaining: 4.27s\n",
      "875:\tlearn: 0.0011684\ttotal: 29.9s\tremaining: 4.24s\n",
      "876:\tlearn: 0.0011682\ttotal: 30s\tremaining: 4.2s\n",
      "877:\tlearn: 0.0011681\ttotal: 30s\tremaining: 4.17s\n",
      "878:\tlearn: 0.0011680\ttotal: 30s\tremaining: 4.13s\n",
      "879:\tlearn: 0.0011601\ttotal: 30.1s\tremaining: 4.1s\n",
      "880:\tlearn: 0.0011582\ttotal: 30.1s\tremaining: 4.07s\n",
      "881:\tlearn: 0.0011581\ttotal: 30.1s\tremaining: 4.03s\n",
      "882:\tlearn: 0.0011512\ttotal: 30.2s\tremaining: 4s\n",
      "883:\tlearn: 0.0011512\ttotal: 30.2s\tremaining: 3.96s\n",
      "884:\tlearn: 0.0011510\ttotal: 30.2s\tremaining: 3.93s\n",
      "885:\tlearn: 0.0011508\ttotal: 30.3s\tremaining: 3.89s\n",
      "886:\tlearn: 0.0011498\ttotal: 30.3s\tremaining: 3.86s\n",
      "887:\tlearn: 0.0011498\ttotal: 30.3s\tremaining: 3.82s\n",
      "888:\tlearn: 0.0011497\ttotal: 30.3s\tremaining: 3.79s\n",
      "889:\tlearn: 0.0011497\ttotal: 30.4s\tremaining: 3.75s\n",
      "890:\tlearn: 0.0011488\ttotal: 30.4s\tremaining: 3.72s\n",
      "891:\tlearn: 0.0011464\ttotal: 30.4s\tremaining: 3.69s\n",
      "892:\tlearn: 0.0011462\ttotal: 30.5s\tremaining: 3.65s\n",
      "893:\tlearn: 0.0011462\ttotal: 30.5s\tremaining: 3.62s\n",
      "894:\tlearn: 0.0011435\ttotal: 30.5s\tremaining: 3.58s\n",
      "895:\tlearn: 0.0011431\ttotal: 30.6s\tremaining: 3.55s\n",
      "896:\tlearn: 0.0011431\ttotal: 30.6s\tremaining: 3.51s\n",
      "897:\tlearn: 0.0011427\ttotal: 30.6s\tremaining: 3.48s\n",
      "898:\tlearn: 0.0011426\ttotal: 30.7s\tremaining: 3.44s\n",
      "899:\tlearn: 0.0011425\ttotal: 30.7s\tremaining: 3.41s\n",
      "900:\tlearn: 0.0011425\ttotal: 30.7s\tremaining: 3.38s\n",
      "901:\tlearn: 0.0011424\ttotal: 30.7s\tremaining: 3.34s\n",
      "902:\tlearn: 0.0011394\ttotal: 30.8s\tremaining: 3.31s\n",
      "903:\tlearn: 0.0011390\ttotal: 30.8s\tremaining: 3.27s\n",
      "904:\tlearn: 0.0011390\ttotal: 30.9s\tremaining: 3.24s\n",
      "905:\tlearn: 0.0011382\ttotal: 30.9s\tremaining: 3.2s\n",
      "906:\tlearn: 0.0011377\ttotal: 30.9s\tremaining: 3.17s\n",
      "907:\tlearn: 0.0011377\ttotal: 30.9s\tremaining: 3.13s\n",
      "908:\tlearn: 0.0011374\ttotal: 31s\tremaining: 3.1s\n",
      "909:\tlearn: 0.0011373\ttotal: 31s\tremaining: 3.06s\n",
      "910:\tlearn: 0.0011325\ttotal: 31s\tremaining: 3.03s\n",
      "911:\tlearn: 0.0011324\ttotal: 31.1s\tremaining: 3s\n",
      "912:\tlearn: 0.0011317\ttotal: 31.1s\tremaining: 2.96s\n",
      "913:\tlearn: 0.0011309\ttotal: 31.1s\tremaining: 2.93s\n",
      "914:\tlearn: 0.0011308\ttotal: 31.2s\tremaining: 2.89s\n",
      "915:\tlearn: 0.0011308\ttotal: 31.2s\tremaining: 2.86s\n",
      "916:\tlearn: 0.0011300\ttotal: 31.2s\tremaining: 2.83s\n",
      "917:\tlearn: 0.0011298\ttotal: 31.3s\tremaining: 2.79s\n",
      "918:\tlearn: 0.0011295\ttotal: 31.3s\tremaining: 2.76s\n",
      "919:\tlearn: 0.0011292\ttotal: 31.3s\tremaining: 2.72s\n",
      "920:\tlearn: 0.0011291\ttotal: 31.4s\tremaining: 2.69s\n",
      "921:\tlearn: 0.0011290\ttotal: 31.4s\tremaining: 2.65s\n",
      "922:\tlearn: 0.0011290\ttotal: 31.4s\tremaining: 2.62s\n",
      "923:\tlearn: 0.0011266\ttotal: 31.4s\tremaining: 2.59s\n",
      "924:\tlearn: 0.0011251\ttotal: 31.5s\tremaining: 2.55s\n",
      "925:\tlearn: 0.0011251\ttotal: 31.5s\tremaining: 2.52s\n",
      "926:\tlearn: 0.0011251\ttotal: 31.5s\tremaining: 2.48s\n",
      "927:\tlearn: 0.0011245\ttotal: 31.6s\tremaining: 2.45s\n",
      "928:\tlearn: 0.0011245\ttotal: 31.6s\tremaining: 2.42s\n",
      "929:\tlearn: 0.0011244\ttotal: 31.6s\tremaining: 2.38s\n",
      "930:\tlearn: 0.0011241\ttotal: 31.7s\tremaining: 2.35s\n",
      "931:\tlearn: 0.0011236\ttotal: 31.7s\tremaining: 2.31s\n",
      "932:\tlearn: 0.0011222\ttotal: 31.7s\tremaining: 2.28s\n",
      "933:\tlearn: 0.0011222\ttotal: 31.8s\tremaining: 2.24s\n",
      "934:\tlearn: 0.0011222\ttotal: 31.8s\tremaining: 2.21s\n",
      "935:\tlearn: 0.0011215\ttotal: 31.8s\tremaining: 2.17s\n",
      "936:\tlearn: 0.0011209\ttotal: 31.9s\tremaining: 2.14s\n",
      "937:\tlearn: 0.0011153\ttotal: 31.9s\tremaining: 2.11s\n",
      "938:\tlearn: 0.0011152\ttotal: 31.9s\tremaining: 2.07s\n",
      "939:\tlearn: 0.0011152\ttotal: 32s\tremaining: 2.04s\n",
      "940:\tlearn: 0.0011152\ttotal: 32s\tremaining: 2s\n",
      "941:\tlearn: 0.0011150\ttotal: 32s\tremaining: 1.97s\n",
      "942:\tlearn: 0.0011108\ttotal: 32.1s\tremaining: 1.94s\n",
      "943:\tlearn: 0.0011100\ttotal: 32.1s\tremaining: 1.9s\n",
      "944:\tlearn: 0.0011096\ttotal: 32.1s\tremaining: 1.87s\n",
      "945:\tlearn: 0.0011095\ttotal: 32.1s\tremaining: 1.83s\n",
      "946:\tlearn: 0.0011087\ttotal: 32.2s\tremaining: 1.8s\n",
      "947:\tlearn: 0.0011081\ttotal: 32.2s\tremaining: 1.77s\n",
      "948:\tlearn: 0.0011074\ttotal: 32.2s\tremaining: 1.73s\n",
      "949:\tlearn: 0.0011073\ttotal: 32.3s\tremaining: 1.7s\n",
      "950:\tlearn: 0.0011073\ttotal: 32.3s\tremaining: 1.66s\n",
      "951:\tlearn: 0.0011070\ttotal: 32.3s\tremaining: 1.63s\n",
      "952:\tlearn: 0.0011069\ttotal: 32.4s\tremaining: 1.6s\n",
      "953:\tlearn: 0.0011024\ttotal: 32.4s\tremaining: 1.56s\n",
      "954:\tlearn: 0.0011019\ttotal: 32.4s\tremaining: 1.53s\n",
      "955:\tlearn: 0.0010979\ttotal: 32.5s\tremaining: 1.49s\n",
      "956:\tlearn: 0.0010976\ttotal: 32.5s\tremaining: 1.46s\n",
      "957:\tlearn: 0.0010976\ttotal: 32.5s\tremaining: 1.43s\n",
      "958:\tlearn: 0.0010974\ttotal: 32.6s\tremaining: 1.39s\n",
      "959:\tlearn: 0.0010973\ttotal: 32.6s\tremaining: 1.36s\n",
      "960:\tlearn: 0.0010973\ttotal: 32.6s\tremaining: 1.32s\n",
      "961:\tlearn: 0.0010972\ttotal: 32.7s\tremaining: 1.29s\n",
      "962:\tlearn: 0.0010971\ttotal: 32.7s\tremaining: 1.26s\n",
      "963:\tlearn: 0.0010971\ttotal: 32.7s\tremaining: 1.22s\n",
      "964:\tlearn: 0.0010969\ttotal: 32.8s\tremaining: 1.19s\n",
      "965:\tlearn: 0.0010969\ttotal: 32.8s\tremaining: 1.15s\n",
      "966:\tlearn: 0.0010968\ttotal: 32.8s\tremaining: 1.12s\n",
      "967:\tlearn: 0.0010913\ttotal: 32.9s\tremaining: 1.09s\n",
      "968:\tlearn: 0.0010869\ttotal: 32.9s\tremaining: 1.05s\n",
      "969:\tlearn: 0.0010834\ttotal: 32.9s\tremaining: 1.02s\n",
      "970:\tlearn: 0.0010829\ttotal: 33s\tremaining: 985ms\n",
      "971:\tlearn: 0.0010827\ttotal: 33s\tremaining: 951ms\n",
      "972:\tlearn: 0.0010789\ttotal: 33.1s\tremaining: 918ms\n",
      "973:\tlearn: 0.0010788\ttotal: 33.1s\tremaining: 884ms\n",
      "974:\tlearn: 0.0010785\ttotal: 33.1s\tremaining: 850ms\n",
      "975:\tlearn: 0.0010782\ttotal: 33.2s\tremaining: 815ms\n",
      "976:\tlearn: 0.0010780\ttotal: 33.2s\tremaining: 781ms\n",
      "977:\tlearn: 0.0010774\ttotal: 33.2s\tremaining: 747ms\n",
      "978:\tlearn: 0.0010740\ttotal: 33.3s\tremaining: 714ms\n",
      "979:\tlearn: 0.0010735\ttotal: 33.3s\tremaining: 680ms\n",
      "980:\tlearn: 0.0010731\ttotal: 33.3s\tremaining: 646ms\n",
      "981:\tlearn: 0.0010731\ttotal: 33.4s\tremaining: 612ms\n",
      "982:\tlearn: 0.0010731\ttotal: 33.4s\tremaining: 578ms\n",
      "983:\tlearn: 0.0010728\ttotal: 33.4s\tremaining: 544ms\n",
      "984:\tlearn: 0.0010728\ttotal: 33.5s\tremaining: 510ms\n",
      "985:\tlearn: 0.0010727\ttotal: 33.5s\tremaining: 476ms\n",
      "986:\tlearn: 0.0010724\ttotal: 33.5s\tremaining: 442ms\n",
      "987:\tlearn: 0.0010719\ttotal: 33.6s\tremaining: 408ms\n",
      "988:\tlearn: 0.0010716\ttotal: 33.6s\tremaining: 374ms\n",
      "989:\tlearn: 0.0010714\ttotal: 33.6s\tremaining: 340ms\n",
      "990:\tlearn: 0.0010711\ttotal: 33.7s\tremaining: 306ms\n",
      "991:\tlearn: 0.0010711\ttotal: 33.7s\tremaining: 272ms\n",
      "992:\tlearn: 0.0010671\ttotal: 33.7s\tremaining: 238ms\n",
      "993:\tlearn: 0.0010661\ttotal: 33.8s\tremaining: 204ms\n",
      "994:\tlearn: 0.0010660\ttotal: 33.8s\tremaining: 170ms\n",
      "995:\tlearn: 0.0010657\ttotal: 33.8s\tremaining: 136ms\n",
      "996:\tlearn: 0.0010657\ttotal: 33.9s\tremaining: 102ms\n",
      "997:\tlearn: 0.0010652\ttotal: 33.9s\tremaining: 67.9ms\n",
      "998:\tlearn: 0.0010652\ttotal: 33.9s\tremaining: 34ms\n",
      "999:\tlearn: 0.0010650\ttotal: 34s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cat_reg=CatBoostClassifier()\n",
    "cat_reg.fit(X_train,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "cat_train_set_predictions=cat_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "cat_test_set_predictions=cat_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_accuracy\n",
      " 0.9996961325966851\n",
      "[[ 6791     5     8]\n",
      " [    0  1983     0]\n",
      " [    9     0 63604]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      6804\n",
      "         5.0       1.00      1.00      1.00      1983\n",
      "       105.0       1.00      1.00      1.00     63613\n",
      "\n",
      "    accuracy                           1.00     72400\n",
      "   macro avg       1.00      1.00      1.00     72400\n",
      "weighted avg       1.00      1.00      1.00     72400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamiegoh/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#convert y_pred to 0,5,105\n",
    "cat_test_set_predictions=np.round(cat_test_set_predictions)\n",
    "cat_test_set_predictions=le.inverse_transform(cat_test_set_predictions.astype(int))\n",
    "\n",
    "cat_accuracy=accuracy_score(y_test,cat_test_set_predictions)\n",
    "cat_confusion_matrix=confusion_matrix(y_test,cat_test_set_predictions)\n",
    "\n",
    "print(\"cat_accuracy\\n\",cat_accuracy)\n",
    "print(cat_confusion_matrix)\n",
    "print(xgb_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1785\n",
      "[LightGBM] [Info] Number of data points in the train set: 289598, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 92.431733\n"
     ]
    }
   ],
   "source": [
    "# #train lightgbm regression model on training set against class label\n",
    "\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "lgb_reg=lgb.LGBMRegressor()\n",
    "lgb_reg.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "lgb_train_set_predictions=lgb_reg.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "lgb_test_set_predictions=lgb_reg.predict(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [-15 -12 -11 -10  -9  -6  -5  -4  -3  -2  -1   3   4   5   6   7   8   9\n  10  11  12  13  14  15  16  17  18  19  20  22  23  24  25  26  27  28\n  29  32  33  37  38  40  42  43  44  48  49  51  54  56  57  58  59  60\n  61  63  64  67  68  70  71  73  74  75  76  77  78  79  80  81  82  83\n  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n 102 103 104 105 106 107 108 109 110 111 112 116 119 121]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/BC2406-3.ipynb Cell 42\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dyllon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni/BC2406/oil/BC2406-3.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m lgb_test_set_predictions\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mround(lgb_test_set_predictions)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dyllon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni/BC2406/oil/BC2406-3.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m lgb_test_set_predictions\u001b[39m=\u001b[39mle\u001b[39m.\u001b[39;49minverse_transform(lgb_test_set_predictions\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dyllon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni/BC2406/oil/BC2406-3.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m lgb_accuracy\u001b[39m=\u001b[39maccuracy_score(y_test,lgb_test_set_predictions)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dyllon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni/BC2406/oil/BC2406-3.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m lgb_confusion_matrix\u001b[39m=\u001b[39mconfusion_matrix(y_test,lgb_test_set_predictions)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:160\u001b[0m, in \u001b[0;36mLabelEncoder.inverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    158\u001b[0m diff \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msetdiff1d(y, np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_)))\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(diff):\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my contains previously unseen labels: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(diff))\n\u001b[1;32m    161\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(y)\n\u001b[1;32m    162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[y]\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [-15 -12 -11 -10  -9  -6  -5  -4  -3  -2  -1   3   4   5   6   7   8   9\n  10  11  12  13  14  15  16  17  18  19  20  22  23  24  25  26  27  28\n  29  32  33  37  38  40  42  43  44  48  49  51  54  56  57  58  59  60\n  61  63  64  67  68  70  71  73  74  75  76  77  78  79  80  81  82  83\n  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n 102 103 104 105 106 107 108 109 110 111 112 116 119 121]"
     ]
    }
   ],
   "source": [
    "lgb_test_set_predictions=np.round(lgb_test_set_predictions)\n",
    "lgb_test_set_predictions=le.inverse_transform(lgb_test_set_predictions.astype(int))\n",
    "\n",
    "lgb_accuracy=accuracy_score(y_test,lgb_test_set_predictions)\n",
    "lgb_confusion_matrix=confusion_matrix(y_test,lgb_test_set_predictions)\n",
    "lgb_classification_report=classification_report(y_test,lgb_test_set_predictions)\n",
    "\n",
    "print(\"lgb_accuracy\\n\",lgb_accuracy)\n",
    "print(lgb_confusion_matrix)\n",
    "print(xgb_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare both models with f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# calculate F1 scores for both models\n",
    "logreg_f1 = f1_score(y_test, logreg_test_set_predictions, average='weighted')\n",
    "dectree_f1 = f1_score(y_test, dectree_test_set_predictions, average='weighted')\n",
    "\n",
    "# print\n",
    "print(\"F1 scores:\")\n",
    "print(\"Logistic Regression: \", logreg_f1)\n",
    "print(\"Decision Tree Regressor: \", dectree_f1)\n",
    "\n",
    "# compare F1 scores\n",
    "if logreg_f1 > dectree_f1:\n",
    "    print(\"Logistic Regression has a higher F1 score.\")\n",
    "elif logreg_f1 < dectree_f1:\n",
    "    print(\"Decision Tree has a higher F1 score.\")\n",
    "else:\n",
    "    print(\"Both models have the same F1 score.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/7/WELL-00006_20180620181348.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/7/WELL-00006_20180618110721.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/7/WELL-00001_20170226220309.csv', '/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/oil/data/7/WELL-00018_20180611040207.csv']\n",
      "WELL-00006\n",
      "WELL-00001\n",
      "WELL-00018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180620181348</td>\n",
       "      <td>2018-06-20 18:13:48.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>21125440.0</td>\n",
       "      <td>117.6264</td>\n",
       "      <td>12038980.0</td>\n",
       "      <td>65.97606</td>\n",
       "      <td>1627220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180620181348</td>\n",
       "      <td>2018-06-20 18:13:49.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>21125550.0</td>\n",
       "      <td>117.6270</td>\n",
       "      <td>12039360.0</td>\n",
       "      <td>65.97627</td>\n",
       "      <td>1627243.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180620181348</td>\n",
       "      <td>2018-06-20 18:13:50.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>21125650.0</td>\n",
       "      <td>117.6277</td>\n",
       "      <td>12039750.0</td>\n",
       "      <td>65.97648</td>\n",
       "      <td>1627266.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180620181348</td>\n",
       "      <td>2018-06-20 18:13:51.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>21125760.0</td>\n",
       "      <td>117.6283</td>\n",
       "      <td>12040130.0</td>\n",
       "      <td>65.97669</td>\n",
       "      <td>1627290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WELL-00006</td>\n",
       "      <td>20180620181348</td>\n",
       "      <td>2018-06-20 18:13:52.000000</td>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>21125860.0</td>\n",
       "      <td>117.6290</td>\n",
       "      <td>12040520.0</td>\n",
       "      <td>65.97691</td>\n",
       "      <td>1627313.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271703</th>\n",
       "      <td>WELL-00018</td>\n",
       "      <td>20180611040207</td>\n",
       "      <td>2018-06-11 12:58:09.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8721603.0</td>\n",
       "      <td>109.4972</td>\n",
       "      <td>2195037.0</td>\n",
       "      <td>68.44791</td>\n",
       "      <td>8454861.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271704</th>\n",
       "      <td>WELL-00018</td>\n",
       "      <td>20180611040207</td>\n",
       "      <td>2018-06-11 12:58:10.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8721549.0</td>\n",
       "      <td>109.4979</td>\n",
       "      <td>2195037.0</td>\n",
       "      <td>68.44791</td>\n",
       "      <td>8454861.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271705</th>\n",
       "      <td>WELL-00018</td>\n",
       "      <td>20180611040207</td>\n",
       "      <td>2018-06-11 12:58:11.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8721495.0</td>\n",
       "      <td>109.4987</td>\n",
       "      <td>2195037.0</td>\n",
       "      <td>68.44791</td>\n",
       "      <td>8454861.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271706</th>\n",
       "      <td>WELL-00018</td>\n",
       "      <td>20180611040207</td>\n",
       "      <td>2018-06-11 12:58:12.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8721441.0</td>\n",
       "      <td>109.4994</td>\n",
       "      <td>2195037.0</td>\n",
       "      <td>68.44791</td>\n",
       "      <td>8454861.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271707</th>\n",
       "      <td>WELL-00018</td>\n",
       "      <td>20180611040207</td>\n",
       "      <td>2018-06-11 12:58:13.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8721387.0</td>\n",
       "      <td>109.5001</td>\n",
       "      <td>2195037.0</td>\n",
       "      <td>68.44791</td>\n",
       "      <td>8454861.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271708 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name              id                   timestamp         P-PDG  \\\n",
       "0       WELL-00006  20180620181348  2018-06-20 18:13:48.000000 -1.180116e+42   \n",
       "1       WELL-00006  20180620181348  2018-06-20 18:13:49.000000 -1.180116e+42   \n",
       "2       WELL-00006  20180620181348  2018-06-20 18:13:50.000000 -1.180116e+42   \n",
       "3       WELL-00006  20180620181348  2018-06-20 18:13:51.000000 -1.180116e+42   \n",
       "4       WELL-00006  20180620181348  2018-06-20 18:13:52.000000 -1.180116e+42   \n",
       "...            ...             ...                         ...           ...   \n",
       "271703  WELL-00018  20180611040207  2018-06-11 12:58:09.000000  0.000000e+00   \n",
       "271704  WELL-00018  20180611040207  2018-06-11 12:58:10.000000  0.000000e+00   \n",
       "271705  WELL-00018  20180611040207  2018-06-11 12:58:11.000000  0.000000e+00   \n",
       "271706  WELL-00018  20180611040207  2018-06-11 12:58:12.000000  0.000000e+00   \n",
       "271707  WELL-00018  20180611040207  2018-06-11 12:58:13.000000  0.000000e+00   \n",
       "\n",
       "             P-TPT     T-TPT   P-MON-CKP  T-JUS-CKP  P-JUS-CKGL  T-JUS-CKGL  \\\n",
       "0       21125440.0  117.6264  12038980.0   65.97606   1627220.0         NaN   \n",
       "1       21125550.0  117.6270  12039360.0   65.97627   1627243.0         NaN   \n",
       "2       21125650.0  117.6277  12039750.0   65.97648   1627266.0         NaN   \n",
       "3       21125760.0  117.6283  12040130.0   65.97669   1627290.0         NaN   \n",
       "4       21125860.0  117.6290  12040520.0   65.97691   1627313.0         NaN   \n",
       "...            ...       ...         ...        ...         ...         ...   \n",
       "271703   8721603.0  109.4972   2195037.0   68.44791   8454861.0         NaN   \n",
       "271704   8721549.0  109.4979   2195037.0   68.44791   8454861.0         NaN   \n",
       "271705   8721495.0  109.4987   2195037.0   68.44791   8454861.0         NaN   \n",
       "271706   8721441.0  109.4994   2195037.0   68.44791   8454861.0         NaN   \n",
       "271707   8721387.0  109.5001   2195037.0   68.44791   8454861.0         NaN   \n",
       "\n",
       "        QGL  class  \n",
       "0       0.0    0.0  \n",
       "1       0.0    0.0  \n",
       "2       0.0    0.0  \n",
       "3       0.0    0.0  \n",
       "4       0.0    0.0  \n",
       "...     ...    ...  \n",
       "271703  0.0  107.0  \n",
       "271704  0.0  107.0  \n",
       "271705  0.0  107.0  \n",
       "271706  0.0  107.0  \n",
       "271707  0.0  107.0  \n",
       "\n",
       "[271708 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#import csv files\n",
    "# print(csv_files)\n",
    "path=os.path.join(os.getcwd(),'data','7')\n",
    "csv_files=glob.glob(path + \"/*.csv\")\n",
    "\n",
    "#remove BC2406.ipynb from csv_files\n",
    "# csv_files.remove('BC2406.ipynb')\n",
    "\n",
    "# remove all files whose file name (not path) starts with SIMULATED\n",
    "csv_files=[csv_file for csv_file in csv_files if not os.path.basename(csv_file).startswith('DRAWN')]\n",
    "\n",
    "dataframes={}\n",
    "\n",
    "print(csv_files)\n",
    "for csv_file in csv_files:\n",
    "  # print(csv_file)\n",
    "  well_name=os.path.splitext(csv_file)[0]\n",
    "  # print(\"file path\")\n",
    "  # print(os.path.join(csv_directory,csv_file))\n",
    "  df=pd.read_csv(csv_file)\n",
    "  dataframes[well_name]=df\n",
    "\n",
    "for well_name,df in dataframes.items():\n",
    "  df.insert(0,'name',well_name.split('_')[0].split('/')[-1])\n",
    "  df.insert(1,'id',well_name.split('_')[1])\n",
    "\n",
    "df=pd.concat(dataframes.values(),ignore_index=True)\n",
    "\n",
    "distinct_wells=df['name'].unique()\n",
    "for name in distinct_wells:\n",
    "  print(name)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [P-PDG, P-TPT, T-TPT, P-MON-CKP, T-JUS-CKP, P-JUS-CKGL, QGL, class]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#clean dataset to remove name, id, timestamp\n",
    "df=df.drop(['name','id','timestamp', 'T-JUS-CKGL'],axis=1)\n",
    "\n",
    "#replace all NaN with 0\n",
    "# df=df.fillna(0)\n",
    "\n",
    "# drop all rows with class NaN\n",
    "df=df.dropna(subset=['class'])\n",
    "\n",
    "# # print NaN in any column\n",
    "\n",
    "# drop all rows where P-PDG is NaN\n",
    "df=df.dropna(subset=['P-PDG'])\n",
    "\n",
    "print(df[df.isna().any(axis=1)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0. 107.   7.]\n",
      "Empty DataFrame\n",
      "Columns: [P-PDG, P-TPT, T-TPT, P-MON-CKP, T-JUS-CKP, P-JUS-CKGL, QGL, class]\n",
      "Index: []\n",
      "count of 0 in class label:  12526\n",
      "count of NaN in class label:  0\n",
      "count of 7 in class label:  821\n",
      "count of 107 in class label:  257366\n"
     ]
    }
   ],
   "source": [
    "# show all values in column class\n",
    "print(df['class'].unique())\n",
    "\n",
    "# print 5 rows where class = NaN\n",
    "print(df[df['class'].isna()].head())\n",
    "\n",
    "#count number of 0, 3 in class label\n",
    "print(\"count of 0 in class label: \",len(df[df['class']==0])) # normal state\n",
    "print(\"count of NaN in class label: \",len(df[df['class'].isna()])) # NaN state\n",
    "print(\"count of 7 in class label: \",len(df[df['class']==7]))  # warning state\n",
    "print(\"count of 107 in class label: \",len(df[df['class']==107]))  # error state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop(['class'],axis=1)\n",
    "y=df['class']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train logistic regression model on training set against class label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#train model on training set\n",
    "log_reg=LogisticRegression(max_iter=100000)\n",
    "log_reg.fit(X_train_scaled,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "logreg_train_set_predictions=log_reg.predict(X_train_scaled)\n",
    "\n",
    "#test model on test set\n",
    "logreg_test_set_predictions=log_reg.predict(X_test_scaled)\n",
    "log_accuracy=accuracy_score(y_test,logreg_test_set_predictions)\n",
    "log_confusion_matrix=confusion_matrix(y_test,logreg_test_set_predictions)\n",
    "log_classification_report=classification_report(y_test,logreg_test_set_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_accuracy\n",
      " 0.9526254548141034\n",
      "[[  178     0  2368]\n",
      " [    0     7   155]\n",
      " [   42     0 51393]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.07      0.13      2546\n",
      "         7.0       1.00      0.04      0.08       162\n",
      "       107.0       0.95      1.00      0.98     51435\n",
      "\n",
      "    accuracy                           0.95     54143\n",
      "   macro avg       0.92      0.37      0.40     54143\n",
      "weighted avg       0.95      0.95      0.93     54143\n",
      "\n",
      "log_accuracy = 95.3 %\n"
     ]
    }
   ],
   "source": [
    "print(\"log_accuracy\\n\",log_accuracy)\n",
    "print(log_confusion_matrix)\n",
    "print(log_classification_report)\n",
    "print(\"log_accuracy = %.1f\"%(log_accuracy*100),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:134: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:134: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    }
   ],
   "source": [
    "#train decision tree regression model on training set against class label\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.nan_to_num(X_train.astype(np.float32))\n",
    "X_test = np.nan_to_num(X_test.astype(np.float32))\n",
    "\n",
    "# check for infinite or NaN values in X_train and X_test\n",
    "if not np.isfinite(X_train).all() or not np.isfinite(X_test).all():\n",
    "    print(\"Input data contains infinite or NaN values.\")\n",
    "\n",
    "#train model on training set\n",
    "dt_class=DecisionTreeClassifier()\n",
    "dt_class.fit(X_train,y_train)\n",
    "\n",
    "#predict class label on training set\n",
    "dectree_train_set_predictions=dt_class.predict(X_train)\n",
    "\n",
    "#test model on test set\n",
    "dectree_test_set_predictions=dt_class.predict(X_test)\n",
    "dt_mse=mean_squared_error(y_test,dectree_test_set_predictions)\n",
    "dt_rmse=np.sqrt(dt_mse)\n",
    "dt_accuracy=accuracy_score(y_test,dectree_test_set_predictions)\n",
    "dt_confusion_matrix=confusion_matrix(y_test,dectree_test_set_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_mse\n",
      " 0.18469608259608813\n",
      "dt_rmse\n",
      " 0.4297628213283324\n",
      "dt_accuracy\n",
      " 0.9999815303917404\n",
      "[[ 2546     0     0]\n",
      " [    0   161     1]\n",
      " [    0     0 51435]]\n",
      "dt_accuracy = 100.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"dt_mse\\n\",dt_mse)\n",
    "print(\"dt_rmse\\n\",dt_rmse)\n",
    "print(\"dt_accuracy\\n\",dt_accuracy)\n",
    "print(dt_confusion_matrix)\n",
    "print(\"dt_accuracy = %.1f\"%(dt_accuracy*100),\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_accuracy\n",
      " 0.9994089725356925\n",
      "[[ 2542     0     4]\n",
      " [    0   159     3]\n",
      " [   24     1 51410]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      2546\n",
      "         7.0       0.99      0.98      0.99       162\n",
      "       107.0       1.00      1.00      1.00     51435\n",
      "\n",
      "    accuracy                           1.00     54143\n",
      "   macro avg       0.99      0.99      0.99     54143\n",
      "weighted avg       1.00      1.00      1.00     54143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train xgboost regression model on training set against class label\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "xgb_class=xgb.XGBClassifier()\n",
    "xgb_class.fit(X_train_scaled,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "xgb_train_set_predictions=xgb_class.predict(X_train_scaled)\n",
    "\n",
    "#test model on test set\n",
    "y_pred=xgb_class.predict(X_test_scaled)\n",
    "\n",
    "#convert y_pred\n",
    "y_pred=np.round(y_pred)\n",
    "y_pred=le.inverse_transform(y_pred.astype(int))\n",
    "\n",
    "xgb_accuracy=accuracy_score(y_test,y_pred)\n",
    "xgb_confusion_matrix=confusion_matrix(y_test,y_pred)\n",
    "xgb_classification_report=classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"xgb_accuracy\\n\",xgb_accuracy)\n",
    "print(xgb_confusion_matrix)\n",
    "print(xgb_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN - TAKES 100 MINS TO RUN\n",
    "\n",
    "# #tune hyperparameters for xgboost\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # define parameters to tune\n",
    "# parameters = {'max_depth': [3, 4, 5, 6, 7, 8, 9, 10], 'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "#             'n_estimators': [100, 200, 300, 400, 500]}\n",
    "# xgb_class = xgb.XGBClassifier()\n",
    "\n",
    "# # tune hyperparameters\n",
    "\n",
    "# grid_search = GridSearchCV(xgb_class, parameters, cv=5, scoring='accuracy', return_train_score=True)\n",
    "# grid_search.fit(X_train_scaled, y_trainLE)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters\n",
    "# print(grid_search.best_params_)\n",
    "\n",
    "# print(grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 400}\n",
    "0.999533638084684"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_accuracy\n",
      " 0.9994274421439521\n",
      "[[ 2544     0     2]\n",
      " [    0   159     3]\n",
      " [   25     1 51409]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      2546\n",
      "         7.0       0.99      0.98      0.99       162\n",
      "       107.0       1.00      1.00      1.00     51435\n",
      "\n",
      "    accuracy                           1.00     54143\n",
      "   macro avg       0.99      0.99      0.99     54143\n",
      "weighted avg       1.00      1.00      1.00     54143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train xgboost regression model on training set against class label\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "xgb_class=xgb.XGBClassifier(\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    n_estimators=400,\n",
    ")\n",
    "\n",
    "xgb_class.fit(X_train_scaled,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "xgb_train_set_predictions=xgb_class.predict(X_train_scaled)\n",
    "\n",
    "#test model on test set\n",
    "y_pred=xgb_class.predict(X_test_scaled)\n",
    "\n",
    "#convert y_pred\n",
    "y_pred=np.round(y_pred)\n",
    "y_pred=le.inverse_transform(y_pred.astype(int))\n",
    "\n",
    "xgb_accuracy=accuracy_score(y_test,y_pred)\n",
    "xgb_confusion_matrix=confusion_matrix(y_test,y_pred)\n",
    "xgb_classification_report=classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"xgb_accuracy\\n\",xgb_accuracy)\n",
    "print(xgb_confusion_matrix)\n",
    "print(xgb_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train catboost regression model on training set against class label\n",
    "\n",
    "# # scale the data\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "# cat_reg=CatBoostClassifier()\n",
    "# cat_reg.fit(X_train_scaled,y_trainLE)\n",
    "\n",
    "# #predict class label on training set\n",
    "# cat_train_set_predictions=cat_reg.predict(X_train_scaled)\n",
    "\n",
    "\n",
    "# #test model on test set\n",
    "# cat_test_set_predictions=cat_reg.predict(X_test_scaled)\n",
    "\n",
    "# #convert y_pred\n",
    "# cat_test_set_predictions=np.round(cat_test_set_predictions)\n",
    "# cat_test_set_predictions=le.inverse_transform(cat_test_set_predictions.astype(int))\n",
    "\n",
    "# cat_accuracy=accuracy_score(y_test,cat_test_set_predictions)\n",
    "# cat_confusion_matrix=confusion_matrix(y_test,cat_test_set_predictions)\n",
    "# cat_classification_report=classification_report(y_test,cat_test_set_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"cat_accuracy\\n\",cat_accuracy)\n",
    "# print(cat_confusion_matrix)\n",
    "# print(cat_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tune hyperparameters for catboost\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # scale the data\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "# cat_reg=CatBoostClassifier()\n",
    "\n",
    "# # define the grid of hyperparameters to search\n",
    "# search_space = {'iterations': [100, 200, 500],\n",
    "#                 'learning_rate': [0.01, 0.05, 0.1],\n",
    "#                 'depth': [3, 5, 7]}\n",
    "# # define search\n",
    "# grid_search = GridSearchCV(cat_reg, search_space, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "# # execute search\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_trainLE)\n",
    "# # summarize result\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best params  \n",
    "(via sklearn gridsearchcv):  \n",
    "Best: 0.999372 using {'depth': 7, 'iterations': 500, 'learning_rate': 0.05}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3861038\ttotal: 293ms\tremaining: 2m 26s\n",
      "1:\tlearn: 0.2189519\ttotal: 494ms\tremaining: 2m 3s\n",
      "2:\tlearn: 0.1240743\ttotal: 651ms\tremaining: 1m 47s\n",
      "3:\tlearn: 0.0788224\ttotal: 834ms\tremaining: 1m 43s\n",
      "4:\tlearn: 0.0491858\ttotal: 1.06s\tremaining: 1m 44s\n",
      "5:\tlearn: 0.0339245\ttotal: 1.25s\tremaining: 1m 42s\n",
      "6:\tlearn: 0.0230531\ttotal: 1.46s\tremaining: 1m 42s\n",
      "7:\tlearn: 0.0166981\ttotal: 1.69s\tremaining: 1m 43s\n",
      "8:\tlearn: 0.0120986\ttotal: 1.86s\tremaining: 1m 41s\n",
      "9:\tlearn: 0.0092694\ttotal: 2.01s\tremaining: 1m 38s\n",
      "10:\tlearn: 0.0078769\ttotal: 2.18s\tremaining: 1m 36s\n",
      "11:\tlearn: 0.0063803\ttotal: 2.32s\tremaining: 1m 34s\n",
      "12:\tlearn: 0.0056869\ttotal: 2.46s\tremaining: 1m 32s\n",
      "13:\tlearn: 0.0045628\ttotal: 2.59s\tremaining: 1m 29s\n",
      "14:\tlearn: 0.0042310\ttotal: 2.7s\tremaining: 1m 27s\n",
      "15:\tlearn: 0.0038234\ttotal: 2.82s\tremaining: 1m 25s\n",
      "16:\tlearn: 0.0033371\ttotal: 2.97s\tremaining: 1m 24s\n",
      "17:\tlearn: 0.0029969\ttotal: 3.12s\tremaining: 1m 23s\n",
      "18:\tlearn: 0.0028679\ttotal: 3.28s\tremaining: 1m 22s\n",
      "19:\tlearn: 0.0027808\ttotal: 3.42s\tremaining: 1m 22s\n",
      "20:\tlearn: 0.0025772\ttotal: 3.57s\tremaining: 1m 21s\n",
      "21:\tlearn: 0.0025141\ttotal: 3.69s\tremaining: 1m 20s\n",
      "22:\tlearn: 0.0023270\ttotal: 3.8s\tremaining: 1m 18s\n",
      "23:\tlearn: 0.0022860\ttotal: 3.9s\tremaining: 1m 17s\n",
      "24:\tlearn: 0.0022113\ttotal: 4.01s\tremaining: 1m 16s\n",
      "25:\tlearn: 0.0022021\ttotal: 4.11s\tremaining: 1m 14s\n",
      "26:\tlearn: 0.0021882\ttotal: 4.24s\tremaining: 1m 14s\n",
      "27:\tlearn: 0.0020671\ttotal: 4.4s\tremaining: 1m 14s\n",
      "28:\tlearn: 0.0020573\ttotal: 4.52s\tremaining: 1m 13s\n",
      "29:\tlearn: 0.0020409\ttotal: 4.66s\tremaining: 1m 12s\n",
      "30:\tlearn: 0.0020358\ttotal: 4.76s\tremaining: 1m 11s\n",
      "31:\tlearn: 0.0020302\ttotal: 4.87s\tremaining: 1m 11s\n",
      "32:\tlearn: 0.0019576\ttotal: 5.02s\tremaining: 1m 11s\n",
      "33:\tlearn: 0.0019545\ttotal: 5.17s\tremaining: 1m 10s\n",
      "34:\tlearn: 0.0019434\ttotal: 5.33s\tremaining: 1m 10s\n",
      "35:\tlearn: 0.0019404\ttotal: 5.44s\tremaining: 1m 10s\n",
      "36:\tlearn: 0.0019345\ttotal: 5.52s\tremaining: 1m 9s\n",
      "37:\tlearn: 0.0019325\ttotal: 5.61s\tremaining: 1m 8s\n",
      "38:\tlearn: 0.0019293\ttotal: 5.69s\tremaining: 1m 7s\n",
      "39:\tlearn: 0.0019079\ttotal: 5.79s\tremaining: 1m 6s\n",
      "40:\tlearn: 0.0019047\ttotal: 5.88s\tremaining: 1m 5s\n",
      "41:\tlearn: 0.0019036\ttotal: 5.96s\tremaining: 1m 5s\n",
      "42:\tlearn: 0.0019024\ttotal: 6.06s\tremaining: 1m 4s\n",
      "43:\tlearn: 0.0019013\ttotal: 6.17s\tremaining: 1m 3s\n",
      "44:\tlearn: 0.0018992\ttotal: 6.29s\tremaining: 1m 3s\n",
      "45:\tlearn: 0.0018949\ttotal: 6.42s\tremaining: 1m 3s\n",
      "46:\tlearn: 0.0018934\ttotal: 6.56s\tremaining: 1m 3s\n",
      "47:\tlearn: 0.0018427\ttotal: 6.68s\tremaining: 1m 2s\n",
      "48:\tlearn: 0.0018350\ttotal: 6.85s\tremaining: 1m 3s\n",
      "49:\tlearn: 0.0018328\ttotal: 6.98s\tremaining: 1m 2s\n",
      "50:\tlearn: 0.0018317\ttotal: 7.12s\tremaining: 1m 2s\n",
      "51:\tlearn: 0.0018311\ttotal: 7.25s\tremaining: 1m 2s\n",
      "52:\tlearn: 0.0018229\ttotal: 7.36s\tremaining: 1m 2s\n",
      "53:\tlearn: 0.0018221\ttotal: 7.45s\tremaining: 1m 1s\n",
      "54:\tlearn: 0.0018216\ttotal: 7.55s\tremaining: 1m 1s\n",
      "55:\tlearn: 0.0018206\ttotal: 7.65s\tremaining: 1m\n",
      "56:\tlearn: 0.0018203\ttotal: 7.75s\tremaining: 1m\n",
      "57:\tlearn: 0.0018127\ttotal: 7.84s\tremaining: 59.8s\n",
      "58:\tlearn: 0.0018124\ttotal: 7.95s\tremaining: 59.4s\n",
      "59:\tlearn: 0.0018115\ttotal: 8.08s\tremaining: 59.3s\n",
      "60:\tlearn: 0.0018110\ttotal: 8.2s\tremaining: 59s\n",
      "61:\tlearn: 0.0017654\ttotal: 8.39s\tremaining: 59.3s\n",
      "62:\tlearn: 0.0017651\ttotal: 8.57s\tremaining: 59.5s\n",
      "63:\tlearn: 0.0017645\ttotal: 8.73s\tremaining: 59.5s\n",
      "64:\tlearn: 0.0017642\ttotal: 8.84s\tremaining: 59.2s\n",
      "65:\tlearn: 0.0017596\ttotal: 8.91s\tremaining: 58.6s\n",
      "66:\tlearn: 0.0017584\ttotal: 9s\tremaining: 58.2s\n",
      "67:\tlearn: 0.0017396\ttotal: 9.11s\tremaining: 57.9s\n",
      "68:\tlearn: 0.0017393\ttotal: 9.19s\tremaining: 57.4s\n",
      "69:\tlearn: 0.0017391\ttotal: 9.3s\tremaining: 57.1s\n",
      "70:\tlearn: 0.0017389\ttotal: 9.39s\tremaining: 56.7s\n",
      "71:\tlearn: 0.0017385\ttotal: 9.47s\tremaining: 56.3s\n",
      "72:\tlearn: 0.0017383\ttotal: 9.59s\tremaining: 56.1s\n",
      "73:\tlearn: 0.0017381\ttotal: 9.68s\tremaining: 55.7s\n",
      "74:\tlearn: 0.0017380\ttotal: 9.82s\tremaining: 55.7s\n",
      "75:\tlearn: 0.0017374\ttotal: 9.96s\tremaining: 55.6s\n",
      "76:\tlearn: 0.0017372\ttotal: 10s\tremaining: 55.1s\n",
      "77:\tlearn: 0.0017371\ttotal: 10.1s\tremaining: 54.9s\n",
      "78:\tlearn: 0.0017367\ttotal: 10.4s\tremaining: 55.5s\n",
      "79:\tlearn: 0.0017366\ttotal: 10.5s\tremaining: 55.3s\n",
      "80:\tlearn: 0.0017365\ttotal: 10.6s\tremaining: 54.9s\n",
      "81:\tlearn: 0.0017364\ttotal: 10.7s\tremaining: 54.7s\n",
      "82:\tlearn: 0.0017341\ttotal: 10.9s\tremaining: 54.8s\n",
      "83:\tlearn: 0.0017340\ttotal: 11s\tremaining: 54.6s\n",
      "84:\tlearn: 0.0017339\ttotal: 11.1s\tremaining: 54.3s\n",
      "85:\tlearn: 0.0017334\ttotal: 11.2s\tremaining: 53.8s\n",
      "86:\tlearn: 0.0017333\ttotal: 11.3s\tremaining: 53.5s\n",
      "87:\tlearn: 0.0017329\ttotal: 11.3s\tremaining: 53.1s\n",
      "88:\tlearn: 0.0017326\ttotal: 11.4s\tremaining: 52.7s\n",
      "89:\tlearn: 0.0017325\ttotal: 11.5s\tremaining: 52.2s\n",
      "90:\tlearn: 0.0017323\ttotal: 11.5s\tremaining: 51.8s\n",
      "91:\tlearn: 0.0016863\ttotal: 11.6s\tremaining: 51.5s\n",
      "92:\tlearn: 0.0016861\ttotal: 11.7s\tremaining: 51.3s\n",
      "93:\tlearn: 0.0016860\ttotal: 11.8s\tremaining: 50.9s\n",
      "94:\tlearn: 0.0016756\ttotal: 11.8s\tremaining: 50.5s\n",
      "95:\tlearn: 0.0016753\ttotal: 11.9s\tremaining: 50.1s\n",
      "96:\tlearn: 0.0016752\ttotal: 12s\tremaining: 49.8s\n",
      "97:\tlearn: 0.0016751\ttotal: 12.1s\tremaining: 49.7s\n",
      "98:\tlearn: 0.0016612\ttotal: 12.3s\tremaining: 49.7s\n",
      "99:\tlearn: 0.0016501\ttotal: 12.4s\tremaining: 49.4s\n",
      "100:\tlearn: 0.0016496\ttotal: 12.4s\tremaining: 49.2s\n",
      "101:\tlearn: 0.0016495\ttotal: 12.5s\tremaining: 48.8s\n",
      "102:\tlearn: 0.0016495\ttotal: 12.6s\tremaining: 48.5s\n",
      "103:\tlearn: 0.0016494\ttotal: 12.6s\tremaining: 48.1s\n",
      "104:\tlearn: 0.0016493\ttotal: 12.7s\tremaining: 47.8s\n",
      "105:\tlearn: 0.0016493\ttotal: 12.8s\tremaining: 47.4s\n",
      "106:\tlearn: 0.0016492\ttotal: 12.8s\tremaining: 47.1s\n",
      "107:\tlearn: 0.0016423\ttotal: 12.9s\tremaining: 46.7s\n",
      "108:\tlearn: 0.0016423\ttotal: 12.9s\tremaining: 46.4s\n",
      "109:\tlearn: 0.0016420\ttotal: 13s\tremaining: 46s\n",
      "110:\tlearn: 0.0016420\ttotal: 13s\tremaining: 45.7s\n",
      "111:\tlearn: 0.0016419\ttotal: 13.1s\tremaining: 45.4s\n",
      "112:\tlearn: 0.0016417\ttotal: 13.2s\tremaining: 45.1s\n",
      "113:\tlearn: 0.0016416\ttotal: 13.2s\tremaining: 44.8s\n",
      "114:\tlearn: 0.0016396\ttotal: 13.3s\tremaining: 44.5s\n",
      "115:\tlearn: 0.0016395\ttotal: 13.3s\tremaining: 44.1s\n",
      "116:\tlearn: 0.0016395\ttotal: 13.4s\tremaining: 43.9s\n",
      "117:\tlearn: 0.0016326\ttotal: 13.5s\tremaining: 43.8s\n",
      "118:\tlearn: 0.0016316\ttotal: 13.6s\tremaining: 43.5s\n",
      "119:\tlearn: 0.0016300\ttotal: 13.7s\tremaining: 43.3s\n",
      "120:\tlearn: 0.0016299\ttotal: 13.7s\tremaining: 43s\n",
      "121:\tlearn: 0.0016299\ttotal: 13.8s\tremaining: 42.8s\n",
      "122:\tlearn: 0.0016298\ttotal: 14s\tremaining: 42.8s\n",
      "123:\tlearn: 0.0016297\ttotal: 14s\tremaining: 42.5s\n",
      "124:\tlearn: 0.0016296\ttotal: 14.2s\tremaining: 42.6s\n",
      "125:\tlearn: 0.0016295\ttotal: 14.4s\tremaining: 42.7s\n",
      "126:\tlearn: 0.0016294\ttotal: 14.5s\tremaining: 42.6s\n",
      "127:\tlearn: 0.0016293\ttotal: 14.6s\tremaining: 42.4s\n",
      "128:\tlearn: 0.0016293\ttotal: 14.7s\tremaining: 42.2s\n",
      "129:\tlearn: 0.0016292\ttotal: 14.7s\tremaining: 42s\n",
      "130:\tlearn: 0.0016250\ttotal: 14.8s\tremaining: 41.7s\n",
      "131:\tlearn: 0.0016249\ttotal: 14.9s\tremaining: 41.6s\n",
      "132:\tlearn: 0.0016249\ttotal: 15s\tremaining: 41.5s\n",
      "133:\tlearn: 0.0016248\ttotal: 15.1s\tremaining: 41.4s\n",
      "134:\tlearn: 0.0016248\ttotal: 15.2s\tremaining: 41.1s\n",
      "135:\tlearn: 0.0016247\ttotal: 15.3s\tremaining: 40.9s\n",
      "136:\tlearn: 0.0016247\ttotal: 15.4s\tremaining: 40.8s\n",
      "137:\tlearn: 0.0016203\ttotal: 15.5s\tremaining: 40.5s\n",
      "138:\tlearn: 0.0016202\ttotal: 15.6s\tremaining: 40.4s\n",
      "139:\tlearn: 0.0016202\ttotal: 15.6s\tremaining: 40.1s\n",
      "140:\tlearn: 0.0016201\ttotal: 15.7s\tremaining: 40s\n",
      "141:\tlearn: 0.0016166\ttotal: 15.7s\tremaining: 39.7s\n",
      "142:\tlearn: 0.0016165\ttotal: 15.8s\tremaining: 39.5s\n",
      "143:\tlearn: 0.0016159\ttotal: 15.9s\tremaining: 39.3s\n",
      "144:\tlearn: 0.0016158\ttotal: 16s\tremaining: 39.1s\n",
      "145:\tlearn: 0.0016158\ttotal: 16s\tremaining: 38.8s\n",
      "146:\tlearn: 0.0016157\ttotal: 16.1s\tremaining: 38.6s\n",
      "147:\tlearn: 0.0016157\ttotal: 16.2s\tremaining: 38.4s\n",
      "148:\tlearn: 0.0016157\ttotal: 16.2s\tremaining: 38.2s\n",
      "149:\tlearn: 0.0016156\ttotal: 16.3s\tremaining: 38s\n",
      "150:\tlearn: 0.0016156\ttotal: 16.4s\tremaining: 37.8s\n",
      "151:\tlearn: 0.0016155\ttotal: 16.4s\tremaining: 37.7s\n",
      "152:\tlearn: 0.0016155\ttotal: 16.5s\tremaining: 37.4s\n",
      "153:\tlearn: 0.0016155\ttotal: 16.6s\tremaining: 37.2s\n",
      "154:\tlearn: 0.0016154\ttotal: 16.6s\tremaining: 37s\n",
      "155:\tlearn: 0.0016154\ttotal: 16.7s\tremaining: 36.8s\n",
      "156:\tlearn: 0.0016154\ttotal: 16.7s\tremaining: 36.6s\n",
      "157:\tlearn: 0.0016154\ttotal: 16.9s\tremaining: 36.5s\n",
      "158:\tlearn: 0.0016143\ttotal: 17s\tremaining: 36.4s\n",
      "159:\tlearn: 0.0016142\ttotal: 17s\tremaining: 36.2s\n",
      "160:\tlearn: 0.0016142\ttotal: 17.1s\tremaining: 36s\n",
      "161:\tlearn: 0.0016142\ttotal: 17.2s\tremaining: 35.8s\n",
      "162:\tlearn: 0.0016141\ttotal: 17.2s\tremaining: 35.6s\n",
      "163:\tlearn: 0.0016126\ttotal: 17.3s\tremaining: 35.5s\n",
      "164:\tlearn: 0.0016108\ttotal: 17.4s\tremaining: 35.3s\n",
      "165:\tlearn: 0.0016108\ttotal: 17.4s\tremaining: 35.1s\n",
      "166:\tlearn: 0.0016094\ttotal: 17.5s\tremaining: 34.9s\n",
      "167:\tlearn: 0.0016094\ttotal: 17.5s\tremaining: 34.7s\n",
      "168:\tlearn: 0.0016094\ttotal: 17.6s\tremaining: 34.5s\n",
      "169:\tlearn: 0.0016094\ttotal: 17.7s\tremaining: 34.3s\n",
      "170:\tlearn: 0.0016094\ttotal: 17.7s\tremaining: 34.1s\n",
      "171:\tlearn: 0.0016093\ttotal: 17.8s\tremaining: 33.9s\n",
      "172:\tlearn: 0.0016093\ttotal: 17.8s\tremaining: 33.7s\n",
      "173:\tlearn: 0.0016093\ttotal: 17.9s\tremaining: 33.5s\n",
      "174:\tlearn: 0.0016093\ttotal: 17.9s\tremaining: 33.3s\n",
      "175:\tlearn: 0.0016093\ttotal: 18s\tremaining: 33.1s\n",
      "176:\tlearn: 0.0016092\ttotal: 18s\tremaining: 32.9s\n",
      "177:\tlearn: 0.0016092\ttotal: 18.1s\tremaining: 32.7s\n",
      "178:\tlearn: 0.0016092\ttotal: 18.2s\tremaining: 32.6s\n",
      "179:\tlearn: 0.0016092\ttotal: 18.2s\tremaining: 32.3s\n",
      "180:\tlearn: 0.0016061\ttotal: 18.2s\tremaining: 32.1s\n",
      "181:\tlearn: 0.0016059\ttotal: 18.3s\tremaining: 31.9s\n",
      "182:\tlearn: 0.0016059\ttotal: 18.3s\tremaining: 31.7s\n",
      "183:\tlearn: 0.0016059\ttotal: 18.4s\tremaining: 31.6s\n",
      "184:\tlearn: 0.0016059\ttotal: 18.4s\tremaining: 31.4s\n",
      "185:\tlearn: 0.0016059\ttotal: 18.5s\tremaining: 31.2s\n",
      "186:\tlearn: 0.0016058\ttotal: 18.5s\tremaining: 31s\n",
      "187:\tlearn: 0.0016058\ttotal: 18.6s\tremaining: 30.9s\n",
      "188:\tlearn: 0.0016058\ttotal: 18.7s\tremaining: 30.8s\n",
      "189:\tlearn: 0.0016058\ttotal: 18.8s\tremaining: 30.6s\n",
      "190:\tlearn: 0.0016058\ttotal: 18.8s\tremaining: 30.5s\n",
      "191:\tlearn: 0.0016058\ttotal: 18.9s\tremaining: 30.3s\n",
      "192:\tlearn: 0.0016057\ttotal: 18.9s\tremaining: 30.1s\n",
      "193:\tlearn: 0.0016057\ttotal: 19s\tremaining: 30s\n",
      "194:\tlearn: 0.0016057\ttotal: 19s\tremaining: 29.8s\n",
      "195:\tlearn: 0.0016057\ttotal: 19.1s\tremaining: 29.6s\n",
      "196:\tlearn: 0.0016057\ttotal: 19.2s\tremaining: 29.5s\n",
      "197:\tlearn: 0.0016056\ttotal: 19.2s\tremaining: 29.3s\n",
      "198:\tlearn: 0.0016056\ttotal: 19.3s\tremaining: 29.2s\n",
      "199:\tlearn: 0.0016056\ttotal: 19.3s\tremaining: 29s\n",
      "200:\tlearn: 0.0016056\ttotal: 19.4s\tremaining: 28.8s\n",
      "201:\tlearn: 0.0016056\ttotal: 19.4s\tremaining: 28.7s\n",
      "202:\tlearn: 0.0016056\ttotal: 19.5s\tremaining: 28.5s\n",
      "203:\tlearn: 0.0016053\ttotal: 19.5s\tremaining: 28.3s\n",
      "204:\tlearn: 0.0016043\ttotal: 19.6s\tremaining: 28.2s\n",
      "205:\tlearn: 0.0016043\ttotal: 19.6s\tremaining: 28s\n",
      "206:\tlearn: 0.0016043\ttotal: 19.7s\tremaining: 27.9s\n",
      "207:\tlearn: 0.0016043\ttotal: 19.7s\tremaining: 27.7s\n",
      "208:\tlearn: 0.0016043\ttotal: 19.8s\tremaining: 27.6s\n",
      "209:\tlearn: 0.0016043\ttotal: 19.9s\tremaining: 27.5s\n",
      "210:\tlearn: 0.0016042\ttotal: 19.9s\tremaining: 27.3s\n",
      "211:\tlearn: 0.0016041\ttotal: 20s\tremaining: 27.1s\n",
      "212:\tlearn: 0.0016041\ttotal: 20s\tremaining: 27s\n",
      "213:\tlearn: 0.0016041\ttotal: 20.1s\tremaining: 26.8s\n",
      "214:\tlearn: 0.0016041\ttotal: 20.1s\tremaining: 26.7s\n",
      "215:\tlearn: 0.0016041\ttotal: 20.2s\tremaining: 26.5s\n",
      "216:\tlearn: 0.0016041\ttotal: 20.2s\tremaining: 26.4s\n",
      "217:\tlearn: 0.0016040\ttotal: 20.3s\tremaining: 26.2s\n",
      "218:\tlearn: 0.0016040\ttotal: 20.3s\tremaining: 26.1s\n",
      "219:\tlearn: 0.0016039\ttotal: 20.4s\tremaining: 25.9s\n",
      "220:\tlearn: 0.0016039\ttotal: 20.4s\tremaining: 25.8s\n",
      "221:\tlearn: 0.0016039\ttotal: 20.5s\tremaining: 25.7s\n",
      "222:\tlearn: 0.0016039\ttotal: 20.6s\tremaining: 25.6s\n",
      "223:\tlearn: 0.0016031\ttotal: 20.6s\tremaining: 25.4s\n",
      "224:\tlearn: 0.0016031\ttotal: 20.7s\tremaining: 25.3s\n",
      "225:\tlearn: 0.0016031\ttotal: 20.8s\tremaining: 25.2s\n",
      "226:\tlearn: 0.0016029\ttotal: 20.8s\tremaining: 25s\n",
      "227:\tlearn: 0.0016028\ttotal: 20.9s\tremaining: 24.9s\n",
      "228:\tlearn: 0.0016019\ttotal: 20.9s\tremaining: 24.8s\n",
      "229:\tlearn: 0.0016019\ttotal: 21s\tremaining: 24.7s\n",
      "230:\tlearn: 0.0016015\ttotal: 21.1s\tremaining: 24.5s\n",
      "231:\tlearn: 0.0016015\ttotal: 21.1s\tremaining: 24.4s\n",
      "232:\tlearn: 0.0016015\ttotal: 21.2s\tremaining: 24.3s\n",
      "233:\tlearn: 0.0016015\ttotal: 21.2s\tremaining: 24.1s\n",
      "234:\tlearn: 0.0016015\ttotal: 21.3s\tremaining: 24s\n",
      "235:\tlearn: 0.0016014\ttotal: 21.3s\tremaining: 23.9s\n",
      "236:\tlearn: 0.0016014\ttotal: 21.4s\tremaining: 23.8s\n",
      "237:\tlearn: 0.0015972\ttotal: 21.5s\tremaining: 23.6s\n",
      "238:\tlearn: 0.0015971\ttotal: 21.5s\tremaining: 23.5s\n",
      "239:\tlearn: 0.0015971\ttotal: 21.6s\tremaining: 23.4s\n",
      "240:\tlearn: 0.0015971\ttotal: 21.7s\tremaining: 23.3s\n",
      "241:\tlearn: 0.0015971\ttotal: 21.7s\tremaining: 23.2s\n",
      "242:\tlearn: 0.0015971\ttotal: 21.8s\tremaining: 23.1s\n",
      "243:\tlearn: 0.0015822\ttotal: 21.9s\tremaining: 23s\n",
      "244:\tlearn: 0.0015822\ttotal: 22s\tremaining: 22.9s\n",
      "245:\tlearn: 0.0015822\ttotal: 22s\tremaining: 22.7s\n",
      "246:\tlearn: 0.0015821\ttotal: 22.1s\tremaining: 22.6s\n",
      "247:\tlearn: 0.0015821\ttotal: 22.1s\tremaining: 22.5s\n",
      "248:\tlearn: 0.0015816\ttotal: 22.2s\tremaining: 22.3s\n",
      "249:\tlearn: 0.0015816\ttotal: 22.2s\tremaining: 22.2s\n",
      "250:\tlearn: 0.0015816\ttotal: 22.2s\tremaining: 22.1s\n",
      "251:\tlearn: 0.0015816\ttotal: 22.3s\tremaining: 21.9s\n",
      "252:\tlearn: 0.0015816\ttotal: 22.3s\tremaining: 21.8s\n",
      "253:\tlearn: 0.0015816\ttotal: 22.4s\tremaining: 21.7s\n",
      "254:\tlearn: 0.0015816\ttotal: 22.4s\tremaining: 21.6s\n",
      "255:\tlearn: 0.0015811\ttotal: 22.5s\tremaining: 21.4s\n",
      "256:\tlearn: 0.0015807\ttotal: 22.5s\tremaining: 21.3s\n",
      "257:\tlearn: 0.0015807\ttotal: 22.6s\tremaining: 21.2s\n",
      "258:\tlearn: 0.0015807\ttotal: 22.6s\tremaining: 21.1s\n",
      "259:\tlearn: 0.0015807\ttotal: 22.7s\tremaining: 20.9s\n",
      "260:\tlearn: 0.0015807\ttotal: 22.7s\tremaining: 20.8s\n",
      "261:\tlearn: 0.0015807\ttotal: 22.8s\tremaining: 20.7s\n",
      "262:\tlearn: 0.0015806\ttotal: 22.9s\tremaining: 20.6s\n",
      "263:\tlearn: 0.0015806\ttotal: 22.9s\tremaining: 20.5s\n",
      "264:\tlearn: 0.0015806\ttotal: 23s\tremaining: 20.4s\n",
      "265:\tlearn: 0.0015806\ttotal: 23s\tremaining: 20.3s\n",
      "266:\tlearn: 0.0015806\ttotal: 23.1s\tremaining: 20.2s\n",
      "267:\tlearn: 0.0015806\ttotal: 23.2s\tremaining: 20.1s\n",
      "268:\tlearn: 0.0015806\ttotal: 23.2s\tremaining: 19.9s\n",
      "269:\tlearn: 0.0015806\ttotal: 23.3s\tremaining: 19.8s\n",
      "270:\tlearn: 0.0015806\ttotal: 23.4s\tremaining: 19.8s\n",
      "271:\tlearn: 0.0015806\ttotal: 23.5s\tremaining: 19.7s\n",
      "272:\tlearn: 0.0015806\ttotal: 23.6s\tremaining: 19.6s\n",
      "273:\tlearn: 0.0015805\ttotal: 23.6s\tremaining: 19.5s\n",
      "274:\tlearn: 0.0015805\ttotal: 23.8s\tremaining: 19.4s\n",
      "275:\tlearn: 0.0015805\ttotal: 23.9s\tremaining: 19.4s\n",
      "276:\tlearn: 0.0015805\ttotal: 24s\tremaining: 19.3s\n",
      "277:\tlearn: 0.0015805\ttotal: 24.1s\tremaining: 19.2s\n",
      "278:\tlearn: 0.0015805\ttotal: 24.1s\tremaining: 19.1s\n",
      "279:\tlearn: 0.0015803\ttotal: 24.2s\tremaining: 19s\n",
      "280:\tlearn: 0.0015787\ttotal: 24.3s\tremaining: 18.9s\n",
      "281:\tlearn: 0.0015787\ttotal: 24.4s\tremaining: 18.8s\n",
      "282:\tlearn: 0.0015787\ttotal: 24.5s\tremaining: 18.8s\n",
      "283:\tlearn: 0.0015787\ttotal: 24.6s\tremaining: 18.7s\n",
      "284:\tlearn: 0.0015787\ttotal: 24.6s\tremaining: 18.6s\n",
      "285:\tlearn: 0.0015787\ttotal: 24.7s\tremaining: 18.5s\n",
      "286:\tlearn: 0.0015787\ttotal: 24.7s\tremaining: 18.4s\n",
      "287:\tlearn: 0.0015787\ttotal: 24.8s\tremaining: 18.2s\n",
      "288:\tlearn: 0.0015787\ttotal: 24.9s\tremaining: 18.2s\n",
      "289:\tlearn: 0.0015786\ttotal: 24.9s\tremaining: 18.1s\n",
      "290:\tlearn: 0.0015786\ttotal: 25s\tremaining: 18s\n",
      "291:\tlearn: 0.0015786\ttotal: 25.1s\tremaining: 17.9s\n",
      "292:\tlearn: 0.0015786\ttotal: 25.2s\tremaining: 17.8s\n",
      "293:\tlearn: 0.0015783\ttotal: 25.2s\tremaining: 17.7s\n",
      "294:\tlearn: 0.0015783\ttotal: 25.3s\tremaining: 17.6s\n",
      "295:\tlearn: 0.0015783\ttotal: 25.4s\tremaining: 17.5s\n",
      "296:\tlearn: 0.0015783\ttotal: 25.4s\tremaining: 17.4s\n",
      "297:\tlearn: 0.0015783\ttotal: 25.5s\tremaining: 17.3s\n",
      "298:\tlearn: 0.0015783\ttotal: 25.5s\tremaining: 17.2s\n",
      "299:\tlearn: 0.0015783\ttotal: 25.6s\tremaining: 17.1s\n",
      "300:\tlearn: 0.0015783\ttotal: 25.7s\tremaining: 17s\n",
      "301:\tlearn: 0.0015783\ttotal: 25.8s\tremaining: 16.9s\n",
      "302:\tlearn: 0.0015783\ttotal: 25.9s\tremaining: 16.8s\n",
      "303:\tlearn: 0.0015783\ttotal: 25.9s\tremaining: 16.7s\n",
      "304:\tlearn: 0.0015783\ttotal: 26s\tremaining: 16.6s\n",
      "305:\tlearn: 0.0015783\ttotal: 26s\tremaining: 16.5s\n",
      "306:\tlearn: 0.0015783\ttotal: 26.1s\tremaining: 16.4s\n",
      "307:\tlearn: 0.0015780\ttotal: 26.2s\tremaining: 16.3s\n",
      "308:\tlearn: 0.0015780\ttotal: 26.3s\tremaining: 16.3s\n",
      "309:\tlearn: 0.0015780\ttotal: 26.5s\tremaining: 16.3s\n",
      "310:\tlearn: 0.0015780\ttotal: 26.6s\tremaining: 16.2s\n",
      "311:\tlearn: 0.0015780\ttotal: 26.7s\tremaining: 16.1s\n",
      "312:\tlearn: 0.0015771\ttotal: 26.7s\tremaining: 16s\n",
      "313:\tlearn: 0.0015771\ttotal: 26.8s\tremaining: 15.9s\n",
      "314:\tlearn: 0.0015771\ttotal: 26.8s\tremaining: 15.8s\n",
      "315:\tlearn: 0.0015771\ttotal: 26.9s\tremaining: 15.7s\n",
      "316:\tlearn: 0.0015770\ttotal: 27s\tremaining: 15.6s\n",
      "317:\tlearn: 0.0015770\ttotal: 27.1s\tremaining: 15.5s\n",
      "318:\tlearn: 0.0015770\ttotal: 27.1s\tremaining: 15.4s\n",
      "319:\tlearn: 0.0015770\ttotal: 27.2s\tremaining: 15.3s\n",
      "320:\tlearn: 0.0015770\ttotal: 27.3s\tremaining: 15.2s\n",
      "321:\tlearn: 0.0015770\ttotal: 27.3s\tremaining: 15.1s\n",
      "322:\tlearn: 0.0015770\ttotal: 27.4s\tremaining: 15s\n",
      "323:\tlearn: 0.0015770\ttotal: 27.4s\tremaining: 14.9s\n",
      "324:\tlearn: 0.0015770\ttotal: 27.5s\tremaining: 14.8s\n",
      "325:\tlearn: 0.0015769\ttotal: 27.6s\tremaining: 14.7s\n",
      "326:\tlearn: 0.0015769\ttotal: 27.6s\tremaining: 14.6s\n",
      "327:\tlearn: 0.0015769\ttotal: 27.7s\tremaining: 14.5s\n",
      "328:\tlearn: 0.0015769\ttotal: 27.7s\tremaining: 14.4s\n",
      "329:\tlearn: 0.0015766\ttotal: 27.8s\tremaining: 14.3s\n",
      "330:\tlearn: 0.0015766\ttotal: 27.9s\tremaining: 14.2s\n",
      "331:\tlearn: 0.0015766\ttotal: 27.9s\tremaining: 14.1s\n",
      "332:\tlearn: 0.0015766\ttotal: 28s\tremaining: 14.1s\n",
      "333:\tlearn: 0.0015766\ttotal: 28.1s\tremaining: 14s\n",
      "334:\tlearn: 0.0015748\ttotal: 28.2s\tremaining: 13.9s\n",
      "335:\tlearn: 0.0015748\ttotal: 28.2s\tremaining: 13.8s\n",
      "336:\tlearn: 0.0015748\ttotal: 28.3s\tremaining: 13.7s\n",
      "337:\tlearn: 0.0015740\ttotal: 28.4s\tremaining: 13.6s\n",
      "338:\tlearn: 0.0015740\ttotal: 28.5s\tremaining: 13.5s\n",
      "339:\tlearn: 0.0015740\ttotal: 28.5s\tremaining: 13.4s\n",
      "340:\tlearn: 0.0015733\ttotal: 28.6s\tremaining: 13.3s\n",
      "341:\tlearn: 0.0015733\ttotal: 28.7s\tremaining: 13.2s\n",
      "342:\tlearn: 0.0015733\ttotal: 28.7s\tremaining: 13.1s\n",
      "343:\tlearn: 0.0015733\ttotal: 28.8s\tremaining: 13.1s\n",
      "344:\tlearn: 0.0015732\ttotal: 28.9s\tremaining: 13s\n",
      "345:\tlearn: 0.0015732\ttotal: 28.9s\tremaining: 12.9s\n",
      "346:\tlearn: 0.0015732\ttotal: 29.1s\tremaining: 12.8s\n",
      "347:\tlearn: 0.0015732\ttotal: 29.2s\tremaining: 12.7s\n",
      "348:\tlearn: 0.0015732\ttotal: 29.2s\tremaining: 12.7s\n",
      "349:\tlearn: 0.0015732\ttotal: 29.3s\tremaining: 12.6s\n",
      "350:\tlearn: 0.0015732\ttotal: 29.4s\tremaining: 12.5s\n",
      "351:\tlearn: 0.0015731\ttotal: 29.4s\tremaining: 12.4s\n",
      "352:\tlearn: 0.0015731\ttotal: 29.5s\tremaining: 12.3s\n",
      "353:\tlearn: 0.0015731\ttotal: 29.6s\tremaining: 12.2s\n",
      "354:\tlearn: 0.0015730\ttotal: 29.7s\tremaining: 12.1s\n",
      "355:\tlearn: 0.0015729\ttotal: 29.7s\tremaining: 12s\n",
      "356:\tlearn: 0.0015729\ttotal: 29.8s\tremaining: 11.9s\n",
      "357:\tlearn: 0.0015729\ttotal: 29.9s\tremaining: 11.9s\n",
      "358:\tlearn: 0.0015729\ttotal: 30s\tremaining: 11.8s\n",
      "359:\tlearn: 0.0015729\ttotal: 30s\tremaining: 11.7s\n",
      "360:\tlearn: 0.0015729\ttotal: 30.1s\tremaining: 11.6s\n",
      "361:\tlearn: 0.0015729\ttotal: 30.1s\tremaining: 11.5s\n",
      "362:\tlearn: 0.0015728\ttotal: 30.2s\tremaining: 11.4s\n",
      "363:\tlearn: 0.0015728\ttotal: 30.2s\tremaining: 11.3s\n",
      "364:\tlearn: 0.0015728\ttotal: 30.3s\tremaining: 11.2s\n",
      "365:\tlearn: 0.0015728\ttotal: 30.3s\tremaining: 11.1s\n",
      "366:\tlearn: 0.0015728\ttotal: 30.4s\tremaining: 11s\n",
      "367:\tlearn: 0.0015698\ttotal: 30.5s\tremaining: 10.9s\n",
      "368:\tlearn: 0.0015698\ttotal: 30.5s\tremaining: 10.8s\n",
      "369:\tlearn: 0.0015698\ttotal: 30.6s\tremaining: 10.7s\n",
      "370:\tlearn: 0.0015698\ttotal: 30.6s\tremaining: 10.7s\n",
      "371:\tlearn: 0.0015694\ttotal: 30.7s\tremaining: 10.6s\n",
      "372:\tlearn: 0.0015693\ttotal: 30.7s\tremaining: 10.5s\n",
      "373:\tlearn: 0.0015693\ttotal: 30.8s\tremaining: 10.4s\n",
      "374:\tlearn: 0.0015693\ttotal: 30.9s\tremaining: 10.3s\n",
      "375:\tlearn: 0.0015693\ttotal: 31s\tremaining: 10.2s\n",
      "376:\tlearn: 0.0015693\ttotal: 31s\tremaining: 10.1s\n",
      "377:\tlearn: 0.0015693\ttotal: 31.1s\tremaining: 10s\n",
      "378:\tlearn: 0.0015693\ttotal: 31.1s\tremaining: 9.94s\n",
      "379:\tlearn: 0.0015693\ttotal: 31.2s\tremaining: 9.85s\n",
      "380:\tlearn: 0.0015693\ttotal: 31.2s\tremaining: 9.76s\n",
      "381:\tlearn: 0.0015693\ttotal: 31.3s\tremaining: 9.67s\n",
      "382:\tlearn: 0.0015683\ttotal: 31.4s\tremaining: 9.58s\n",
      "383:\tlearn: 0.0015683\ttotal: 31.4s\tremaining: 9.49s\n",
      "384:\tlearn: 0.0015683\ttotal: 31.5s\tremaining: 9.4s\n",
      "385:\tlearn: 0.0015683\ttotal: 31.5s\tremaining: 9.31s\n",
      "386:\tlearn: 0.0015683\ttotal: 31.6s\tremaining: 9.22s\n",
      "387:\tlearn: 0.0015679\ttotal: 31.6s\tremaining: 9.13s\n",
      "388:\tlearn: 0.0015679\ttotal: 31.7s\tremaining: 9.05s\n",
      "389:\tlearn: 0.0015679\ttotal: 31.8s\tremaining: 8.96s\n",
      "390:\tlearn: 0.0015679\ttotal: 31.8s\tremaining: 8.86s\n",
      "391:\tlearn: 0.0015679\ttotal: 31.8s\tremaining: 8.77s\n",
      "392:\tlearn: 0.0015679\ttotal: 31.9s\tremaining: 8.68s\n",
      "393:\tlearn: 0.0015679\ttotal: 31.9s\tremaining: 8.59s\n",
      "394:\tlearn: 0.0015679\ttotal: 32s\tremaining: 8.51s\n",
      "395:\tlearn: 0.0015679\ttotal: 32.1s\tremaining: 8.42s\n",
      "396:\tlearn: 0.0015679\ttotal: 32.1s\tremaining: 8.34s\n",
      "397:\tlearn: 0.0015679\ttotal: 32.2s\tremaining: 8.25s\n",
      "398:\tlearn: 0.0015679\ttotal: 32.3s\tremaining: 8.16s\n",
      "399:\tlearn: 0.0015679\ttotal: 32.3s\tremaining: 8.08s\n",
      "400:\tlearn: 0.0015679\ttotal: 32.4s\tremaining: 7.99s\n",
      "401:\tlearn: 0.0015679\ttotal: 32.5s\tremaining: 7.91s\n",
      "402:\tlearn: 0.0015679\ttotal: 32.5s\tremaining: 7.83s\n",
      "403:\tlearn: 0.0015679\ttotal: 32.6s\tremaining: 7.74s\n",
      "404:\tlearn: 0.0015678\ttotal: 32.6s\tremaining: 7.66s\n",
      "405:\tlearn: 0.0015678\ttotal: 32.7s\tremaining: 7.57s\n",
      "406:\tlearn: 0.0015678\ttotal: 32.8s\tremaining: 7.49s\n",
      "407:\tlearn: 0.0015678\ttotal: 32.8s\tremaining: 7.4s\n",
      "408:\tlearn: 0.0015678\ttotal: 32.9s\tremaining: 7.32s\n",
      "409:\tlearn: 0.0015678\ttotal: 33s\tremaining: 7.24s\n",
      "410:\tlearn: 0.0015678\ttotal: 33.1s\tremaining: 7.16s\n",
      "411:\tlearn: 0.0015678\ttotal: 33.1s\tremaining: 7.08s\n",
      "412:\tlearn: 0.0015678\ttotal: 33.2s\tremaining: 6.99s\n",
      "413:\tlearn: 0.0015678\ttotal: 33.3s\tremaining: 6.91s\n",
      "414:\tlearn: 0.0015678\ttotal: 33.3s\tremaining: 6.83s\n",
      "415:\tlearn: 0.0015678\ttotal: 33.4s\tremaining: 6.74s\n",
      "416:\tlearn: 0.0015678\ttotal: 33.4s\tremaining: 6.65s\n",
      "417:\tlearn: 0.0015678\ttotal: 33.5s\tremaining: 6.57s\n",
      "418:\tlearn: 0.0015678\ttotal: 33.5s\tremaining: 6.48s\n",
      "419:\tlearn: 0.0015667\ttotal: 33.6s\tremaining: 6.4s\n",
      "420:\tlearn: 0.0015667\ttotal: 33.7s\tremaining: 6.32s\n",
      "421:\tlearn: 0.0015667\ttotal: 33.7s\tremaining: 6.23s\n",
      "422:\tlearn: 0.0015667\ttotal: 33.8s\tremaining: 6.15s\n",
      "423:\tlearn: 0.0015667\ttotal: 33.8s\tremaining: 6.06s\n",
      "424:\tlearn: 0.0015666\ttotal: 33.9s\tremaining: 5.98s\n",
      "425:\tlearn: 0.0015666\ttotal: 33.9s\tremaining: 5.89s\n",
      "426:\tlearn: 0.0015666\ttotal: 34s\tremaining: 5.81s\n",
      "427:\tlearn: 0.0015659\ttotal: 34s\tremaining: 5.72s\n",
      "428:\tlearn: 0.0015659\ttotal: 34.1s\tremaining: 5.64s\n",
      "429:\tlearn: 0.0015659\ttotal: 34.1s\tremaining: 5.55s\n",
      "430:\tlearn: 0.0015659\ttotal: 34.2s\tremaining: 5.47s\n",
      "431:\tlearn: 0.0015659\ttotal: 34.2s\tremaining: 5.39s\n",
      "432:\tlearn: 0.0015659\ttotal: 34.3s\tremaining: 5.31s\n",
      "433:\tlearn: 0.0015659\ttotal: 34.4s\tremaining: 5.23s\n",
      "434:\tlearn: 0.0015659\ttotal: 34.4s\tremaining: 5.14s\n",
      "435:\tlearn: 0.0015659\ttotal: 34.5s\tremaining: 5.06s\n",
      "436:\tlearn: 0.0015659\ttotal: 34.5s\tremaining: 4.97s\n",
      "437:\tlearn: 0.0015658\ttotal: 34.6s\tremaining: 4.89s\n",
      "438:\tlearn: 0.0015658\ttotal: 34.6s\tremaining: 4.81s\n",
      "439:\tlearn: 0.0015658\ttotal: 34.7s\tremaining: 4.72s\n",
      "440:\tlearn: 0.0015658\ttotal: 34.7s\tremaining: 4.64s\n",
      "441:\tlearn: 0.0015656\ttotal: 34.8s\tremaining: 4.56s\n",
      "442:\tlearn: 0.0015656\ttotal: 34.8s\tremaining: 4.48s\n",
      "443:\tlearn: 0.0015656\ttotal: 34.9s\tremaining: 4.4s\n",
      "444:\tlearn: 0.0015656\ttotal: 34.9s\tremaining: 4.32s\n",
      "445:\tlearn: 0.0015653\ttotal: 35s\tremaining: 4.24s\n",
      "446:\tlearn: 0.0015653\ttotal: 35s\tremaining: 4.16s\n",
      "447:\tlearn: 0.0015653\ttotal: 35.1s\tremaining: 4.08s\n",
      "448:\tlearn: 0.0015653\ttotal: 35.2s\tremaining: 3.99s\n",
      "449:\tlearn: 0.0015653\ttotal: 35.2s\tremaining: 3.91s\n",
      "450:\tlearn: 0.0015653\ttotal: 35.3s\tremaining: 3.83s\n",
      "451:\tlearn: 0.0015653\ttotal: 35.4s\tremaining: 3.75s\n",
      "452:\tlearn: 0.0015652\ttotal: 35.4s\tremaining: 3.68s\n",
      "453:\tlearn: 0.0015652\ttotal: 35.5s\tremaining: 3.6s\n",
      "454:\tlearn: 0.0015652\ttotal: 35.6s\tremaining: 3.52s\n",
      "455:\tlearn: 0.0015644\ttotal: 35.6s\tremaining: 3.44s\n",
      "456:\tlearn: 0.0015644\ttotal: 35.7s\tremaining: 3.36s\n",
      "457:\tlearn: 0.0015644\ttotal: 35.7s\tremaining: 3.28s\n",
      "458:\tlearn: 0.0015642\ttotal: 35.8s\tremaining: 3.2s\n",
      "459:\tlearn: 0.0015641\ttotal: 35.9s\tremaining: 3.12s\n",
      "460:\tlearn: 0.0015641\ttotal: 35.9s\tremaining: 3.04s\n",
      "461:\tlearn: 0.0015641\ttotal: 36s\tremaining: 2.96s\n",
      "462:\tlearn: 0.0015641\ttotal: 36s\tremaining: 2.88s\n",
      "463:\tlearn: 0.0015639\ttotal: 36.1s\tremaining: 2.8s\n",
      "464:\tlearn: 0.0015638\ttotal: 36.2s\tremaining: 2.73s\n",
      "465:\tlearn: 0.0015638\ttotal: 36.3s\tremaining: 2.65s\n",
      "466:\tlearn: 0.0015638\ttotal: 36.4s\tremaining: 2.57s\n",
      "467:\tlearn: 0.0015638\ttotal: 36.4s\tremaining: 2.49s\n",
      "468:\tlearn: 0.0015637\ttotal: 36.5s\tremaining: 2.41s\n",
      "469:\tlearn: 0.0015637\ttotal: 36.5s\tremaining: 2.33s\n",
      "470:\tlearn: 0.0015637\ttotal: 36.5s\tremaining: 2.25s\n",
      "471:\tlearn: 0.0015637\ttotal: 36.6s\tremaining: 2.17s\n",
      "472:\tlearn: 0.0015637\ttotal: 36.6s\tremaining: 2.09s\n",
      "473:\tlearn: 0.0015635\ttotal: 36.7s\tremaining: 2.01s\n",
      "474:\tlearn: 0.0015635\ttotal: 36.8s\tremaining: 1.94s\n",
      "475:\tlearn: 0.0015634\ttotal: 36.9s\tremaining: 1.86s\n",
      "476:\tlearn: 0.0015634\ttotal: 36.9s\tremaining: 1.78s\n",
      "477:\tlearn: 0.0015634\ttotal: 37s\tremaining: 1.7s\n",
      "478:\tlearn: 0.0015634\ttotal: 37.1s\tremaining: 1.63s\n",
      "479:\tlearn: 0.0015634\ttotal: 37.1s\tremaining: 1.55s\n",
      "480:\tlearn: 0.0015634\ttotal: 37.2s\tremaining: 1.47s\n",
      "481:\tlearn: 0.0015634\ttotal: 37.3s\tremaining: 1.39s\n",
      "482:\tlearn: 0.0015629\ttotal: 37.3s\tremaining: 1.31s\n",
      "483:\tlearn: 0.0015629\ttotal: 37.4s\tremaining: 1.24s\n",
      "484:\tlearn: 0.0015628\ttotal: 37.5s\tremaining: 1.16s\n",
      "485:\tlearn: 0.0015628\ttotal: 37.6s\tremaining: 1.08s\n",
      "486:\tlearn: 0.0015628\ttotal: 37.6s\tremaining: 1s\n",
      "487:\tlearn: 0.0015628\ttotal: 37.7s\tremaining: 927ms\n",
      "488:\tlearn: 0.0015628\ttotal: 37.8s\tremaining: 850ms\n",
      "489:\tlearn: 0.0015628\ttotal: 37.8s\tremaining: 772ms\n",
      "490:\tlearn: 0.0015628\ttotal: 37.9s\tremaining: 695ms\n",
      "491:\tlearn: 0.0015628\ttotal: 38s\tremaining: 618ms\n",
      "492:\tlearn: 0.0015624\ttotal: 38.1s\tremaining: 540ms\n",
      "493:\tlearn: 0.0015624\ttotal: 38.1s\tremaining: 463ms\n",
      "494:\tlearn: 0.0015624\ttotal: 38.2s\tremaining: 386ms\n",
      "495:\tlearn: 0.0015622\ttotal: 38.3s\tremaining: 309ms\n",
      "496:\tlearn: 0.0015622\ttotal: 38.4s\tremaining: 232ms\n",
      "497:\tlearn: 0.0015622\ttotal: 38.5s\tremaining: 154ms\n",
      "498:\tlearn: 0.0015622\ttotal: 38.5s\tremaining: 77.2ms\n",
      "499:\tlearn: 0.0015622\ttotal: 38.6s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:153: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# %pip install catboost\n",
    "from catboost import CatBoostClassifier\n",
    "#train catboost regression model on training set against class label\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "cat_reg=CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.5,\n",
    "    depth=7\n",
    ")\n",
    "cat_reg.fit(X_train_scaled,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "cat_train_set_predictions=cat_reg.predict(X_train_scaled)\n",
    "\n",
    "\n",
    "#test model on test set\n",
    "cat_test_set_predictions=cat_reg.predict(X_test_scaled)\n",
    "\n",
    "#convert y_pred\n",
    "cat_test_set_predictions=np.round(cat_test_set_predictions)\n",
    "cat_test_set_predictions=le.inverse_transform(cat_test_set_predictions.astype(int))\n",
    "\n",
    "cat_accuracy=accuracy_score(y_test,cat_test_set_predictions)\n",
    "cat_confusion_matrix=confusion_matrix(y_test,cat_test_set_predictions)\n",
    "cat_classification_report=classification_report(y_test,cat_test_set_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_accuracy\n",
      " 0.9990211107622408\n",
      "[[ 2536     0    10]\n",
      " [    0   162     0]\n",
      " [   43     0 51392]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      2546\n",
      "         7.0       1.00      1.00      1.00       162\n",
      "       107.0       1.00      1.00      1.00     51435\n",
      "\n",
      "    accuracy                           1.00     54143\n",
      "   macro avg       0.99      1.00      1.00     54143\n",
      "weighted avg       1.00      1.00      1.00     54143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"cat_accuracy\\n\",cat_accuracy)\n",
    "print(cat_confusion_matrix)\n",
    "print(cat_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1278\n",
      "[LightGBM] [Info] Number of data points in the train set: 216570, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -3.077331\n",
      "[LightGBM] [Info] Start training from score -5.794946\n",
      "[LightGBM] [Info] Start training from score -0.050373\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "lgb_accuracy\n",
      " 0.9990949891952792\n",
      "[[ 2539     0     7]\n",
      " [    0   162     0]\n",
      " [   40     2 51393]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      2546\n",
      "         7.0       0.99      1.00      0.99       162\n",
      "       107.0       1.00      1.00      1.00     51435\n",
      "\n",
      "    accuracy                           1.00     54143\n",
      "   macro avg       0.99      1.00      0.99     54143\n",
      "weighted avg       1.00      1.00      1.00     54143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#train lightgbm regression model on training set against class label\n",
    "le = LabelEncoder()\n",
    "y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "lgb_reg=lgb.LGBMClassifier()\n",
    "lgb_reg.fit(X_train_scaled,y_trainLE)\n",
    "\n",
    "#predict class label on training set\n",
    "lgb_train_set_predictions=lgb_reg.predict(X_train_scaled)\n",
    "\n",
    "#test model on test set\n",
    "lgb_test_set_predictions=lgb_reg.predict(X_test_scaled)\n",
    "\n",
    "#convert y_pred\n",
    "lgb_test_set_predictions=np.round(lgb_test_set_predictions)\n",
    "lgb_test_set_predictions=le.inverse_transform(lgb_test_set_predictions.astype(int))\n",
    "\n",
    "lgb_accuracy=accuracy_score(y_test,lgb_test_set_predictions)\n",
    "lgb_confusion_matrix=confusion_matrix(y_test,lgb_test_set_predictions)\n",
    "lgb_classification_report=classification_report(y_test,lgb_test_set_predictions)\n",
    "\n",
    "print(\"lgb_accuracy\\n\",lgb_accuracy)\n",
    "print(lgb_confusion_matrix)\n",
    "print(lgb_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tune hyperparameters for lightgbm\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # scale the data\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# y_trainLE = le.fit_transform(y_train)\n",
    "\n",
    "# lgb_reg=lgb.LGBMClassifier()\n",
    "\n",
    "# # define the grid of hyperparameters to search\n",
    "# search_space = {'n_estimators': [100, 200, 500],\n",
    "#                 'learning_rate': [0.01, 0.05, 0.1],\n",
    "#                 'max_depth': [3, 5, 7]}\n",
    "# # define search\n",
    "# grid_search = GridSearchCV(lgb_reg, search_space, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "# # execute search\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_trainLE)\n",
    "# # summarize result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3861038\ttotal: 89.3ms\tremaining: 44.5s\n",
      "1:\tlearn: 0.2189519\ttotal: 149ms\tremaining: 37.1s\n",
      "2:\tlearn: 0.1240743\ttotal: 217ms\tremaining: 36s\n",
      "3:\tlearn: 0.0788224\ttotal: 266ms\tremaining: 33s\n",
      "4:\tlearn: 0.0491858\ttotal: 317ms\tremaining: 31.4s\n",
      "5:\tlearn: 0.0339245\ttotal: 375ms\tremaining: 30.9s\n",
      "6:\tlearn: 0.0230531\ttotal: 437ms\tremaining: 30.8s\n",
      "7:\tlearn: 0.0166981\ttotal: 496ms\tremaining: 30.5s\n",
      "8:\tlearn: 0.0120986\ttotal: 568ms\tremaining: 31s\n",
      "9:\tlearn: 0.0092694\ttotal: 634ms\tremaining: 31s\n",
      "10:\tlearn: 0.0078769\ttotal: 736ms\tremaining: 32.7s\n",
      "11:\tlearn: 0.0063803\ttotal: 781ms\tremaining: 31.8s\n",
      "12:\tlearn: 0.0056869\ttotal: 855ms\tremaining: 32s\n",
      "13:\tlearn: 0.0045628\ttotal: 897ms\tremaining: 31.2s\n",
      "14:\tlearn: 0.0042310\ttotal: 943ms\tremaining: 30.5s\n",
      "15:\tlearn: 0.0038234\ttotal: 1.02s\tremaining: 30.8s\n",
      "16:\tlearn: 0.0033371\ttotal: 1.09s\tremaining: 31.1s\n",
      "17:\tlearn: 0.0029969\ttotal: 1.16s\tremaining: 31s\n",
      "18:\tlearn: 0.0028679\ttotal: 1.22s\tremaining: 30.8s\n",
      "19:\tlearn: 0.0027808\ttotal: 1.28s\tremaining: 30.6s\n",
      "20:\tlearn: 0.0025772\ttotal: 1.36s\tremaining: 31.1s\n",
      "21:\tlearn: 0.0025141\ttotal: 1.46s\tremaining: 31.8s\n",
      "22:\tlearn: 0.0023270\ttotal: 1.54s\tremaining: 31.9s\n",
      "23:\tlearn: 0.0022860\ttotal: 1.69s\tremaining: 33.6s\n",
      "24:\tlearn: 0.0022113\ttotal: 1.78s\tremaining: 33.8s\n",
      "25:\tlearn: 0.0022021\ttotal: 1.83s\tremaining: 33.4s\n",
      "26:\tlearn: 0.0021882\ttotal: 1.89s\tremaining: 33.1s\n",
      "27:\tlearn: 0.0020671\ttotal: 1.95s\tremaining: 32.9s\n",
      "28:\tlearn: 0.0020573\ttotal: 1.99s\tremaining: 32.4s\n",
      "29:\tlearn: 0.0020409\ttotal: 2.03s\tremaining: 31.8s\n",
      "30:\tlearn: 0.0020358\ttotal: 2.07s\tremaining: 31.4s\n",
      "31:\tlearn: 0.0020302\ttotal: 2.11s\tremaining: 30.9s\n",
      "32:\tlearn: 0.0019576\ttotal: 2.16s\tremaining: 30.6s\n",
      "33:\tlearn: 0.0019545\ttotal: 2.23s\tremaining: 30.5s\n",
      "34:\tlearn: 0.0019434\ttotal: 2.33s\tremaining: 30.9s\n",
      "35:\tlearn: 0.0019404\ttotal: 2.4s\tremaining: 31s\n",
      "36:\tlearn: 0.0019345\ttotal: 2.49s\tremaining: 31.2s\n",
      "37:\tlearn: 0.0019325\ttotal: 2.57s\tremaining: 31.3s\n",
      "38:\tlearn: 0.0019293\ttotal: 2.63s\tremaining: 31.1s\n",
      "39:\tlearn: 0.0019079\ttotal: 2.68s\tremaining: 30.8s\n",
      "40:\tlearn: 0.0019047\ttotal: 2.72s\tremaining: 30.5s\n",
      "41:\tlearn: 0.0019036\ttotal: 2.76s\tremaining: 30.1s\n",
      "42:\tlearn: 0.0019024\ttotal: 2.8s\tremaining: 29.8s\n",
      "43:\tlearn: 0.0019013\ttotal: 2.86s\tremaining: 29.7s\n",
      "44:\tlearn: 0.0018992\ttotal: 2.94s\tremaining: 29.7s\n",
      "45:\tlearn: 0.0018949\ttotal: 3s\tremaining: 29.7s\n",
      "46:\tlearn: 0.0018934\ttotal: 3.06s\tremaining: 29.5s\n",
      "47:\tlearn: 0.0018427\ttotal: 3.11s\tremaining: 29.3s\n",
      "48:\tlearn: 0.0018350\ttotal: 3.15s\tremaining: 29s\n",
      "49:\tlearn: 0.0018328\ttotal: 3.18s\tremaining: 28.7s\n",
      "50:\tlearn: 0.0018317\ttotal: 3.22s\tremaining: 28.4s\n",
      "51:\tlearn: 0.0018311\ttotal: 3.26s\tremaining: 28.1s\n",
      "52:\tlearn: 0.0018229\ttotal: 3.31s\tremaining: 27.9s\n",
      "53:\tlearn: 0.0018221\ttotal: 3.38s\tremaining: 27.9s\n",
      "54:\tlearn: 0.0018216\ttotal: 3.44s\tremaining: 27.9s\n",
      "55:\tlearn: 0.0018206\ttotal: 3.52s\tremaining: 27.9s\n",
      "56:\tlearn: 0.0018203\ttotal: 3.57s\tremaining: 27.8s\n",
      "57:\tlearn: 0.0018127\ttotal: 3.65s\tremaining: 27.8s\n",
      "58:\tlearn: 0.0018124\ttotal: 3.71s\tremaining: 27.7s\n",
      "59:\tlearn: 0.0018115\ttotal: 3.75s\tremaining: 27.5s\n",
      "60:\tlearn: 0.0018110\ttotal: 3.78s\tremaining: 27.2s\n",
      "61:\tlearn: 0.0017654\ttotal: 3.82s\tremaining: 27s\n",
      "62:\tlearn: 0.0017651\ttotal: 3.86s\tremaining: 26.8s\n",
      "63:\tlearn: 0.0017645\ttotal: 3.9s\tremaining: 26.5s\n",
      "64:\tlearn: 0.0017642\ttotal: 3.93s\tremaining: 26.3s\n",
      "65:\tlearn: 0.0017596\ttotal: 3.97s\tremaining: 26.1s\n",
      "66:\tlearn: 0.0017584\ttotal: 4s\tremaining: 25.9s\n",
      "67:\tlearn: 0.0017396\ttotal: 4.04s\tremaining: 25.7s\n",
      "68:\tlearn: 0.0017393\ttotal: 4.08s\tremaining: 25.5s\n",
      "69:\tlearn: 0.0017391\ttotal: 4.12s\tremaining: 25.3s\n",
      "70:\tlearn: 0.0017389\ttotal: 4.15s\tremaining: 25.1s\n",
      "71:\tlearn: 0.0017385\ttotal: 4.19s\tremaining: 24.9s\n",
      "72:\tlearn: 0.0017383\ttotal: 4.22s\tremaining: 24.7s\n",
      "73:\tlearn: 0.0017381\ttotal: 4.26s\tremaining: 24.5s\n",
      "74:\tlearn: 0.0017380\ttotal: 4.3s\tremaining: 24.4s\n",
      "75:\tlearn: 0.0017374\ttotal: 4.34s\tremaining: 24.2s\n",
      "76:\tlearn: 0.0017372\ttotal: 4.38s\tremaining: 24.1s\n",
      "77:\tlearn: 0.0017371\ttotal: 4.42s\tremaining: 23.9s\n",
      "78:\tlearn: 0.0017367\ttotal: 4.45s\tremaining: 23.7s\n",
      "79:\tlearn: 0.0017366\ttotal: 4.49s\tremaining: 23.6s\n",
      "80:\tlearn: 0.0017365\ttotal: 4.53s\tremaining: 23.4s\n",
      "81:\tlearn: 0.0017364\ttotal: 4.57s\tremaining: 23.3s\n",
      "82:\tlearn: 0.0017341\ttotal: 4.61s\tremaining: 23.2s\n",
      "83:\tlearn: 0.0017340\ttotal: 4.65s\tremaining: 23s\n",
      "84:\tlearn: 0.0017339\ttotal: 4.68s\tremaining: 22.9s\n",
      "85:\tlearn: 0.0017334\ttotal: 4.74s\tremaining: 22.8s\n",
      "86:\tlearn: 0.0017333\ttotal: 4.79s\tremaining: 22.7s\n",
      "87:\tlearn: 0.0017329\ttotal: 4.85s\tremaining: 22.7s\n",
      "88:\tlearn: 0.0017326\ttotal: 4.9s\tremaining: 22.6s\n",
      "89:\tlearn: 0.0017325\ttotal: 4.94s\tremaining: 22.5s\n",
      "90:\tlearn: 0.0017323\ttotal: 5s\tremaining: 22.5s\n",
      "91:\tlearn: 0.0016863\ttotal: 5.05s\tremaining: 22.4s\n",
      "92:\tlearn: 0.0016861\ttotal: 5.09s\tremaining: 22.3s\n",
      "93:\tlearn: 0.0016860\ttotal: 5.13s\tremaining: 22.2s\n",
      "94:\tlearn: 0.0016756\ttotal: 5.18s\tremaining: 22.1s\n",
      "95:\tlearn: 0.0016753\ttotal: 5.23s\tremaining: 22s\n",
      "96:\tlearn: 0.0016752\ttotal: 5.27s\tremaining: 21.9s\n",
      "97:\tlearn: 0.0016751\ttotal: 5.31s\tremaining: 21.8s\n",
      "98:\tlearn: 0.0016612\ttotal: 5.35s\tremaining: 21.7s\n",
      "99:\tlearn: 0.0016501\ttotal: 5.4s\tremaining: 21.6s\n",
      "100:\tlearn: 0.0016496\ttotal: 5.44s\tremaining: 21.5s\n",
      "101:\tlearn: 0.0016495\ttotal: 5.48s\tremaining: 21.4s\n",
      "102:\tlearn: 0.0016495\ttotal: 5.52s\tremaining: 21.3s\n",
      "103:\tlearn: 0.0016494\ttotal: 5.55s\tremaining: 21.1s\n",
      "104:\tlearn: 0.0016493\ttotal: 5.59s\tremaining: 21s\n",
      "105:\tlearn: 0.0016493\ttotal: 5.63s\tremaining: 20.9s\n",
      "106:\tlearn: 0.0016492\ttotal: 5.68s\tremaining: 20.8s\n",
      "107:\tlearn: 0.0016423\ttotal: 5.72s\tremaining: 20.8s\n",
      "108:\tlearn: 0.0016423\ttotal: 5.76s\tremaining: 20.7s\n",
      "109:\tlearn: 0.0016420\ttotal: 5.79s\tremaining: 20.5s\n",
      "110:\tlearn: 0.0016420\ttotal: 5.83s\tremaining: 20.4s\n",
      "111:\tlearn: 0.0016419\ttotal: 5.87s\tremaining: 20.3s\n",
      "112:\tlearn: 0.0016417\ttotal: 5.91s\tremaining: 20.2s\n",
      "113:\tlearn: 0.0016416\ttotal: 5.94s\tremaining: 20.1s\n",
      "114:\tlearn: 0.0016396\ttotal: 5.98s\tremaining: 20s\n",
      "115:\tlearn: 0.0016395\ttotal: 6.02s\tremaining: 19.9s\n",
      "116:\tlearn: 0.0016395\ttotal: 6.06s\tremaining: 19.8s\n",
      "117:\tlearn: 0.0016326\ttotal: 6.11s\tremaining: 19.8s\n",
      "118:\tlearn: 0.0016316\ttotal: 6.15s\tremaining: 19.7s\n",
      "119:\tlearn: 0.0016300\ttotal: 6.18s\tremaining: 19.6s\n",
      "120:\tlearn: 0.0016299\ttotal: 6.21s\tremaining: 19.5s\n",
      "121:\tlearn: 0.0016299\ttotal: 6.26s\tremaining: 19.4s\n",
      "122:\tlearn: 0.0016298\ttotal: 6.3s\tremaining: 19.3s\n",
      "123:\tlearn: 0.0016297\ttotal: 6.34s\tremaining: 19.2s\n",
      "124:\tlearn: 0.0016296\ttotal: 6.39s\tremaining: 19.2s\n",
      "125:\tlearn: 0.0016295\ttotal: 6.43s\tremaining: 19.1s\n",
      "126:\tlearn: 0.0016294\ttotal: 6.48s\tremaining: 19s\n",
      "127:\tlearn: 0.0016293\ttotal: 6.56s\tremaining: 19.1s\n",
      "128:\tlearn: 0.0016293\ttotal: 6.64s\tremaining: 19.1s\n",
      "129:\tlearn: 0.0016292\ttotal: 6.72s\tremaining: 19.1s\n",
      "130:\tlearn: 0.0016250\ttotal: 6.8s\tremaining: 19.2s\n",
      "131:\tlearn: 0.0016249\ttotal: 6.88s\tremaining: 19.2s\n",
      "132:\tlearn: 0.0016249\ttotal: 6.93s\tremaining: 19.1s\n",
      "133:\tlearn: 0.0016248\ttotal: 6.98s\tremaining: 19.1s\n",
      "134:\tlearn: 0.0016248\ttotal: 7.03s\tremaining: 19s\n",
      "135:\tlearn: 0.0016247\ttotal: 7.09s\tremaining: 19s\n",
      "136:\tlearn: 0.0016247\ttotal: 7.18s\tremaining: 19s\n",
      "137:\tlearn: 0.0016203\ttotal: 7.26s\tremaining: 19s\n",
      "138:\tlearn: 0.0016202\ttotal: 7.32s\tremaining: 19s\n",
      "139:\tlearn: 0.0016202\ttotal: 7.39s\tremaining: 19s\n",
      "140:\tlearn: 0.0016201\ttotal: 7.46s\tremaining: 19s\n",
      "141:\tlearn: 0.0016166\ttotal: 7.52s\tremaining: 19s\n",
      "142:\tlearn: 0.0016165\ttotal: 7.59s\tremaining: 18.9s\n",
      "143:\tlearn: 0.0016159\ttotal: 7.66s\tremaining: 18.9s\n",
      "144:\tlearn: 0.0016158\ttotal: 7.72s\tremaining: 18.9s\n",
      "145:\tlearn: 0.0016158\ttotal: 7.78s\tremaining: 18.9s\n",
      "146:\tlearn: 0.0016157\ttotal: 7.83s\tremaining: 18.8s\n",
      "147:\tlearn: 0.0016157\ttotal: 7.89s\tremaining: 18.8s\n",
      "148:\tlearn: 0.0016157\ttotal: 7.94s\tremaining: 18.7s\n",
      "149:\tlearn: 0.0016156\ttotal: 8s\tremaining: 18.7s\n",
      "150:\tlearn: 0.0016156\ttotal: 8.06s\tremaining: 18.6s\n",
      "151:\tlearn: 0.0016155\ttotal: 8.12s\tremaining: 18.6s\n",
      "152:\tlearn: 0.0016155\ttotal: 8.18s\tremaining: 18.5s\n",
      "153:\tlearn: 0.0016155\ttotal: 8.24s\tremaining: 18.5s\n",
      "154:\tlearn: 0.0016154\ttotal: 8.29s\tremaining: 18.5s\n",
      "155:\tlearn: 0.0016154\ttotal: 8.34s\tremaining: 18.4s\n",
      "156:\tlearn: 0.0016154\ttotal: 8.4s\tremaining: 18.4s\n",
      "157:\tlearn: 0.0016154\ttotal: 8.46s\tremaining: 18.3s\n",
      "158:\tlearn: 0.0016143\ttotal: 8.52s\tremaining: 18.3s\n",
      "159:\tlearn: 0.0016142\ttotal: 8.58s\tremaining: 18.2s\n",
      "160:\tlearn: 0.0016142\ttotal: 8.63s\tremaining: 18.2s\n",
      "161:\tlearn: 0.0016142\ttotal: 8.69s\tremaining: 18.1s\n",
      "162:\tlearn: 0.0016141\ttotal: 8.73s\tremaining: 18.1s\n",
      "163:\tlearn: 0.0016126\ttotal: 8.77s\tremaining: 18s\n",
      "164:\tlearn: 0.0016108\ttotal: 8.83s\tremaining: 17.9s\n",
      "165:\tlearn: 0.0016108\ttotal: 8.88s\tremaining: 17.9s\n",
      "166:\tlearn: 0.0016094\ttotal: 8.93s\tremaining: 17.8s\n",
      "167:\tlearn: 0.0016094\ttotal: 8.97s\tremaining: 17.7s\n",
      "168:\tlearn: 0.0016094\ttotal: 9.01s\tremaining: 17.6s\n",
      "169:\tlearn: 0.0016094\ttotal: 9.05s\tremaining: 17.6s\n",
      "170:\tlearn: 0.0016094\ttotal: 9.1s\tremaining: 17.5s\n",
      "171:\tlearn: 0.0016093\ttotal: 9.15s\tremaining: 17.4s\n",
      "172:\tlearn: 0.0016093\ttotal: 9.23s\tremaining: 17.4s\n",
      "173:\tlearn: 0.0016093\ttotal: 9.28s\tremaining: 17.4s\n",
      "174:\tlearn: 0.0016093\ttotal: 9.34s\tremaining: 17.3s\n",
      "175:\tlearn: 0.0016093\ttotal: 9.4s\tremaining: 17.3s\n",
      "176:\tlearn: 0.0016092\ttotal: 9.46s\tremaining: 17.3s\n",
      "177:\tlearn: 0.0016092\ttotal: 9.53s\tremaining: 17.2s\n",
      "178:\tlearn: 0.0016092\ttotal: 9.59s\tremaining: 17.2s\n",
      "179:\tlearn: 0.0016092\ttotal: 9.64s\tremaining: 17.1s\n",
      "180:\tlearn: 0.0016061\ttotal: 9.7s\tremaining: 17.1s\n",
      "181:\tlearn: 0.0016059\ttotal: 9.77s\tremaining: 17.1s\n",
      "182:\tlearn: 0.0016059\ttotal: 9.83s\tremaining: 17s\n",
      "183:\tlearn: 0.0016059\ttotal: 9.88s\tremaining: 17s\n",
      "184:\tlearn: 0.0016059\ttotal: 9.93s\tremaining: 16.9s\n",
      "185:\tlearn: 0.0016059\ttotal: 9.98s\tremaining: 16.8s\n",
      "186:\tlearn: 0.0016058\ttotal: 10s\tremaining: 16.8s\n",
      "187:\tlearn: 0.0016058\ttotal: 10.1s\tremaining: 16.7s\n",
      "188:\tlearn: 0.0016058\ttotal: 10.1s\tremaining: 16.7s\n",
      "189:\tlearn: 0.0016058\ttotal: 10.2s\tremaining: 16.7s\n",
      "190:\tlearn: 0.0016058\ttotal: 10.3s\tremaining: 16.6s\n",
      "191:\tlearn: 0.0016058\ttotal: 10.4s\tremaining: 16.8s\n",
      "192:\tlearn: 0.0016057\ttotal: 10.5s\tremaining: 16.8s\n",
      "193:\tlearn: 0.0016057\ttotal: 10.6s\tremaining: 16.7s\n",
      "194:\tlearn: 0.0016057\ttotal: 10.7s\tremaining: 16.8s\n",
      "195:\tlearn: 0.0016057\ttotal: 10.9s\tremaining: 16.9s\n",
      "196:\tlearn: 0.0016057\ttotal: 11s\tremaining: 16.8s\n",
      "197:\tlearn: 0.0016056\ttotal: 11.1s\tremaining: 16.9s\n",
      "198:\tlearn: 0.0016056\ttotal: 11.1s\tremaining: 16.8s\n",
      "199:\tlearn: 0.0016056\ttotal: 11.2s\tremaining: 16.8s\n",
      "200:\tlearn: 0.0016056\ttotal: 11.2s\tremaining: 16.7s\n",
      "201:\tlearn: 0.0016056\ttotal: 11.3s\tremaining: 16.6s\n",
      "202:\tlearn: 0.0016056\ttotal: 11.3s\tremaining: 16.6s\n",
      "203:\tlearn: 0.0016053\ttotal: 11.4s\tremaining: 16.5s\n",
      "204:\tlearn: 0.0016043\ttotal: 11.4s\tremaining: 16.4s\n",
      "205:\tlearn: 0.0016043\ttotal: 11.5s\tremaining: 16.4s\n",
      "206:\tlearn: 0.0016043\ttotal: 11.5s\tremaining: 16.3s\n",
      "207:\tlearn: 0.0016043\ttotal: 11.7s\tremaining: 16.4s\n",
      "208:\tlearn: 0.0016043\ttotal: 11.7s\tremaining: 16.3s\n",
      "209:\tlearn: 0.0016043\ttotal: 11.8s\tremaining: 16.3s\n",
      "210:\tlearn: 0.0016042\ttotal: 11.8s\tremaining: 16.2s\n",
      "211:\tlearn: 0.0016041\ttotal: 11.9s\tremaining: 16.1s\n",
      "212:\tlearn: 0.0016041\ttotal: 11.9s\tremaining: 16.1s\n",
      "213:\tlearn: 0.0016041\ttotal: 12s\tremaining: 16s\n",
      "214:\tlearn: 0.0016041\ttotal: 12s\tremaining: 16s\n",
      "215:\tlearn: 0.0016041\ttotal: 12.1s\tremaining: 15.9s\n",
      "216:\tlearn: 0.0016041\ttotal: 12.2s\tremaining: 15.8s\n",
      "217:\tlearn: 0.0016040\ttotal: 12.2s\tremaining: 15.8s\n",
      "218:\tlearn: 0.0016040\ttotal: 12.3s\tremaining: 15.8s\n",
      "219:\tlearn: 0.0016039\ttotal: 12.5s\tremaining: 15.9s\n",
      "220:\tlearn: 0.0016039\ttotal: 12.6s\tremaining: 15.9s\n",
      "221:\tlearn: 0.0016039\ttotal: 12.7s\tremaining: 15.9s\n",
      "222:\tlearn: 0.0016039\ttotal: 12.8s\tremaining: 16s\n",
      "223:\tlearn: 0.0016031\ttotal: 12.9s\tremaining: 15.9s\n",
      "224:\tlearn: 0.0016031\ttotal: 13s\tremaining: 15.9s\n",
      "225:\tlearn: 0.0016031\ttotal: 13.1s\tremaining: 15.9s\n",
      "226:\tlearn: 0.0016029\ttotal: 13.2s\tremaining: 15.9s\n",
      "227:\tlearn: 0.0016028\ttotal: 13.3s\tremaining: 15.9s\n",
      "228:\tlearn: 0.0016019\ttotal: 13.5s\tremaining: 16s\n",
      "229:\tlearn: 0.0016019\ttotal: 13.6s\tremaining: 16s\n",
      "230:\tlearn: 0.0016015\ttotal: 13.6s\tremaining: 15.9s\n",
      "231:\tlearn: 0.0016015\ttotal: 13.7s\tremaining: 15.9s\n",
      "232:\tlearn: 0.0016015\ttotal: 13.9s\tremaining: 15.9s\n",
      "233:\tlearn: 0.0016015\ttotal: 14s\tremaining: 15.9s\n",
      "234:\tlearn: 0.0016015\ttotal: 14s\tremaining: 15.8s\n",
      "235:\tlearn: 0.0016014\ttotal: 14.2s\tremaining: 15.9s\n",
      "236:\tlearn: 0.0016014\ttotal: 14.3s\tremaining: 15.9s\n",
      "237:\tlearn: 0.0015972\ttotal: 14.4s\tremaining: 15.9s\n",
      "238:\tlearn: 0.0015971\ttotal: 14.5s\tremaining: 15.8s\n",
      "239:\tlearn: 0.0015971\ttotal: 14.6s\tremaining: 15.8s\n",
      "240:\tlearn: 0.0015971\ttotal: 14.7s\tremaining: 15.8s\n",
      "241:\tlearn: 0.0015971\ttotal: 14.8s\tremaining: 15.7s\n",
      "242:\tlearn: 0.0015971\ttotal: 14.9s\tremaining: 15.7s\n",
      "243:\tlearn: 0.0015822\ttotal: 15s\tremaining: 15.7s\n",
      "244:\tlearn: 0.0015822\ttotal: 15.1s\tremaining: 15.7s\n",
      "245:\tlearn: 0.0015822\ttotal: 15.1s\tremaining: 15.6s\n",
      "246:\tlearn: 0.0015821\ttotal: 15.2s\tremaining: 15.5s\n",
      "247:\tlearn: 0.0015821\ttotal: 15.2s\tremaining: 15.5s\n",
      "248:\tlearn: 0.0015816\ttotal: 15.3s\tremaining: 15.4s\n",
      "249:\tlearn: 0.0015816\ttotal: 15.3s\tremaining: 15.3s\n",
      "250:\tlearn: 0.0015816\ttotal: 15.4s\tremaining: 15.3s\n",
      "251:\tlearn: 0.0015816\ttotal: 15.4s\tremaining: 15.2s\n",
      "252:\tlearn: 0.0015816\ttotal: 15.5s\tremaining: 15.2s\n",
      "253:\tlearn: 0.0015816\ttotal: 15.6s\tremaining: 15.1s\n",
      "254:\tlearn: 0.0015816\ttotal: 15.7s\tremaining: 15.1s\n",
      "255:\tlearn: 0.0015811\ttotal: 15.8s\tremaining: 15s\n",
      "256:\tlearn: 0.0015807\ttotal: 15.9s\tremaining: 15s\n",
      "257:\tlearn: 0.0015807\ttotal: 15.9s\tremaining: 14.9s\n",
      "258:\tlearn: 0.0015807\ttotal: 16s\tremaining: 14.9s\n",
      "259:\tlearn: 0.0015807\ttotal: 16.1s\tremaining: 14.8s\n",
      "260:\tlearn: 0.0015807\ttotal: 16.2s\tremaining: 14.8s\n",
      "261:\tlearn: 0.0015807\ttotal: 16.2s\tremaining: 14.8s\n",
      "262:\tlearn: 0.0015806\ttotal: 16.3s\tremaining: 14.7s\n",
      "263:\tlearn: 0.0015806\ttotal: 16.4s\tremaining: 14.7s\n",
      "264:\tlearn: 0.0015806\ttotal: 16.5s\tremaining: 14.7s\n",
      "265:\tlearn: 0.0015806\ttotal: 16.6s\tremaining: 14.6s\n",
      "266:\tlearn: 0.0015806\ttotal: 16.7s\tremaining: 14.6s\n",
      "267:\tlearn: 0.0015806\ttotal: 16.8s\tremaining: 14.6s\n",
      "268:\tlearn: 0.0015806\ttotal: 17s\tremaining: 14.6s\n",
      "269:\tlearn: 0.0015806\ttotal: 17.2s\tremaining: 14.6s\n",
      "270:\tlearn: 0.0015806\ttotal: 17.3s\tremaining: 14.6s\n",
      "271:\tlearn: 0.0015806\ttotal: 17.4s\tremaining: 14.6s\n",
      "272:\tlearn: 0.0015806\ttotal: 17.5s\tremaining: 14.6s\n",
      "273:\tlearn: 0.0015805\ttotal: 17.6s\tremaining: 14.5s\n",
      "274:\tlearn: 0.0015805\ttotal: 17.6s\tremaining: 14.4s\n",
      "275:\tlearn: 0.0015805\ttotal: 17.7s\tremaining: 14.4s\n",
      "276:\tlearn: 0.0015805\ttotal: 17.8s\tremaining: 14.3s\n",
      "277:\tlearn: 0.0015805\ttotal: 17.9s\tremaining: 14.3s\n",
      "278:\tlearn: 0.0015805\ttotal: 18.2s\tremaining: 14.4s\n",
      "279:\tlearn: 0.0015803\ttotal: 18.3s\tremaining: 14.4s\n",
      "280:\tlearn: 0.0015787\ttotal: 18.4s\tremaining: 14.3s\n",
      "281:\tlearn: 0.0015787\ttotal: 18.5s\tremaining: 14.3s\n",
      "282:\tlearn: 0.0015787\ttotal: 18.5s\tremaining: 14.2s\n",
      "283:\tlearn: 0.0015787\ttotal: 18.6s\tremaining: 14.1s\n",
      "284:\tlearn: 0.0015787\ttotal: 18.7s\tremaining: 14.1s\n",
      "285:\tlearn: 0.0015787\ttotal: 18.7s\tremaining: 14s\n",
      "286:\tlearn: 0.0015787\ttotal: 18.8s\tremaining: 13.9s\n",
      "287:\tlearn: 0.0015787\ttotal: 18.8s\tremaining: 13.9s\n",
      "288:\tlearn: 0.0015787\ttotal: 18.9s\tremaining: 13.8s\n",
      "289:\tlearn: 0.0015786\ttotal: 19s\tremaining: 13.8s\n",
      "290:\tlearn: 0.0015786\ttotal: 19.1s\tremaining: 13.7s\n",
      "291:\tlearn: 0.0015786\ttotal: 19.2s\tremaining: 13.7s\n",
      "292:\tlearn: 0.0015786\ttotal: 19.3s\tremaining: 13.6s\n",
      "293:\tlearn: 0.0015783\ttotal: 19.4s\tremaining: 13.6s\n",
      "294:\tlearn: 0.0015783\ttotal: 19.5s\tremaining: 13.5s\n",
      "295:\tlearn: 0.0015783\ttotal: 19.6s\tremaining: 13.5s\n",
      "296:\tlearn: 0.0015783\ttotal: 19.8s\tremaining: 13.5s\n",
      "297:\tlearn: 0.0015783\ttotal: 19.9s\tremaining: 13.5s\n",
      "298:\tlearn: 0.0015783\ttotal: 20s\tremaining: 13.4s\n",
      "299:\tlearn: 0.0015783\ttotal: 20.1s\tremaining: 13.4s\n",
      "300:\tlearn: 0.0015783\ttotal: 20.2s\tremaining: 13.4s\n",
      "301:\tlearn: 0.0015783\ttotal: 20.3s\tremaining: 13.3s\n",
      "302:\tlearn: 0.0015783\ttotal: 20.4s\tremaining: 13.3s\n",
      "303:\tlearn: 0.0015783\ttotal: 20.5s\tremaining: 13.2s\n",
      "304:\tlearn: 0.0015783\ttotal: 20.6s\tremaining: 13.2s\n",
      "305:\tlearn: 0.0015783\ttotal: 20.7s\tremaining: 13.1s\n",
      "306:\tlearn: 0.0015783\ttotal: 20.8s\tremaining: 13.1s\n",
      "307:\tlearn: 0.0015780\ttotal: 20.9s\tremaining: 13s\n",
      "308:\tlearn: 0.0015780\ttotal: 21s\tremaining: 13s\n",
      "309:\tlearn: 0.0015780\ttotal: 21.1s\tremaining: 12.9s\n",
      "310:\tlearn: 0.0015780\ttotal: 21.1s\tremaining: 12.8s\n",
      "311:\tlearn: 0.0015780\ttotal: 21.2s\tremaining: 12.8s\n",
      "312:\tlearn: 0.0015771\ttotal: 21.3s\tremaining: 12.7s\n",
      "313:\tlearn: 0.0015771\ttotal: 21.5s\tremaining: 12.7s\n",
      "314:\tlearn: 0.0015771\ttotal: 21.7s\tremaining: 12.8s\n",
      "315:\tlearn: 0.0015771\ttotal: 21.9s\tremaining: 12.7s\n",
      "316:\tlearn: 0.0015770\ttotal: 22s\tremaining: 12.7s\n",
      "317:\tlearn: 0.0015770\ttotal: 22.1s\tremaining: 12.7s\n",
      "318:\tlearn: 0.0015770\ttotal: 22.3s\tremaining: 12.6s\n",
      "319:\tlearn: 0.0015770\ttotal: 22.4s\tremaining: 12.6s\n",
      "320:\tlearn: 0.0015770\ttotal: 22.6s\tremaining: 12.6s\n",
      "321:\tlearn: 0.0015770\ttotal: 22.7s\tremaining: 12.5s\n",
      "322:\tlearn: 0.0015770\ttotal: 23s\tremaining: 12.6s\n",
      "323:\tlearn: 0.0015770\ttotal: 23.1s\tremaining: 12.6s\n",
      "324:\tlearn: 0.0015770\ttotal: 23.3s\tremaining: 12.6s\n",
      "325:\tlearn: 0.0015769\ttotal: 23.7s\tremaining: 12.7s\n",
      "326:\tlearn: 0.0015769\ttotal: 23.9s\tremaining: 12.6s\n",
      "327:\tlearn: 0.0015769\ttotal: 24.1s\tremaining: 12.7s\n",
      "328:\tlearn: 0.0015769\ttotal: 24.6s\tremaining: 12.8s\n",
      "329:\tlearn: 0.0015766\ttotal: 24.9s\tremaining: 12.8s\n",
      "330:\tlearn: 0.0015766\ttotal: 25s\tremaining: 12.8s\n",
      "331:\tlearn: 0.0015766\ttotal: 25.2s\tremaining: 12.8s\n",
      "332:\tlearn: 0.0015766\ttotal: 25.3s\tremaining: 12.7s\n",
      "333:\tlearn: 0.0015766\ttotal: 25.4s\tremaining: 12.6s\n",
      "334:\tlearn: 0.0015748\ttotal: 25.5s\tremaining: 12.6s\n",
      "335:\tlearn: 0.0015748\ttotal: 25.7s\tremaining: 12.5s\n",
      "336:\tlearn: 0.0015748\ttotal: 25.9s\tremaining: 12.5s\n",
      "337:\tlearn: 0.0015740\ttotal: 26.4s\tremaining: 12.7s\n",
      "338:\tlearn: 0.0015740\ttotal: 26.6s\tremaining: 12.6s\n",
      "339:\tlearn: 0.0015740\ttotal: 26.9s\tremaining: 12.6s\n",
      "340:\tlearn: 0.0015733\ttotal: 27s\tremaining: 12.6s\n",
      "341:\tlearn: 0.0015733\ttotal: 27.1s\tremaining: 12.5s\n",
      "342:\tlearn: 0.0015733\ttotal: 27.2s\tremaining: 12.5s\n",
      "343:\tlearn: 0.0015733\ttotal: 27.4s\tremaining: 12.4s\n",
      "344:\tlearn: 0.0015732\ttotal: 27.5s\tremaining: 12.4s\n",
      "345:\tlearn: 0.0015732\ttotal: 27.9s\tremaining: 12.4s\n",
      "346:\tlearn: 0.0015732\ttotal: 28.2s\tremaining: 12.4s\n",
      "347:\tlearn: 0.0015732\ttotal: 28.4s\tremaining: 12.4s\n",
      "348:\tlearn: 0.0015732\ttotal: 28.6s\tremaining: 12.4s\n",
      "349:\tlearn: 0.0015732\ttotal: 28.8s\tremaining: 12.3s\n",
      "350:\tlearn: 0.0015732\ttotal: 28.9s\tremaining: 12.3s\n",
      "351:\tlearn: 0.0015731\ttotal: 29s\tremaining: 12.2s\n",
      "352:\tlearn: 0.0015731\ttotal: 29.1s\tremaining: 12.1s\n",
      "353:\tlearn: 0.0015731\ttotal: 29.2s\tremaining: 12.1s\n",
      "354:\tlearn: 0.0015730\ttotal: 29.3s\tremaining: 12s\n",
      "355:\tlearn: 0.0015729\ttotal: 29.5s\tremaining: 11.9s\n",
      "356:\tlearn: 0.0015729\ttotal: 29.6s\tremaining: 11.9s\n",
      "357:\tlearn: 0.0015729\ttotal: 29.9s\tremaining: 11.9s\n",
      "358:\tlearn: 0.0015729\ttotal: 30s\tremaining: 11.8s\n",
      "359:\tlearn: 0.0015729\ttotal: 30.2s\tremaining: 11.7s\n",
      "360:\tlearn: 0.0015729\ttotal: 30.3s\tremaining: 11.6s\n",
      "361:\tlearn: 0.0015729\ttotal: 30.4s\tremaining: 11.6s\n",
      "362:\tlearn: 0.0015728\ttotal: 30.4s\tremaining: 11.5s\n",
      "363:\tlearn: 0.0015728\ttotal: 30.6s\tremaining: 11.4s\n",
      "364:\tlearn: 0.0015728\ttotal: 30.7s\tremaining: 11.3s\n",
      "365:\tlearn: 0.0015728\ttotal: 30.7s\tremaining: 11.3s\n",
      "366:\tlearn: 0.0015728\ttotal: 30.9s\tremaining: 11.2s\n",
      "367:\tlearn: 0.0015698\ttotal: 31s\tremaining: 11.1s\n",
      "368:\tlearn: 0.0015698\ttotal: 31.1s\tremaining: 11s\n",
      "369:\tlearn: 0.0015698\ttotal: 31.2s\tremaining: 11s\n",
      "370:\tlearn: 0.0015698\ttotal: 31.3s\tremaining: 10.9s\n",
      "371:\tlearn: 0.0015694\ttotal: 31.4s\tremaining: 10.8s\n",
      "372:\tlearn: 0.0015693\ttotal: 31.4s\tremaining: 10.7s\n",
      "373:\tlearn: 0.0015693\ttotal: 31.5s\tremaining: 10.6s\n",
      "374:\tlearn: 0.0015693\ttotal: 31.6s\tremaining: 10.5s\n",
      "375:\tlearn: 0.0015693\ttotal: 31.7s\tremaining: 10.4s\n",
      "376:\tlearn: 0.0015693\ttotal: 31.9s\tremaining: 10.4s\n",
      "377:\tlearn: 0.0015693\ttotal: 32.2s\tremaining: 10.4s\n",
      "378:\tlearn: 0.0015693\ttotal: 32.3s\tremaining: 10.3s\n",
      "379:\tlearn: 0.0015693\ttotal: 32.4s\tremaining: 10.2s\n",
      "380:\tlearn: 0.0015693\ttotal: 32.6s\tremaining: 10.2s\n",
      "381:\tlearn: 0.0015693\ttotal: 32.7s\tremaining: 10.1s\n",
      "382:\tlearn: 0.0015683\ttotal: 32.8s\tremaining: 10s\n",
      "383:\tlearn: 0.0015683\ttotal: 32.9s\tremaining: 9.93s\n",
      "384:\tlearn: 0.0015683\ttotal: 33s\tremaining: 9.85s\n",
      "385:\tlearn: 0.0015683\ttotal: 33.1s\tremaining: 9.77s\n",
      "386:\tlearn: 0.0015683\ttotal: 33.3s\tremaining: 9.73s\n",
      "387:\tlearn: 0.0015679\ttotal: 33.6s\tremaining: 9.69s\n",
      "388:\tlearn: 0.0015679\ttotal: 33.7s\tremaining: 9.62s\n",
      "389:\tlearn: 0.0015679\ttotal: 33.8s\tremaining: 9.54s\n",
      "390:\tlearn: 0.0015679\ttotal: 33.9s\tremaining: 9.46s\n",
      "391:\tlearn: 0.0015679\ttotal: 34s\tremaining: 9.38s\n",
      "392:\tlearn: 0.0015679\ttotal: 34.2s\tremaining: 9.3s\n",
      "393:\tlearn: 0.0015679\ttotal: 34.3s\tremaining: 9.22s\n",
      "394:\tlearn: 0.0015679\ttotal: 34.3s\tremaining: 9.13s\n",
      "395:\tlearn: 0.0015679\ttotal: 34.4s\tremaining: 9.04s\n",
      "396:\tlearn: 0.0015679\ttotal: 34.6s\tremaining: 8.96s\n",
      "397:\tlearn: 0.0015679\ttotal: 34.7s\tremaining: 8.88s\n",
      "398:\tlearn: 0.0015679\ttotal: 34.8s\tremaining: 8.81s\n",
      "399:\tlearn: 0.0015679\ttotal: 34.9s\tremaining: 8.73s\n",
      "400:\tlearn: 0.0015679\ttotal: 35.1s\tremaining: 8.67s\n",
      "401:\tlearn: 0.0015679\ttotal: 35.2s\tremaining: 8.58s\n",
      "402:\tlearn: 0.0015679\ttotal: 35.3s\tremaining: 8.49s\n",
      "403:\tlearn: 0.0015679\ttotal: 35.4s\tremaining: 8.42s\n",
      "404:\tlearn: 0.0015678\ttotal: 35.5s\tremaining: 8.33s\n",
      "405:\tlearn: 0.0015678\ttotal: 35.6s\tremaining: 8.24s\n",
      "406:\tlearn: 0.0015678\ttotal: 35.7s\tremaining: 8.15s\n",
      "407:\tlearn: 0.0015678\ttotal: 35.8s\tremaining: 8.06s\n",
      "408:\tlearn: 0.0015678\ttotal: 35.8s\tremaining: 7.97s\n",
      "409:\tlearn: 0.0015678\ttotal: 35.9s\tremaining: 7.88s\n",
      "410:\tlearn: 0.0015678\ttotal: 36s\tremaining: 7.79s\n",
      "411:\tlearn: 0.0015678\ttotal: 36s\tremaining: 7.7s\n",
      "412:\tlearn: 0.0015678\ttotal: 36.1s\tremaining: 7.61s\n",
      "413:\tlearn: 0.0015678\ttotal: 36.2s\tremaining: 7.53s\n",
      "414:\tlearn: 0.0015678\ttotal: 36.3s\tremaining: 7.44s\n",
      "415:\tlearn: 0.0015678\ttotal: 36.4s\tremaining: 7.34s\n",
      "416:\tlearn: 0.0015678\ttotal: 36.4s\tremaining: 7.25s\n",
      "417:\tlearn: 0.0015678\ttotal: 36.6s\tremaining: 7.18s\n",
      "418:\tlearn: 0.0015678\ttotal: 36.7s\tremaining: 7.09s\n",
      "419:\tlearn: 0.0015667\ttotal: 36.7s\tremaining: 7s\n",
      "420:\tlearn: 0.0015667\ttotal: 36.8s\tremaining: 6.91s\n",
      "421:\tlearn: 0.0015667\ttotal: 36.9s\tremaining: 6.82s\n",
      "422:\tlearn: 0.0015667\ttotal: 37s\tremaining: 6.73s\n",
      "423:\tlearn: 0.0015667\ttotal: 37s\tremaining: 6.64s\n",
      "424:\tlearn: 0.0015666\ttotal: 37.1s\tremaining: 6.55s\n",
      "425:\tlearn: 0.0015666\ttotal: 37.2s\tremaining: 6.46s\n",
      "426:\tlearn: 0.0015666\ttotal: 37.2s\tremaining: 6.37s\n",
      "427:\tlearn: 0.0015659\ttotal: 37.3s\tremaining: 6.28s\n",
      "428:\tlearn: 0.0015659\ttotal: 37.4s\tremaining: 6.19s\n",
      "429:\tlearn: 0.0015659\ttotal: 37.5s\tremaining: 6.1s\n",
      "430:\tlearn: 0.0015659\ttotal: 37.5s\tremaining: 6.01s\n",
      "431:\tlearn: 0.0015659\ttotal: 37.6s\tremaining: 5.92s\n",
      "432:\tlearn: 0.0015659\ttotal: 37.7s\tremaining: 5.83s\n",
      "433:\tlearn: 0.0015659\ttotal: 37.8s\tremaining: 5.74s\n",
      "434:\tlearn: 0.0015659\ttotal: 37.9s\tremaining: 5.66s\n",
      "435:\tlearn: 0.0015659\ttotal: 37.9s\tremaining: 5.57s\n",
      "436:\tlearn: 0.0015659\ttotal: 38s\tremaining: 5.47s\n",
      "437:\tlearn: 0.0015658\ttotal: 38.1s\tremaining: 5.39s\n",
      "438:\tlearn: 0.0015658\ttotal: 38.1s\tremaining: 5.3s\n",
      "439:\tlearn: 0.0015658\ttotal: 38.2s\tremaining: 5.21s\n",
      "440:\tlearn: 0.0015658\ttotal: 38.2s\tremaining: 5.12s\n",
      "441:\tlearn: 0.0015656\ttotal: 38.3s\tremaining: 5.03s\n",
      "442:\tlearn: 0.0015656\ttotal: 38.4s\tremaining: 4.94s\n",
      "443:\tlearn: 0.0015656\ttotal: 38.4s\tremaining: 4.85s\n",
      "444:\tlearn: 0.0015656\ttotal: 38.5s\tremaining: 4.76s\n",
      "445:\tlearn: 0.0015653\ttotal: 38.6s\tremaining: 4.67s\n",
      "446:\tlearn: 0.0015653\ttotal: 38.6s\tremaining: 4.58s\n",
      "447:\tlearn: 0.0015653\ttotal: 38.7s\tremaining: 4.49s\n",
      "448:\tlearn: 0.0015653\ttotal: 38.8s\tremaining: 4.4s\n",
      "449:\tlearn: 0.0015653\ttotal: 38.9s\tremaining: 4.32s\n",
      "450:\tlearn: 0.0015653\ttotal: 38.9s\tremaining: 4.23s\n",
      "451:\tlearn: 0.0015653\ttotal: 39s\tremaining: 4.14s\n",
      "452:\tlearn: 0.0015652\ttotal: 39.1s\tremaining: 4.05s\n",
      "453:\tlearn: 0.0015652\ttotal: 39.1s\tremaining: 3.97s\n",
      "454:\tlearn: 0.0015652\ttotal: 39.2s\tremaining: 3.88s\n",
      "455:\tlearn: 0.0015644\ttotal: 39.3s\tremaining: 3.79s\n",
      "456:\tlearn: 0.0015644\ttotal: 39.3s\tremaining: 3.7s\n",
      "457:\tlearn: 0.0015644\ttotal: 39.4s\tremaining: 3.62s\n",
      "458:\tlearn: 0.0015642\ttotal: 39.5s\tremaining: 3.53s\n",
      "459:\tlearn: 0.0015641\ttotal: 39.6s\tremaining: 3.44s\n",
      "460:\tlearn: 0.0015641\ttotal: 39.7s\tremaining: 3.35s\n",
      "461:\tlearn: 0.0015641\ttotal: 39.7s\tremaining: 3.27s\n",
      "462:\tlearn: 0.0015641\ttotal: 39.8s\tremaining: 3.18s\n",
      "463:\tlearn: 0.0015639\ttotal: 39.8s\tremaining: 3.09s\n",
      "464:\tlearn: 0.0015638\ttotal: 39.9s\tremaining: 3s\n",
      "465:\tlearn: 0.0015638\ttotal: 40s\tremaining: 2.92s\n",
      "466:\tlearn: 0.0015638\ttotal: 40.1s\tremaining: 2.83s\n",
      "467:\tlearn: 0.0015638\ttotal: 40.1s\tremaining: 2.74s\n",
      "468:\tlearn: 0.0015637\ttotal: 40.2s\tremaining: 2.66s\n",
      "469:\tlearn: 0.0015637\ttotal: 40.3s\tremaining: 2.57s\n",
      "470:\tlearn: 0.0015637\ttotal: 40.3s\tremaining: 2.48s\n",
      "471:\tlearn: 0.0015637\ttotal: 40.5s\tremaining: 2.4s\n",
      "472:\tlearn: 0.0015637\ttotal: 40.6s\tremaining: 2.32s\n",
      "473:\tlearn: 0.0015635\ttotal: 40.7s\tremaining: 2.23s\n",
      "474:\tlearn: 0.0015635\ttotal: 40.9s\tremaining: 2.15s\n",
      "475:\tlearn: 0.0015634\ttotal: 41s\tremaining: 2.07s\n",
      "476:\tlearn: 0.0015634\ttotal: 41.1s\tremaining: 1.98s\n",
      "477:\tlearn: 0.0015634\ttotal: 41.1s\tremaining: 1.89s\n",
      "478:\tlearn: 0.0015634\ttotal: 41.2s\tremaining: 1.81s\n",
      "479:\tlearn: 0.0015634\ttotal: 41.3s\tremaining: 1.72s\n",
      "480:\tlearn: 0.0015634\ttotal: 41.3s\tremaining: 1.63s\n",
      "481:\tlearn: 0.0015634\ttotal: 41.4s\tremaining: 1.54s\n",
      "482:\tlearn: 0.0015629\ttotal: 41.4s\tremaining: 1.46s\n",
      "483:\tlearn: 0.0015629\ttotal: 41.5s\tremaining: 1.37s\n",
      "484:\tlearn: 0.0015628\ttotal: 41.5s\tremaining: 1.28s\n",
      "485:\tlearn: 0.0015628\ttotal: 41.6s\tremaining: 1.2s\n",
      "486:\tlearn: 0.0015628\ttotal: 41.7s\tremaining: 1.11s\n",
      "487:\tlearn: 0.0015628\ttotal: 41.7s\tremaining: 1.03s\n",
      "488:\tlearn: 0.0015628\ttotal: 41.8s\tremaining: 940ms\n",
      "489:\tlearn: 0.0015628\ttotal: 41.8s\tremaining: 854ms\n",
      "490:\tlearn: 0.0015628\ttotal: 41.9s\tremaining: 768ms\n",
      "491:\tlearn: 0.0015628\ttotal: 42s\tremaining: 682ms\n",
      "492:\tlearn: 0.0015624\ttotal: 42s\tremaining: 597ms\n",
      "493:\tlearn: 0.0015624\ttotal: 42.1s\tremaining: 512ms\n",
      "494:\tlearn: 0.0015624\ttotal: 42.2s\tremaining: 426ms\n",
      "495:\tlearn: 0.0015622\ttotal: 42.4s\tremaining: 342ms\n",
      "496:\tlearn: 0.0015622\ttotal: 42.4s\tremaining: 256ms\n",
      "497:\tlearn: 0.0015622\ttotal: 42.5s\tremaining: 171ms\n",
      "498:\tlearn: 0.0015622\ttotal: 42.6s\tremaining: 85.3ms\n",
      "499:\tlearn: 0.0015622\ttotal: 42.6s\tremaining: 0us\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1278\n",
      "[LightGBM] [Info] Number of data points in the train set: 216570, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -3.077331\n",
      "[LightGBM] [Info] Start training from score -5.794946\n",
      "[LightGBM] [Info] Start training from score -0.050373\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('Decision Tree', dt_class),\n",
    "    ('CatBoost', cat_reg),\n",
    "    ('XGBoost', xgb_class),\n",
    "    ('LightGBM', lgb_reg)\n",
    "], voting='soft')\n",
    "\n",
    "ensemble_model.fit(X_train_scaled, y_train)\n",
    "ensemble_predictions = ensemble_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.96%\n"
     ]
    }
   ],
   "source": [
    "# print accuracy score\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (ensemble_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_name= 'dataset_7_ensemble_model.pkl'\n",
    "\n",
    "# save\n",
    "with open(model_name,'wb') as f:\n",
    "    pickle.dump(ensemble_model,f)\n",
    "\n",
    "# load\n",
    "with open(model_name, 'rb') as f:\n",
    "    ensemble_model_load = pickle.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.96%\n"
     ]
    }
   ],
   "source": [
    "# verify that the loaded model works\n",
    "ensemble_model_load_predictions = ensemble_model_load.predict(X_test_scaled)\n",
    "ensemble_model_load_accuracy = accuracy_score(y_test, ensemble_model_load_predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (ensemble_model_load_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAWN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DRAWN</td>\n",
       "      <td>00009</td>\n",
       "      <td>2018-08-20 11:25:44.000000</td>\n",
       "      <td>235.0643</td>\n",
       "      <td>87.05141</td>\n",
       "      <td>109.9409</td>\n",
       "      <td>21.04113</td>\n",
       "      <td>59.85347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRAWN</td>\n",
       "      <td>00009</td>\n",
       "      <td>2018-08-20 11:25:45.000000</td>\n",
       "      <td>235.0643</td>\n",
       "      <td>87.05141</td>\n",
       "      <td>109.9409</td>\n",
       "      <td>21.04113</td>\n",
       "      <td>59.85347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DRAWN</td>\n",
       "      <td>00009</td>\n",
       "      <td>2018-08-20 11:25:46.000000</td>\n",
       "      <td>235.0644</td>\n",
       "      <td>87.05141</td>\n",
       "      <td>109.9409</td>\n",
       "      <td>21.04113</td>\n",
       "      <td>59.85347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DRAWN</td>\n",
       "      <td>00009</td>\n",
       "      <td>2018-08-20 11:25:47.000000</td>\n",
       "      <td>235.0644</td>\n",
       "      <td>87.05141</td>\n",
       "      <td>109.9409</td>\n",
       "      <td>21.04113</td>\n",
       "      <td>59.85347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DRAWN</td>\n",
       "      <td>00009</td>\n",
       "      <td>2018-08-20 11:25:48.000000</td>\n",
       "      <td>235.0644</td>\n",
       "      <td>87.05141</td>\n",
       "      <td>109.9409</td>\n",
       "      <td>21.04113</td>\n",
       "      <td>59.85347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419205</th>\n",
       "      <td>DRAWN</td>\n",
       "      <td>00010</td>\n",
       "      <td>2018-08-21 11:25:40.000000</td>\n",
       "      <td>260.9383</td>\n",
       "      <td>211.88690</td>\n",
       "      <td>117.8766</td>\n",
       "      <td>122.91520</td>\n",
       "      <td>65.02185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419206</th>\n",
       "      <td>DRAWN</td>\n",
       "      <td>00010</td>\n",
       "      <td>2018-08-21 11:25:41.000000</td>\n",
       "      <td>260.9383</td>\n",
       "      <td>211.88690</td>\n",
       "      <td>117.8766</td>\n",
       "      <td>122.91520</td>\n",
       "      <td>65.02185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419207</th>\n",
       "      <td>DRAWN</td>\n",
       "      <td>00010</td>\n",
       "      <td>2018-08-21 11:25:42.000000</td>\n",
       "      <td>260.9383</td>\n",
       "      <td>211.88690</td>\n",
       "      <td>117.8766</td>\n",
       "      <td>122.91520</td>\n",
       "      <td>65.02185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419208</th>\n",
       "      <td>DRAWN</td>\n",
       "      <td>00010</td>\n",
       "      <td>2018-08-21 11:25:43.000000</td>\n",
       "      <td>260.9383</td>\n",
       "      <td>211.88690</td>\n",
       "      <td>117.8766</td>\n",
       "      <td>122.91520</td>\n",
       "      <td>65.02185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419209</th>\n",
       "      <td>DRAWN</td>\n",
       "      <td>00010</td>\n",
       "      <td>2018-08-21 11:25:44.000000</td>\n",
       "      <td>260.9383</td>\n",
       "      <td>211.88690</td>\n",
       "      <td>117.8766</td>\n",
       "      <td>122.91520</td>\n",
       "      <td>65.02185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2419210 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          name     id                   timestamp     P-PDG      P-TPT  \\\n",
       "0        DRAWN  00009  2018-08-20 11:25:44.000000  235.0643   87.05141   \n",
       "1        DRAWN  00009  2018-08-20 11:25:45.000000  235.0643   87.05141   \n",
       "2        DRAWN  00009  2018-08-20 11:25:46.000000  235.0644   87.05141   \n",
       "3        DRAWN  00009  2018-08-20 11:25:47.000000  235.0644   87.05141   \n",
       "4        DRAWN  00009  2018-08-20 11:25:48.000000  235.0644   87.05141   \n",
       "...        ...    ...                         ...       ...        ...   \n",
       "2419205  DRAWN  00010  2018-08-21 11:25:40.000000  260.9383  211.88690   \n",
       "2419206  DRAWN  00010  2018-08-21 11:25:41.000000  260.9383  211.88690   \n",
       "2419207  DRAWN  00010  2018-08-21 11:25:42.000000  260.9383  211.88690   \n",
       "2419208  DRAWN  00010  2018-08-21 11:25:43.000000  260.9383  211.88690   \n",
       "2419209  DRAWN  00010  2018-08-21 11:25:44.000000  260.9383  211.88690   \n",
       "\n",
       "            T-TPT  P-MON-CKP  T-JUS-CKP  P-JUS-CKGL  T-JUS-CKGL  QGL  class  \n",
       "0        109.9409   21.04113   59.85347         NaN         NaN  NaN      0  \n",
       "1        109.9409   21.04113   59.85347         NaN         NaN  NaN      0  \n",
       "2        109.9409   21.04113   59.85347         NaN         NaN  NaN      0  \n",
       "3        109.9409   21.04113   59.85347         NaN         NaN  NaN      0  \n",
       "4        109.9409   21.04113   59.85347         NaN         NaN  NaN      0  \n",
       "...           ...        ...        ...         ...         ...  ...    ...  \n",
       "2419205  117.8766  122.91520   65.02185         NaN         NaN  NaN      7  \n",
       "2419206  117.8766  122.91520   65.02185         NaN         NaN  NaN      7  \n",
       "2419207  117.8766  122.91520   65.02185         NaN         NaN  NaN      7  \n",
       "2419208  117.8766  122.91520   65.02185         NaN         NaN  NaN      7  \n",
       "2419209  117.8766  122.91520   65.02185         NaN         NaN  NaN      7  \n",
       "\n",
       "[2419210 rows x 12 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=os.path.join(os.getcwd(),'data','7')\n",
    "csv_files=glob.glob(path + \"/*.csv\")\n",
    "\n",
    "csv_files_pickle=[csv_file for csv_file in csv_files if os.path.basename(csv_file).startswith('DRAWN')]\n",
    "\n",
    "dataframes={}\n",
    "\n",
    "for csv_file in csv_files_pickle:\n",
    "  # print(csv_file)\n",
    "  well_name=os.path.splitext(csv_file)[0]\n",
    "  # print(\"file path\")\n",
    "  # print(os.path.join(csv_directory,csv_file))\n",
    "\n",
    "  df = pd.read_csv(csv_file)\n",
    "  # df_test = pd.read_csv(csv_file, nrows=100)\n",
    "\n",
    "  # float_cols = [c for c in df_test if df_test[c].dtype == \"float64\"]\n",
    "  # float32_cols = {c: np.float32 for c in float_cols}\n",
    "\n",
    "  # df=pd.read_csv(csv_file, engine='c', dtype=float32_cols)\n",
    "  dataframes[well_name]=df\n",
    "\n",
    "for well_name,df in dataframes.items():\n",
    "  df.insert(0,'name',well_name.split('_')[0].split('/')[-1])\n",
    "  df.insert(1,'id',well_name.split('_')[1])\n",
    "\n",
    "df=pd.concat(dataframes.values(),ignore_index=True)\n",
    "\n",
    "distinct_wells=df['name'].unique()\n",
    "for name in distinct_wells:\n",
    "  print(name)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()\n",
    "#clean dataset to remove name, id, timestamp\n",
    "df=df.drop(['name','id','timestamp','T-JUS-CKGL'],axis=1)\n",
    "\n",
    "df=df.fillna(0)\n",
    "\n",
    "df.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/xgboost/data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/xgboost/data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/xgboost/data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/xgboost/data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8448617523902431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    267503\n",
      "           7       0.00      0.00      0.00    107809\n",
      "         107       0.84      1.00      0.92   2043898\n",
      "\n",
      "    accuracy                           0.84   2419210\n",
      "   macro avg       0.28      0.33      0.31   2419210\n",
      "weighted avg       0.71      0.84      0.77   2419210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dyllon/Library/Mobile Documents/com~apple~CloudDocs/Uni/BC2406/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_sim = df[\"class\"]\n",
    "\n",
    "\n",
    "X = df.drop(['class'],axis=1)\n",
    "y_pred = ensemble_model_load.predict(X)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_sim, y_pred)\n",
    "report = classification_report(y_sim, y_pred)\n",
    "\n",
    "print(accuracy)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
